---
layout: post
title: "Apr 9th Journal Club"
author: "Seonu An (seonuan82@gmail.com)"
---

Presenters: IL(Inju Lee), CL(Chunghyun Lee), SA(Seonu An), JL(Joohye Lee) <br>

-----------------


# Topic 1: Social Skill Training with Large Language Models [IL]

### **선정 이유**

Social Skill Training을 위한 LLM을 만드는 것에 관심이 있어 읽어보았다. 

### **내용 요약**

Social Skill을 훈련시키는 도구로써 LLM을 활용하는 APMP (AI Partner AI Mentor) 프레임워크를 제안하고 있다. LLM은 AI partner로서 시뮬레이션된 연습을 하는 상대의 역할을 할 수 있고 AI mentor로서는  도메인 전문성과 지식에 기반한 개인화된 피드백을 제공하는 역할을 할 수 있다. AI partner를 만들 때 consistency, faithful simulation, efficient curriculum, diversity가, AI mentor를 만들 때 domain expertise, context awareness, feedback efficacy가 고려되어야 한다. LLM을 이용해 Social Skill을 훈련시키기 위한 과정으로 4가지 단계를 제안하고 있다: (1) 훈련하고자 하는 기술에 필요한 Social Process 이해하기, (2) AI parner를 통한 시뮬레이션 대화 디자인, (3) AI mentor의 피드백 디자인, (4) 두 에이전트가 통합된 훈련 환경 마련. AI 에이전트의 능력 수준에 따라 Mode를 구분하여 제안하였으며(AI partner: rubber ducking, peer roleplay, standardized partner; AI mentor: conversational content, theory-grounded suggestions, structured feedback), 각 Mode의 현재 성능과 한계점을 고려하여 활용할 때 LLM을 안전하게 사용할 수 있다.  APMP 기반의 시스템을 구현하는데 4가지 기술적 어려움이 존재하며(optimizing long-tern interaction, integrating expert framework, designing for end-user control, personalizing skill training), 시스템을 평가할 땐 intrinsic과 extrinsic evaluation을 모두 진행해야 한다. 

### **의의**

Social Skill Training을 위해 LLM을 활용하는 방법과 그때 고려해야 할 점을 체계적으로 정리한 프레임워크를 제안했다는 점에서 의의를 지닌다. 

### **참고 문헌**

Yang, D., Ziems, C., Held, W., Shaikh, O., Bernstein, M. S., & Mitchell, J. (2024). Social skill training with large language models. arXiv preprint arXiv:2404.04204.


# Topic 2: Are Large Language Models Possible to Conduct Cognitive Behavior Therapy [CL]

### **선정 이유**

LLM이 발전하고 있는 가운데, 실제로 LLM 챗봇이 효과적인 상담을 제공할 수 있는지에 대한 의문이 제기되고 있다. LLM 챗봇이 제공하는 텍스트가 실제 상담사의 발언들과 어떻게 비교되는지 살표보고자 본 논문을 선정하였다.

### **내용 요약**

본 연구에서는 실제 상담 대화와 general LLM이 생성한 답변, knowledge base integrated LLM이 생성한 답변 세 가지를 비교하였다. Knowledge base integrated LLM를 만들기 위해 연구자들은 Retrieval Augmented Generation(RAG) process를 통해 LLM들이 CBT 관련 지식을 활용할 수 있도록 했다. 그 결과, knowledge base integrated LLM 조건의 ChatGPT가 가장 실제 상담 대화와 유사한 것으로 나타났지만, 평가지표들을 살펴보았을 때 여전히 실제 상담에 미치지는 못한다는 것을 확인할 수 있다.

### **한계점(선택)**

연구에서 비교군으로 사용된 상담 대화의 수와 inegrate된 CBT 관련 지식이 부족했을 수 있다는 한계점을 지닌다.

### **의의**

본 연구의 결과는 추후 챗봇이 효과적으로 상담을 제공하게될 수 있다는 가능성을 제시한다. 이것이 실현되기 위해서는 LLM의 더욱 구체적인 조작과 수반되는 윤리적 문제들을 검토할 필요가 있다.

### **참고 문헌**

Shen, H., Li, Z., Yang, M., Ni, M., Tao, Y., Yu, Z., ... & Hu, B. (2024, December). Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?. In 2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM) (pp. 3695-3700). IEEE.



# Topic 3: Language measures correlate with other measures used to study emotion [SA]

### **선정 이유**
언어 자료를 분석하는 것이 실제 작성자의 감정을 제대로 반영하고 있는지, 현재 기술력 및 분석방법은 문장에 내재된 작성자의 감정을 제대로 포착할 수 있는지 궁금해 읽어보았다.

### **내용 요약**
대상자의 감정을 측정하는 방법에는 1) self-report, 2) observer report, 3) facial cues, 4) vocal cues 등이 있다. 이 연구에서는 3개의 데이터셋을 바탕으로 언어를 사용한 감정 측정과 그 외 감정 측정 결과의 관계와 언어 측정 방법들 간의 관계(LIWC-22, Lexical Suite, NRC, VADER, ANEW)를 확인하고자 한다. (observer report는 1번 데이터셋, vocal cue, facial cue는 오직 2,3번 데이터셋에서만 얻을 수 있었음)

** 데이터셋 정보
1) social rejector narratives(사회적 거부 경험의 자기보고식 작성 데이터셋)
2) SEND narratives (긍정, 부정 경험 3개씩 자기보고식 영상 데이터셋)
3) CONDOR conversations (초면인 사람과 상호작용하는 영상 데이터셋)
5-6문장 내외 (가설, 결과, 방법론 위주)

결과: 
언어를 통해 측정한 valence와 discrete emotion이 자기보고식 데이터셋(1,2)의 self-report와 유의하게 연관됨을 확인했다. observer report와도 유의하게 연관되어 있었으나 상호작용 데이터셋(3)에서는 유의하게 연관되지 않았다.
facial cue와 언어를 통해 측정한 valence는 유의하게 연관되었으나, discrete emotion은 연관되지 않음을 확인했다. vocal cue에서는 vocal pitch나 intensity와 valence 간의 유의미한 상관이 있는 것으로 드러났으나, 일관되지 않은 결과를 보였다. 
언어를 통해 측정한 valence와 discrete emotion 정보는 self-reported dataset이나 observer report와도 유의하게 연관되나, facial cue나 vocal cue와는 약하게 연관되며 일관성이 없는 것으로 드러났다. 

### **한계점(선택)**
문화적 차이가 있을 수도 있다.

### **의의**
최근 여러 연구들에서 감정인식 (emotion recognition) 관련 연구를 진핻하고 있는데, 데이터 지표 (영상/언어/소리 등)를 선택 및 분석할 때 측정의 정확성과 다른 지표들과의 연관성을 고려해야 할 것 같다.

### **참고 문헌**
Munin, S., Ong, D. C., Okland, S., Freedman, G., & Beer, J. S. (2025). Language measures correlate with other measures used to study emotion. Communications Psychology, 3(1), 29.




# Topic 4: Using Immersive Virtual Reality to Enhance Social Interaction Among Older Adults: A Cross-Site Investigation [JL]
## Topics: VR, Social Presence

### **선정 이유**

본래 관심 있었던 박물관/미술관을 배경으로 하여, VR을 사용하여 사회적 상호작용에 대해 알아본 점이 흥미로워서 선정하게 되었다. 또한, 대부분 젊은 세대를 중심으로 VR 연구가 이뤄져왔는데(해당 논문에서 언급된 내용), 고령층을 대상으로 VR 연구를 진행하여 추후 VR 기기의 이용 나이대를 확장시킬 수 있는 연구라고 생각하였다.
  
### **내용 요약**

고령층 사이에서 상호 대화와 협력적 문제 해결(collaborative problem solving)이 이뤄질 수 있도록 연구자들이 social VR을 디자인하였다. 해당 제목에 나타난 것처럼 본 연구는 cross-site로 진행되었으며, 총 3개 지역에서 36명의 고령층 참가자를 모집하였다. 전반적으로 social VR에 대한 반응은 긍정적으로 나타났다. 높은 수준의 참여도를 보였으며, Social VR이 enjoyable, usable하다고 답변하였다.

### **한계점(선택)**

Cognitive Impairment 가진 참가자들 분석할 때, 구조방정식 모형으로 변수 간 영향 분석할 때 참가자 수가 충분하지 않다는 한계가 있다. 그리고 VR을 사용함으로써 나타나는 유의미한 mood, attitude 변화가 적었다 (논문에서는 이미 VR 기술에 친숙하면 유의미한 변화가 안 나타났을 수도 있다고 언급). 추후 연구에서는 이를 극복하기 위해 더 생생한 아바타 캐릭터, 보다 쉽게 조작 가능한 컨트롤러, 훈련을 통한 친숙화 등이 필요하다고 언급되었다.

### **의의**

고령층에서도 Social VR을 사용해서 사회적 상호작용에 적극적으로 참여할 수 있음을 보임. 또한 앞으로 어떤 사회적 측면이 VR의 사용 경험에 영향을 줄 수 있을지 더 탐구해볼 수 있을 것으로 기대.

### **참고자료**

https://create-center.org/research/projects/project-1/

### **참고 문헌**

Kalantari, S., Xu, T. B., Mostafavi, A., Kim, B., Dilanchian, A., Lee, A., ... & Czaja, S. J. (2023). Using immersive virtual reality to enhance social interaction among older adults: A cross-site investigation. Innovation in aging, 7(4), igad031.
