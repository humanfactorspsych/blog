---
layout: post
title: "Feb 28th Journal Club"
author: "Seonu An (seonuan82@gmail.com)"
---

Presenters: SL(Sunghyun Lee), GP(Geuntae Park) <br>

-----------------


# Topic 1: Enhancing social functioning using multi-user, immersive virtual reality [SL]

### **선정 이유**

VR 등의 몰입경험을 활용한 심리 치료의 가능성을 다룬 연구들은 많은데, 여러 유저들을 접속시켜 집단상담을 진행한 연구는 처음 접하게 되어서 흥미가 갔다. 특히 여러 회차의 상담을 실시하는 과정에서 다수의 참여자들에게 VR 기기를 제공하여 사용법을 교육시키고, 기기를 관리하는 등의 실험 절차가 어떻게 진행되었는지 상세히 제시되어 있어서, VR을 이용한 실험을 실질적으로 구현하는 데 유익한 선행연구가 될 것 같아서 선정하게 되었다.

### **내용 요약**

전 세계적으로 고립감과 사회적 단절이 증가하는 상황에서, 연구자들은 이러한 문제를 해결하기 위한 새로운 방법으로 multi-user VR을 활용한 몰입 환경에서의 집단상담을 제안하였다. 연구에는 사회적 불편감을 겪는다고 보고한 성인 33명이 참여하였다. 이들은 ’ROOM(Reconnecting with Ourselves and Others in virtual Meetings)’이라는 VR 기반 애플리케이션을 통해 이전에 검증된 마음챙김 기반 상담기법에 참여하였다. 참가자들은 세션의 절반 이상에 참석했으며, 90.3%가 ROOM이 유익하다고 평가하였다. 또한 현실 세계에서 타인과의 편안함(p = 0.02)과 얼굴 감정 인식 정확도(p = 0.02)가 유의미하게 향상되었으며, 대인 간 거리감에는 유의한 차이가 나타나지 않았다. 이러한 결과는 multi-user VR 개입이 사회적 기능과 연결성을 향상시키는 데 효과적일 수 있음을 시사한다.

### **한계점(선택)**

표본의 크기가 작으며, 비교집단이 없는 단일 집단으로 설계된 실험이어서 개입의 효과를 명확히 단정짓기 어렵다. 따라서 VR 개입만의 효과와 차별점을 측정하는 후속 연구가 제안될 수 있다.

### **의의**

몰입형 VR 기술이 사회적 연결과 기능 향상에 실제로 활용될 수 있음을 보여주는 근거를 제공하는 연구이다. 특히 사회적 불편감을 가진 사람들에게 다른 사람들과 직접 대면하지 않고도 상호작용할 수 있는 새로운 디지털 기반 상담 개입의 가능성을 제시했다는 점에서 의의가 있다.

### **참고 문헌**

Holt, D. J., DeTore, N. R., Aideyan, B., Utter, L., Vinke, L., Johnson, D. S., ... & Burke, A. (2025). Enhancing social functioning using multi-user, immersive virtual reality. Scientific Reports, 15(1), 2790.



# Topic 2: What large language models know and what people think they know [GP]

### **선정 이유**

이 논문은 LLM이 인식하고 표현하는 정보와 인간이 그 정보를 어떻게 해석하는지에 대한 차이를 분석한다. 이를 통해 LLM이 생성하는 설명의 신뢰도와 인간의 판단 간의 불일치를 탐구하고 있다는 점에서, AI 모델의 사회적 이해 및 신뢰성 문제에 중요한 학문적 시사점을 제공한다.

### **내용 요약**

본 논문에서는 LLM이 생성하는 설명에 대한 인간의 신뢰와 모델의 실제 신뢰도 사이의 차이를 분석하였다. 구체적으로, 실험 1에서는 기본적인 설명 방식을, 실험 2에서는 신뢰도(낮음, 중간, 높음)와 길이(짧음, 김)에 따른 설명 방식을, 실험 3에서는 다양한 프롬프트를 활용하여 신뢰도 표현 방식을 실험하였다.
실험 결과:
기본적인 설명 방식에서는 인간이 모델의 설명을 지나치게 신뢰하는 경향이 나타났다.
신뢰도를 조정한 설명에서는 인간의 신뢰도가 일부 개선되었으나, 사용자들은 여전히 과신하는 경향이 나타났다.
프롬프트를 통한 신뢰도 조절 실험에서는 모델의 신뢰도 표현이 인간의 신뢰도 판단에 미치는 영향을 다르게 나타냈으며, 특히 모델 설명의 불확실성을 명시할 경우 인간의 신뢰도가 낮아졌다.
논문은 이러한 결과를 바탕으로, 모델 설명의 신뢰도 조절이 인간-모델 상호작용에서 중요한 역할을 한다고 주장한다.

### **의의**

이 논문은 LLM의 설명이 인간의 판단에 미치는 영향을 실험적으로 검증하고 신뢰도 표현 방식이 사람들의 이해에 미치는 차이를 분석함.
AI 모델의 사회적 수용과 신뢰 형성에 중요한 학문적 근거를 제시함.

### **참고문헌**

Steyvers, M., Tejeda, H., Kumar, A., Belem, C., Karny, S., Hu, X., Mayer, L. W., & Smyth, P. (2025). What large language models know and what people think they know. Nature Machine Intelligence, 7(2), 221–231. https://doi.org/10.1038/s42256-024-00976-7