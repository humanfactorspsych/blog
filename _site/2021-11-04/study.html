<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Nov 4th Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Nov 4th Journal Club" />
<meta name="author" content="Jae Eun Park (dawn2089@snu.ac.kr)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: Empathy, Motivated Account, Nonverbal Vocal Cues, VUI Presenters: IL (Inju Lee), HM (Hoyoung Maeng) Topic 1: Empathy: A Motivated Account [IL] 선정 이유 감정 일기 데이터를 어떻게 분석할지 관련 레퍼런스들을 찾아보다 선정하게 되었음 내용 요약 공감은 무의식 수준에서 자동적으로 발생하기도 하고, 때론 맥락적 요소의 영향을 받으며 발생하기도 한다. 본 논문은 이러한 상반된 두 가지 공감 발생 과정을 공감의 동기적 요소를 통해 설명하였다. 개인이 타인에 대해 공감을 할 때 진화적으로 생존할 가능성이 높아졌기 때문에 개인은 타인에 대해 공감하고자 하는 동기를 지니고 있다. Information processing 및 emotion regulation 이론을 통해 개인의 동기가 공감에 영향을 줄 수 있다는 것을 확인할 수 있다. 이를 바탕으로 저자는 개인의 동기가 공감에 영향을 주는 메커니즘으로 3가지 empathic regulatory stratigies를 정리하였다: (1) situation selection, (2) attention modulation, (3) appraisal 공감을 유발하는 대표적인 3가지 동기는 positive affect, affiliation, social desirability이며, 공감을 억제하는 대표적인 3가지 동기는 suffering, material costs, interference with competition이다. 이를 통해 6 (motive) X 3 (strategy) 의 18개 케이스가 생기며, 저자는 각 케이스를 뒷받침하는 연구 결과를 본 논문에 체계적으로 정리해두었다. 공감의 동기적 모델은 (1) 이론적 측면, (2) 정신 장애에 대한 이해 및 치료의 측면, (3) 공감을 높이는 개입의 측면에서 각각 함의를 지닌다. (1)번 측면과 관련하여 동기적 모델은 공감과 관련된 기존 연구 결과를 개인의 동기 측면에서 해석해봄으로써 공감에 대한 폭넓은 이해 및 다양한 연구 가능성을 열어주었다. 또한 공감의 (dis)utility (잘못된 도덕 판단 및 행동) 를 해결할 수 있는 방안으로 공감의 동기적 측면을 제안하였다. 또한 (2)번 측면과 관련하여 동기적 모델은 자폐 스펙트럼 장애와 사이코페스를 타인의 상태를 고려하고자 하는 동기가 결함된 상태로 새로운 시각을 제시하였다. 마지막으로 (3)번 측면으로 동기적 모델은 개인의 공감을 높이는 방안으로써 동기적 측면에 대한 개입을 제안하였다. 장점 및 의의 공감의 동기적 측면과 그 과정을 설명하는 메커니즘을 새롭게 제안하였다. 또한 이를 뒷받침하는 연구 결과들을 체계적으로 정리해두었다. 단점 공감을 유발하고 억제하는 대표적인 6가지 동기를 선정한 과정 및 근거가 논문에 나와있지 않아 아쉽다. 참고 문헌 Zaki, J. (2014). Empathy: A motivated account. Psychological Bulletin, 140(6), 1608–1647. https://doi.org/10.1037/a0037679 Topic 2: Effects of Nonverbal Vocal Cues in Voice User Interface [HM] 선정 이유 비언어적 요소를 사용하는 AI agent에서 목소리의 영향을 탐색하는 연구를 살펴보고 싶었음 내용 요약 비언어적 요소를 사용하는 AI 스피커에 대하여 5가지 척도(intimacy, similarity, connectedness, enjoyment, and ease of use)를 측정한 실험 연구다. 실험 참여자는 brain trying task를 실시하였으며, 3가지 세션을 나누어 각각 10개, 12개, 14개 단어를 듣고 기억해내는 실험을 실시하였다. 이때 각 세션이 종료된 후 AI 스피커는 실험 참여자에 대한 피드백을 주었으며 no empathy, low empathy, high empathy 방법으로 피드백이 구분되었다. 실험결과 AI스피커가 high empathy 피드백을 실험참여자들에게 주었을때 위 5가지 척도 모두 가장 높게 나옴을 확인 할 수 있었다. 장단점 공감하는 피드백과 공감하지 않는 피드백을 분류한 실험으로서 AI스피거가 공감하는 피드백을 줄때 인간의 태도의 변화를 확인할 수 있어서 공감하는 목소리에 대한 중요성을 확인 할 수 있었다. AI 스피커가 실험참여자들에 답변에 대한 피드백을 줄때 어떠한 비언어적 요소를 사용했는지 더 자세히 나왔으면 하는 아쉬움이 있었다. 의의 인간의 대화방법을 모방하여 AI agent가 비언어적 요소를 사용하는 것이, AI agent에 대한 인간의 인식에 도움을 줄 수 있음을 확인 할 수 있었다. 참고 문헌 Kim, J., Kim, W., Nam, J., &amp; Song, H. (2020). “i can feel your empathic voice”: Effects of nonverbal vocal cues in voice user interface. Conference on Human Factors in Computing Systems - Proceedings, 1–8." />
<meta property="og:description" content="Themes: Empathy, Motivated Account, Nonverbal Vocal Cues, VUI Presenters: IL (Inju Lee), HM (Hoyoung Maeng) Topic 1: Empathy: A Motivated Account [IL] 선정 이유 감정 일기 데이터를 어떻게 분석할지 관련 레퍼런스들을 찾아보다 선정하게 되었음 내용 요약 공감은 무의식 수준에서 자동적으로 발생하기도 하고, 때론 맥락적 요소의 영향을 받으며 발생하기도 한다. 본 논문은 이러한 상반된 두 가지 공감 발생 과정을 공감의 동기적 요소를 통해 설명하였다. 개인이 타인에 대해 공감을 할 때 진화적으로 생존할 가능성이 높아졌기 때문에 개인은 타인에 대해 공감하고자 하는 동기를 지니고 있다. Information processing 및 emotion regulation 이론을 통해 개인의 동기가 공감에 영향을 줄 수 있다는 것을 확인할 수 있다. 이를 바탕으로 저자는 개인의 동기가 공감에 영향을 주는 메커니즘으로 3가지 empathic regulatory stratigies를 정리하였다: (1) situation selection, (2) attention modulation, (3) appraisal 공감을 유발하는 대표적인 3가지 동기는 positive affect, affiliation, social desirability이며, 공감을 억제하는 대표적인 3가지 동기는 suffering, material costs, interference with competition이다. 이를 통해 6 (motive) X 3 (strategy) 의 18개 케이스가 생기며, 저자는 각 케이스를 뒷받침하는 연구 결과를 본 논문에 체계적으로 정리해두었다. 공감의 동기적 모델은 (1) 이론적 측면, (2) 정신 장애에 대한 이해 및 치료의 측면, (3) 공감을 높이는 개입의 측면에서 각각 함의를 지닌다. (1)번 측면과 관련하여 동기적 모델은 공감과 관련된 기존 연구 결과를 개인의 동기 측면에서 해석해봄으로써 공감에 대한 폭넓은 이해 및 다양한 연구 가능성을 열어주었다. 또한 공감의 (dis)utility (잘못된 도덕 판단 및 행동) 를 해결할 수 있는 방안으로 공감의 동기적 측면을 제안하였다. 또한 (2)번 측면과 관련하여 동기적 모델은 자폐 스펙트럼 장애와 사이코페스를 타인의 상태를 고려하고자 하는 동기가 결함된 상태로 새로운 시각을 제시하였다. 마지막으로 (3)번 측면으로 동기적 모델은 개인의 공감을 높이는 방안으로써 동기적 측면에 대한 개입을 제안하였다. 장점 및 의의 공감의 동기적 측면과 그 과정을 설명하는 메커니즘을 새롭게 제안하였다. 또한 이를 뒷받침하는 연구 결과들을 체계적으로 정리해두었다. 단점 공감을 유발하고 억제하는 대표적인 6가지 동기를 선정한 과정 및 근거가 논문에 나와있지 않아 아쉽다. 참고 문헌 Zaki, J. (2014). Empathy: A motivated account. Psychological Bulletin, 140(6), 1608–1647. https://doi.org/10.1037/a0037679 Topic 2: Effects of Nonverbal Vocal Cues in Voice User Interface [HM] 선정 이유 비언어적 요소를 사용하는 AI agent에서 목소리의 영향을 탐색하는 연구를 살펴보고 싶었음 내용 요약 비언어적 요소를 사용하는 AI 스피커에 대하여 5가지 척도(intimacy, similarity, connectedness, enjoyment, and ease of use)를 측정한 실험 연구다. 실험 참여자는 brain trying task를 실시하였으며, 3가지 세션을 나누어 각각 10개, 12개, 14개 단어를 듣고 기억해내는 실험을 실시하였다. 이때 각 세션이 종료된 후 AI 스피커는 실험 참여자에 대한 피드백을 주었으며 no empathy, low empathy, high empathy 방법으로 피드백이 구분되었다. 실험결과 AI스피커가 high empathy 피드백을 실험참여자들에게 주었을때 위 5가지 척도 모두 가장 높게 나옴을 확인 할 수 있었다. 장단점 공감하는 피드백과 공감하지 않는 피드백을 분류한 실험으로서 AI스피거가 공감하는 피드백을 줄때 인간의 태도의 변화를 확인할 수 있어서 공감하는 목소리에 대한 중요성을 확인 할 수 있었다. AI 스피커가 실험참여자들에 답변에 대한 피드백을 줄때 어떠한 비언어적 요소를 사용했는지 더 자세히 나왔으면 하는 아쉬움이 있었다. 의의 인간의 대화방법을 모방하여 AI agent가 비언어적 요소를 사용하는 것이, AI agent에 대한 인간의 인식에 도움을 줄 수 있음을 확인 할 수 있었다. 참고 문헌 Kim, J., Kim, W., Nam, J., &amp; Song, H. (2020). “i can feel your empathic voice”: Effects of nonverbal vocal cues in voice user interface. Conference on Human Factors in Computing Systems - Proceedings, 1–8." />
<link rel="canonical" href="http://localhost:4000/blog/2021-11-04/study" />
<meta property="og:url" content="http://localhost:4000/blog/2021-11-04/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-04T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Nov 4th Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jae Eun Park (dawn2089@snu.ac.kr)"},"dateModified":"2021-11-04T00:00:00+09:00","datePublished":"2021-11-04T00:00:00+09:00","description":"Themes: Empathy, Motivated Account, Nonverbal Vocal Cues, VUI Presenters: IL (Inju Lee), HM (Hoyoung Maeng) Topic 1: Empathy: A Motivated Account [IL] 선정 이유 감정 일기 데이터를 어떻게 분석할지 관련 레퍼런스들을 찾아보다 선정하게 되었음 내용 요약 공감은 무의식 수준에서 자동적으로 발생하기도 하고, 때론 맥락적 요소의 영향을 받으며 발생하기도 한다. 본 논문은 이러한 상반된 두 가지 공감 발생 과정을 공감의 동기적 요소를 통해 설명하였다. 개인이 타인에 대해 공감을 할 때 진화적으로 생존할 가능성이 높아졌기 때문에 개인은 타인에 대해 공감하고자 하는 동기를 지니고 있다. Information processing 및 emotion regulation 이론을 통해 개인의 동기가 공감에 영향을 줄 수 있다는 것을 확인할 수 있다. 이를 바탕으로 저자는 개인의 동기가 공감에 영향을 주는 메커니즘으로 3가지 empathic regulatory stratigies를 정리하였다: (1) situation selection, (2) attention modulation, (3) appraisal 공감을 유발하는 대표적인 3가지 동기는 positive affect, affiliation, social desirability이며, 공감을 억제하는 대표적인 3가지 동기는 suffering, material costs, interference with competition이다. 이를 통해 6 (motive) X 3 (strategy) 의 18개 케이스가 생기며, 저자는 각 케이스를 뒷받침하는 연구 결과를 본 논문에 체계적으로 정리해두었다. 공감의 동기적 모델은 (1) 이론적 측면, (2) 정신 장애에 대한 이해 및 치료의 측면, (3) 공감을 높이는 개입의 측면에서 각각 함의를 지닌다. (1)번 측면과 관련하여 동기적 모델은 공감과 관련된 기존 연구 결과를 개인의 동기 측면에서 해석해봄으로써 공감에 대한 폭넓은 이해 및 다양한 연구 가능성을 열어주었다. 또한 공감의 (dis)utility (잘못된 도덕 판단 및 행동) 를 해결할 수 있는 방안으로 공감의 동기적 측면을 제안하였다. 또한 (2)번 측면과 관련하여 동기적 모델은 자폐 스펙트럼 장애와 사이코페스를 타인의 상태를 고려하고자 하는 동기가 결함된 상태로 새로운 시각을 제시하였다. 마지막으로 (3)번 측면으로 동기적 모델은 개인의 공감을 높이는 방안으로써 동기적 측면에 대한 개입을 제안하였다. 장점 및 의의 공감의 동기적 측면과 그 과정을 설명하는 메커니즘을 새롭게 제안하였다. 또한 이를 뒷받침하는 연구 결과들을 체계적으로 정리해두었다. 단점 공감을 유발하고 억제하는 대표적인 6가지 동기를 선정한 과정 및 근거가 논문에 나와있지 않아 아쉽다. 참고 문헌 Zaki, J. (2014). Empathy: A motivated account. Psychological Bulletin, 140(6), 1608–1647. https://doi.org/10.1037/a0037679 Topic 2: Effects of Nonverbal Vocal Cues in Voice User Interface [HM] 선정 이유 비언어적 요소를 사용하는 AI agent에서 목소리의 영향을 탐색하는 연구를 살펴보고 싶었음 내용 요약 비언어적 요소를 사용하는 AI 스피커에 대하여 5가지 척도(intimacy, similarity, connectedness, enjoyment, and ease of use)를 측정한 실험 연구다. 실험 참여자는 brain trying task를 실시하였으며, 3가지 세션을 나누어 각각 10개, 12개, 14개 단어를 듣고 기억해내는 실험을 실시하였다. 이때 각 세션이 종료된 후 AI 스피커는 실험 참여자에 대한 피드백을 주었으며 no empathy, low empathy, high empathy 방법으로 피드백이 구분되었다. 실험결과 AI스피커가 high empathy 피드백을 실험참여자들에게 주었을때 위 5가지 척도 모두 가장 높게 나옴을 확인 할 수 있었다. 장단점 공감하는 피드백과 공감하지 않는 피드백을 분류한 실험으로서 AI스피거가 공감하는 피드백을 줄때 인간의 태도의 변화를 확인할 수 있어서 공감하는 목소리에 대한 중요성을 확인 할 수 있었다. AI 스피커가 실험참여자들에 답변에 대한 피드백을 줄때 어떠한 비언어적 요소를 사용했는지 더 자세히 나왔으면 하는 아쉬움이 있었다. 의의 인간의 대화방법을 모방하여 AI agent가 비언어적 요소를 사용하는 것이, AI agent에 대한 인간의 인식에 도움을 줄 수 있음을 확인 할 수 있었다. 참고 문헌 Kim, J., Kim, W., Nam, J., &amp; Song, H. (2020). “i can feel your empathic voice”: Effects of nonverbal vocal cues in voice user interface. Conference on Human Factors in Computing Systems - Proceedings, 1–8.","headline":"Nov 4th Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2021-11-04/study"},"url":"http://localhost:4000/blog/2021-11-04/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Jae Eun Park (dawn2089@snu.ac.kr)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2021-11-04 00:00:00 +0900">November 04, 2021</time>
    
  </div>

  <h1 class="post-title">Nov 4th Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: Empathy, Motivated Account, Nonverbal Vocal Cues, VUI
</code></pre></div></div>

<p>Presenters: IL (Inju Lee), HM (Hoyoung Maeng)  <br /></p>

<hr />

<h1 id="topic-1-empathy-a-motivated-account-il">Topic 1: Empathy: A Motivated Account [IL]</h1>

<h3 id="선정-이유"><strong>선정 이유</strong></h3>

<p>감정 일기 데이터를 어떻게 분석할지 관련 레퍼런스들을 찾아보다 선정하게 되었음</p>

<h3 id="내용-요약"><strong>내용 요약</strong></h3>

<p>공감은 무의식 수준에서 자동적으로 발생하기도 하고, 때론 맥락적 요소의 영향을 받으며 발생하기도 한다. 본 논문은 이러한 상반된 두 가지 공감 발생 과정을 공감의 동기적 요소를 통해 설명하였다.</p>

<p>개인이 타인에 대해 공감을 할 때 진화적으로 생존할 가능성이 높아졌기 때문에 개인은 타인에 대해 공감하고자 하는 동기를 지니고 있다. Information processing 및 emotion regulation 이론을 통해 개인의 동기가 공감에 영향을 줄 수 있다는 것을 확인할 수 있다. 이를 바탕으로 저자는 개인의 동기가 공감에 영향을 주는 메커니즘으로 3가지 empathic regulatory stratigies를 정리하였다: (1) situation selection, (2) attention modulation, (3) appraisal</p>

<p>공감을 유발하는 대표적인 3가지 동기는 positive affect, affiliation, social desirability이며, 공감을 억제하는 대표적인 3가지 동기는 suffering, material costs, interference with competition이다. 이를 통해 6 (motive) X 3 (strategy) 의 18개 케이스가 생기며, 저자는 각 케이스를 뒷받침하는 연구 결과를 본 논문에 체계적으로 정리해두었다.</p>

<p>공감의 동기적 모델은 (1) 이론적 측면, (2) 정신 장애에 대한 이해 및 치료의 측면, (3) 공감을 높이는 개입의 측면에서 각각 함의를 지닌다. (1)번 측면과 관련하여 동기적 모델은 공감과 관련된 기존 연구 결과를 개인의 동기 측면에서 해석해봄으로써 공감에 대한 폭넓은 이해 및 다양한 연구 가능성을 열어주었다. 또한 공감의 (dis)utility (잘못된 도덕 판단 및 행동) 를 해결할 수 있는 방안으로 공감의 동기적 측면을 제안하였다. 또한 (2)번 측면과 관련하여 동기적 모델은 자폐 스펙트럼 장애와 사이코페스를 타인의 상태를 고려하고자 하는 동기가 결함된 상태로 새로운 시각을 제시하였다. 마지막으로 (3)번 측면으로 동기적 모델은 개인의 공감을 높이는 방안으로써 동기적 측면에 대한 개입을 제안하였다.</p>

<h3 id="장점-및-의의"><strong>장점 및 의의</strong></h3>

<p>공감의 동기적 측면과 그 과정을 설명하는 메커니즘을 새롭게 제안하였다. 또한 이를 뒷받침하는 연구 결과들을 체계적으로 정리해두었다.</p>

<h3 id="단점"><strong>단점</strong></h3>

<p>공감을 유발하고 억제하는 대표적인 6가지 동기를 선정한 과정 및 근거가 논문에 나와있지 않아 아쉽다.</p>

<h3 id="참고-문헌"><strong>참고 문헌</strong></h3>

<ul>
  <li>Zaki, J. (2014). Empathy: A motivated account. Psychological Bulletin, 140(6), 1608–1647. https://doi.org/10.1037/a0037679</li>
</ul>

<h1 id="topic-2-effects-of-nonverbal-vocal-cues-in-voice-user-interface-hm">Topic 2: Effects of Nonverbal Vocal Cues in Voice User Interface [HM]</h1>

<h3 id="선정-이유-1"><strong>선정 이유</strong></h3>

<p>비언어적 요소를 사용하는 AI agent에서 목소리의 영향을 탐색하는 연구를 살펴보고 싶었음</p>

<h3 id="내용-요약-1"><strong>내용 요약</strong></h3>

<p>비언어적 요소를 사용하는 AI 스피커에 대하여 5가지 척도(intimacy, similarity, connectedness, enjoyment, and ease of use)를 측정한 실험 연구다. 실험 참여자는 brain trying task를 실시하였으며, 3가지 세션을 나누어 각각 10개, 12개, 14개 단어를 듣고 기억해내는 실험을 실시하였다. 이때 각 세션이 종료된 후 AI 스피커는 실험 참여자에 대한 피드백을 주었으며 no empathy, low empathy, high empathy 방법으로 피드백이 구분되었다.
실험결과 AI스피커가 high empathy 피드백을 실험참여자들에게 주었을때 위 5가지 척도 모두 가장 높게 나옴을 확인 할 수 있었다.</p>

<h3 id="장단점"><strong>장단점</strong></h3>

<p>공감하는 피드백과 공감하지 않는 피드백을 분류한 실험으로서 AI스피거가 공감하는 피드백을 줄때 인간의 태도의 변화를 확인할 수 있어서 공감하는 목소리에 대한 중요성을 확인 할 수 있었다. 
AI 스피커가 실험참여자들에 답변에 대한 피드백을 줄때 어떠한 비언어적 요소를 사용했는지 더 자세히 나왔으면 하는 아쉬움이 있었다.</p>

<h3 id="의의"><strong>의의</strong></h3>

<p>인간의 대화방법을 모방하여 AI agent가 비언어적 요소를 사용하는 것이, AI agent에 대한  인간의 인식에 도움을 줄 수 있음을 확인 할 수 있었다.</p>

<h3 id="참고-문헌-1"><strong>참고 문헌</strong></h3>

<ul>
  <li>Kim, J., Kim, W., Nam, J., &amp; Song, H. (2020). “i can feel your empathic voice”: Effects of nonverbal vocal cues in voice user interface. Conference on Human Factors in Computing Systems - Proceedings, 1–8.</li>
</ul>


</div>

<div class="pagination">
  
    <a href="/blog/2021-11-11/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2021-10-28/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
