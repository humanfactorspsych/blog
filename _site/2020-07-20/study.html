<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>July 20th Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="July 20th Journal Club" />
<meta name="author" content="Soomin Cho (soominc3@illinois.edu)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: DeepRL, BERT, Inverse Reinforcement Learning, Distributed Semantic Representation, Human Judgment, Name Entity Recognition (NER), Past Expectation, Trust in Online Social Groups, AI" />
<meta property="og:description" content="Themes: DeepRL, BERT, Inverse Reinforcement Learning, Distributed Semantic Representation, Human Judgment, Name Entity Recognition (NER), Past Expectation, Trust in Online Social Groups, AI" />
<link rel="canonical" href="http://localhost:4000/blog/2020-07-20/study" />
<meta property="og:url" content="http://localhost:4000/blog/2020-07-20/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-20T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="July 20th Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Soomin Cho (soominc3@illinois.edu)"},"dateModified":"2020-07-20T00:00:00+09:00","datePublished":"2020-07-20T00:00:00+09:00","description":"Themes: DeepRL, BERT, Inverse Reinforcement Learning, Distributed Semantic Representation, Human Judgment, Name Entity Recognition (NER), Past Expectation, Trust in Online Social Groups, AI","headline":"July 20th Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2020-07-20/study"},"url":"http://localhost:4000/blog/2020-07-20/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Soomin Cho (soominc3@illinois.edu)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-07-20 00:00:00 +0900">July 20, 2020</time>
    
  </div>

  <h1 class="post-title">July 20th Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: DeepRL, BERT, Inverse Reinforcement Learning, Distributed Semantic Representation, Human Judgment, Name Entity Recognition (NER), Past Expectation, Trust in Online Social Groups, AI 
</code></pre></div></div>

<p>Presenters: YK (Yoon Kyung Lee), YW (Yoonwon Jung), JE (Jaeun Park), IJ (Inju Lee), HY (Hoyoung Maeng), WK (Whani Kim), SC (Soomin Cho) <br />
Guest : HeeYoung Park (Psychometrics Lab)</p>

<hr />

<h2 id="topic-1-training-deeprl-agent-with-bert-yk">Topic 1: Training DeepRL Agent with BERT [YK]</h2>

<p>선정 이유: 자연어 기반 로봇과 상호작용에 있어서 좀 더 advanced된 방법은 강화 학습을 적용하는 것이다. 예를 들어, 소셜 로봇에게 슬퍼하고 있는 사용자에게 위로의 한 마디를 10개 템플렛을 정해서 계획된 행동과 말을 하게 할 순 있지만, 반대로 사람이 보상을 기반으로 학습을 하는 것처럼 로봇도 스스로 학습하게 할 수 있다. 즉, 위로의 한 마디를 던지고서 높은 보상을 얻었다면 (예: 보상 = 사용자가 위로를 받고서 고마워함) 다른 위로의 표현을 더 탐색하는 등, ‘스스로’ 다른 방법을 찾게 할 수 있다. 강화 학습 이론을 적용해서 로봇이 스스로 ‘잘’ 학습하게 설계할 수 있는 방법 중에는 자연어를 기반으로 피드백을 주는 방법이 있다. 이번에 리뷰한 논문은 자연어 모델 기반 강화학습을 다루었기에 선정했다. 지난 시간에 리뷰했던 논문의 저자인 Felix Hill (DeepMind)의 다른 논문 중 하나이기도 하다. <br /></p>

<p>내용 요약: 강화학습에 자연어 기반 질문과 피드백을 사용해서 에이젼트가 화자의 의도를 잘 파악하는지 알아보았다. 학습 환경은 3D 가상 환경이었고, 공개된 ShapeNet dataset(Chang et al., 2015)의 일부를 활용하였다. 강력한 언어 모형은 제로샷 테스트에서도 더 좋은 정책(policy)를 만들게 함으로써 좋은 성능을 보였다. 에이젼트는 사물 인식 과제와 사물의 관계 그리고 제어 과제를 실행했다. 과제는 자연어 기반 지시를 주면 이에 맞게 에이젼트가 맞는 행동을 했는지 평가했다. 예를 들어 ‘put the cup on the table’형태의 지시가 주어지면 에이젼트가 cup을 찾은 후, 1m 이상 들어올린 다음, 이 행동을 5번 반복하면 보상을 얻었다. 시뮬레이터 환경에 쓰인 사물은 ShapeNet 데이터셋(Chang 2015)을 사용했다. 자연어 기반 학습 네트워크는 BERT + mean pool, BERT + self-attention later, 그리고 BERT + cross-modal self attention 모형을 사용하고 그 성능을 비교했다. 그 결과, BERT를 쓰지 않았을 경우, Word Embeddings + Transformer를 쓴 경우가, BERT를 썼을 경우 BERT + mean pool이 가장 높았으나, typo noise가 들어갔을 땐 WordPiece encoding 모델을 쓴 경우 가장 높았다. <br /></p>

<p>의의: BERT 프리트레인된 언어 모델을 딥강화학습 에이젼트를 학습시키는데 적용해서 이후 유사 주제의 연구에도 활용할 수 있음. <br /></p>

<p>장단점: 강화학습 환경에서 에이젼트에게 SHIFTT (Simulation-to-Human Instruction Following via Transfer from Text)를 적용했다. 지시문의 통사적 구조를 통일시킨 후 오직 타겟 단어의 변이만 신경썼다(synonyms). 실제 사람에게 지시문과 평가를 실시한 후 자연스러운 지시문을 사용하였다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hill, F., Mokra, S., Wong, N., &amp; Harley, T. (2020). Human Instruction-Following with Deep Reinforcement Learning via Transfer-Learning from Text. arXiv preprint arXiv:2005.09382.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-2-inverse-reinforcement-learning-theory-of-mind-tom-sc">Topic 2: Inverse Reinforcement Learning, Theory of Mind (ToM) [SC]</h2>

<p>선정이유: 타인의 생각, 감정 상태를 추론하는 능력을 나타내는 심리학 이론 Theory of Mind를 바탕으로 만들어진 역강화학습 (Inverse Reinforcement Learning) 이론이 흥미로워 선정하였다. 강화학습과 역강화학습을 비교하여 역강화학습이 가지는 의의와 장단점을 다루었다는 점에서 새로운 관점을 제공하였기 때문이다. <br /></p>

<p>내용요약 : 강화학습은 타인의 행동을 예측하는 것에 초점을 맞추는 반면 역강화학습은 행동 기저의 인지, 감정 상태를 추론하는 것을 목표로 한다. 이 논문은 역강화학습을 관찰한 행동을 바탕으로 관찰되지 않는 mental-state 와 가치 함수를 추론하는 것이라고 정의한다. 그러나 인간은 누군가의 행동을 이해하려고 할 때 한 가지 설명에만 만족하고 판단하는 것이 아니라 끊임없이 가능성 있는 시나리오를 생각해보기 때문에, 역강화학습에서도 에이전트가 여러가지 상황들이 각자 얼마나 말이 되는지 판단하는 과정이 필요할 것이다. 일반적으로 강화학습은 beliefs → intentions → actions → outcome 의 순환 구조를 보인다. 욕망과 의도가 상호작용함으로써 어떤 행동을 이끌어내고 그 행동의 결과가 다시 신념에 영향을 미친다. 이와 역방향의 순환 구조를 보이는 것이 역강화학습이다. 행동을 관찰함으로써 특정 policy를 이끌어낸 world model (beliefs) 를 재건한다. <br />
그럼에도 불구하고 역강화학습은 네 가지의 대표적인 한계를 가지고 있다. 먼저 역강화학습은 훈련을 하기 위해 많은 양의 예시를 요구하는데, 이는 높은 비용으로 연결된다. 다음으로 새로운 과제와 새 환경에서의 일반화가 잘 이루어지지 않는다. 셋째는 역강화학습에서 인간의 belief representation 을 학습시키는 것이 까다롭다는 점이다. 인간은 상황을 판단할 때 사소하거나 관련 없는 신념들 (지구는 둥글다 등)에는 자동적으로 신경을 쓰지 않는다. 하지만 역강화학습 모델에게는 그 순간에 어떤 신념이 영향을 미치는지 미치지 않는지 판단하는 것이 어렵다. 인간이 그렇게 작동할 수 있는 이유는 기본적으로 타인이 본인과 비슷한 상식, 윤리 의식, 관점 등을 가지고 있으리라 추정하기 때문이다. 그러므로 역강화학습 모델에게도 이러한 프로세스를 적용시키는 것이 필요하다. 마지막 한계는 인간의 desire representations 을 구현하는 것이 까다롭다는 점이다. 인간의 욕망은 다양한 문맥에서 다양한 요인의 영향을 받아 형성되기 때문에 관찰되는 행동만으로는 충분한 정보를 얻을 수 없다. 인간 수준의 mental-state inference를 발달시키기 위해선 역강화학습 모델은 욕망의 시공간적인 구조를 이해할 필요가 있다. <br /></p>

<p>장점: 직관적이고 심플한 figure 를 제시하였고 각 figure 를 충분히 설명하였다. 역강화학습을 Theory of Mind라는 심리학적 컨셉과 연관지어 일목요연한 구조를 유지하여서 많은 배경지식이 없더라도 이해하기 수월하였다. <br /></p>

<p>단점: 역강화학습이 현재까지 지니고 있는 한계를 분석하고 이에 따른 해결 방향을 제시하였지만 더 나아가 구체적으로 어떤 모델을 구축해야 할지는 언급하지 않았다. 한계를 해결하기 위해서는 이 논문이 제시한 방향을 출발점으로 하여 실질적인 향후 연구가 더 필요할 것이다. <br /></p>

<p>의의: 이 논문은 강화학습과 역강화학습의 기본적인 구조 차이를 제시함으로써 두 모델을 명확하게 구분지었고, 역강화학습의 장단점을 분석함으로써 객관적으로 역강화학습의 전반적인 역량을 다루었다. 강화학습과 다른 측면에서의 역강화학습 모델만 다룬 것이 아니라, 관찰된 행동 기저의 미세한 디테일과 차이점에 집중하는 강화학습의 메커니즘에서 벗어날 필요가 있음을 제시하였다. 동일한 신념과 욕망을 가지고 있어도 충분히 다른 결정을 내릴 수 있는 인간 사고의 가변성을 이해함으로써 abstraction과 simplification을 적절하게 이용할 것을 제시하였다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Jara-Ettinger, J. (2019). Theory of mind as inverse reinforcement learning. Current Opinion in Behavioral Sciences, 29, 105-110
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-3-distributed-semantic-representation-human-judgment-ij">Topic 3: Distributed Semantic Representation, Human Judgment [IJ]</h2>

<p>선정 이유: 판단과 관련된 semantic representation을 알아내고 이를 수치화하는 방법이 궁금하여 해당 논문을 읽어보았다. <br /></p>

<p>내용 요약 <br />
사람들이 판단하고 평가하는 방법에 대해 이해하는 것은 행동과학 분야의 핵심적인 목표이다. 판단의 근간이 되는 지식은 특정 사물 및 개념들에 대한 semantic representation을 통해 표현할 수 있으며, semantic representation에 대해 알아내고 수치화하는 새로운 방법으로 ‘Distributional Semantics(DS)’가 떠오르고 있다. 서로 긴밀하게 연관된 단어들은 비슷한 언어적 맥락(linguistic context)에서 사용되며 이러한 관계를 단어의 분포(distribution of words)에 나타냄으로써 단어의 의미와 지식을 표현하는 것이 DS 모델의 핵심적인 아이디어이다. <br />
DS 모델은 사람의 판단 과정을 모방함으로써 특정 개념에 대한 의미적 혹은 언어학적인 판단을 예측하는 데 사용될 수 있다. 하지만 이때 DS 모델이 개념 간의 유사성(similarity)보단 연관성(association)을 포착하는 것으로 보인다는 한계점이 존재한다. DS 모델을 이용하여 더 높은 차원의 판단(e.g., probability judgement, social judgement, inferring differences in high-level judgments across different groups)을 예측하고자 시도한 연구들이 존재하며, 판단 이외에 명확성(concreteness), 정서가(valence)와 같은 단어의 언어심리학적(psycholinguistic) 속성에 대해 DS 모델을 이용하여 예측한 연구들도 존재한다. <br />
앞으로 사람의 판단에 대한 연구들이 나아갈 방향에는 크게 3가지가 존재한다. : (1) 특정 구(phrase)의 단일 단어들 뿐만 아니라 여러 단어들의 구, 문장, 절(paragraph), 문서들의 의미를 DS 모델을 통해 표현하는 방법(compositional distributional semantics)에 대한 연구, (2) DS와 perceptual data를 함께 이용하여 판단을 예측하는 방법에 대한 연구, (3) DS 모델 이외의 다른 접근을 통해 semantic representation을 나타내는 방법에 대한 연구<br /></p>

<p>단점: semantic representation을 이용하여 판단을 예측하는 과정에 대한 내용이 나와있지 않은 점이 아쉽다.<br /></p>

<p>의의: 판단과 관련된 semantic representation에 대한 연구가 어떻게 이루어져 왔는지, 더 나아가 앞으로는 어떠한 방향으로 연구가 이루어져 나가야 하는지에 대해 요약해 놓은 논문이다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Bhatia, S., Richie, R., &amp; Zou, W. (2019). Distributed semantic representations for modeling human judgment. Current opinion in behavioral sciences, 29, 31-36.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-4-neural-network-name-entity-recognitionner-je">Topic 4: Neural Network, Name Entity Recognition(NER) [JE]</h2>

<p>선정 이유: traditional ML과 비교해 neural network의 장점에 대해 공부하기 위해 선정하였다. <br /></p>

<p>내용 요약 <br />
전통적인 ML에서 softmax나 logistic regression을 classifier로 사용하는 classification의 경우, linear decision boundary만 학습이 가능하다는 한계가 있었다. 하지만 neural network를 통해 classification을 할 경우 nonlinear decision boundary를 학습하여 더 복잡한 과제를 수행할 수 있다. Neural network는 intermediate layer가 상호작용항을 계산하는 등 classification 결과가 더 잘 나오도록 vector space를 re-represent하는 역할을 한다. NLP에서 neural network를 사용할 때는 데이터(벡터)가 고정되어 있는 기존의 ML과 달리, 기존 ML에서의 parameter(weight)뿐 아니라 word representation (word vector) 또한 학습한다. 이것을 neural network layer를 하나 더 추가하여 one-hot vector를 word embedding으로 바꾸는 것으로 생각할 수 있다. <br />
Named Entity Recognition(NER)은 neural network를 사용하는 NLP task 중 하나이다. Entity recognition을 할 때 어느 그룹에 속하는지(사람 이름, 회사명 등) 모호할 수 있기 때문에 맥락을 고려해야한다. Entity recognition을 위해 context window를 벡터화하여 신경망에 입력하면 여러 context word의 상호작용을 고려하여 classification을 더 잘 할 수 있다. <br /></p>

<p>의의: 인공신경망을 사용하면 기존의 ML과 달리 non-linear decision boundary를 학습하여 보다 복잡한 classification을 수행할 수 있다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., &amp; Kuksa, P. (2011). Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12, 2493-2537.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-5-reasoning-about-others-emotions-past-expectations-hy">Topic 5: Reasoning about others emotions, past expectations [HY]</h2>

<p>선정 이유: 과거의 기대와 현재의 결과를 통합하여 특정 사람에 대한 감정을 추론하는 측면이 흥미로웠고, 특히 볼링이라는 친숙한 주제를 통해 감정 추론을 풀어나가는 부분이 인상적이였다. <br /></p>

<p>내용 요약: 볼링 경기에서 발생하는, 두가지 경우의 수에서 추론할 수 있는 감정상태에 대해 실험하였다. <br />
실험 1) <br />
a. 볼링공이 직진으로 가다가 아웃방향으로 마지막에 휘어 볼링 핀을 3개만 넘어뜨렸을 경우: 처음에는 기대감을 느끼다가(high expectation) 마지막에 실망감을 느낀다. <br />
b. 볼링공이 아웃이 될뻔하다가 중앙 방향으로 마지막에 휘어 볼링핀을 3개나 넘어뜨렸을 경우: 처음에는 실망감을 느끼다가(low expectation) 마지막에 성취감을 느낀다 <br />
4~5세 미취학 아동에게 위 2가지 경우의 동영상을 보여주고, 볼링 공을 던진 사람의 마음이 어땠는지 질문하였다
(happy or sad, 그리고 얼마나 happy or sad 한지). 20~68세 사이의 어른에게도 똑같은 실험을 진행하였다. <br />
결과: 어른과 5세 아동은 low expectation 에 긍정적인 감정을 표했다. 반면 4세 아동은 low와 high expectation 에 감정적인 차이를 표하지 않았다. <br />
실험 2) <br />
실험 1과 같은 방식으로 진행하였으나, 차이점은 동영상의 중간(즉, 볼링공이 절반만 지나갔을때) 동영상을 중지하고, 똑같이 볼링 공을 던진 사람의 마음에 대해 같은 질문을 하였다. <br />
결과: 4세 미취학 아동은 실험1과 마찬가지로 low와 high expectation 에 감정적인 차이를 표하지 않았다. 5세 미취학 아동은 low expectation에 더 행복할 것이라는 감정을 표현했다. 어른들은 처음에는 low expectation에 sad 였지만 볼링의 결과를 보고 felt better 했다. <br />
결론적으로, 어린 아이들은 이미 상대적인 감정에 대한 이치를 이해할 수 있고, 그들의 과거의 기대를 자발적으로 추론하는 능력은 유치원에 다니는 기간 동안 계속해서 발전한다. 정서적 인지는 타인의 감정에 적절하고 능동적으로 대응하고, 세상과 다른 사람들에게 개입하여 그들이 기분이 나아지도록 돕고, 비판적으로 다른 사람을 더 나쁘게 만들 행동을 피하는 데 중요한 기술이다. <br /></p>

<p>장점: 위 두가지 실험을 통해, 실제 일상생활에서 발생하는 상황을 제시함으로서 현실적으로 정서적 인지에 대한 개념과 상황 그리고 필요성에 대해 이해할 수 있었다. <br /></p>

<p>의의: 아이들의 감정적인 추리에 대해 연구를 할때 중요한 자료이며, 무엇보다 아이들이 정서적 인지를 하는 측면을 이해할 필요성을 조망하고 다른 사람들과의 인간 관계에서 중요한 능력이라는 부분을 상기시킨다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ong, D., Asaba, M., &amp; Gweon, H.(2016), Young children and adults integrate past expectations and current outcomes to reason about others' emotions, Cog Sci, 135-140
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-6-trust-in-online-social-groups-yw">Topic 6: Trust in Online Social Groups [YW]</h2>

<p>선정 이유: 페이스북에서 진행하는 연구들에 궁금증이 생겨 페이스북이 낸 논문들 중 관심 있는 대인 상호작용과 관련된 주제를 선정하였다. <br /></p>

<p>내용 요약:  사람들이 자신이 속한 사회적 집단에 대해 느끼는 신뢰(trust)는 구성원에 대한 만족과 공동 과제의 수행 성과와 같은 중요한 사회적 결과에 영향을 미친다. 신뢰와 관련된 행동과 조건을 이해하기 위해서 과거 신뢰에 대한 연구들은 단면 연구(cross-sectional survey; 단면 데이터에서 모집단 또는 대표 하위 집합의 데이터를 분석하는 연구) 에 의존해왔으나, 그러한 연구 방법은 인과 관계를 규명하는 데에 있어 한계점을 가진다. 따라서 이 논문에서는 신뢰와 행동 혹은 집단 특성간의 인과관계를 규명하고자 페이스북 그룹에 속한 참여자들의 활동 로그를 분석하여 two-wave 종단연구를 진행하였다. 그를 위해 latent change score modeling을 사용하였는데, 이를 통해 가설의 대상이 되는 여러 개의 변수 간 관계를, 즉 이 연구에서는 두 변수 간 인과관계를 시간에 걸쳐 동시에 모델링할 수 있었다. 연구 결과, 자신이 속한 집단을 신뢰하는 사람들은 해당 그룹의 페이스북 페이지에 글을 더 많이 남겼고, 구성원들로부터 더 신뢰받는 집단이 관리자와 중재자를 더 많이 추가한 반면 관리자와 중재자를 더 많이 추가한다고 해서 해당 집단이 더 신뢰받는 것은 아니었다. 집단의 구성원들끼리 잘 연결되어 있고 교류가 활발한 집단은 시간이 지날수록 신뢰가 증가했지만 구성원들이 활발히 참여하는 다른 집단이 많으면 그렇게 증가한 신뢰는 시간이 지날수록 다시 감소하는 것으로 나타났다. 이는 집단에서 나타나는 사회적 활동을 보는 것이 신뢰를 유발하고, 그것이 다시 해당 집단 구성원의 참여를 증진시켜 결과적으로 집단의 활동성이 증가됨을 의미한다. <br /></p>

<p>단점: 구성원들의 활발한 참여와 우정 형성이 집단에 대한 신뢰를 높인다는 결론을 내리기 전에, 구성원들이 활발히 참여하는 다른 집단이 많은 경우 높아졌던 신뢰가 다시 감소한다는 부분에 대해 조금 더 주목할 필요가 있었다는 생각이 든다. <br /></p>

<p>의의: 기존 연구들에서 규명되지 않았던 신뢰와 다른 변인들 간의 인과관계를 파악하기 위한 시도를 하였다. 뿐만 아니라 활발한 참여와 신뢰 간의 긍정 피드백 루프를 연구 결과로서 제시하여, 새로운 관점 형성에 기여하였다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Iyer, S., Cheng, J., Brown, N., &amp; Wang, X. (2020, May). When Does Trust in Online Social Groups Grow?. In Proceedings of the International AAAI Conference on Web and Social Media (Vol. 14, pp. 283-293).
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-7-tasks-for-aligning-ai-and-psychology-wk">Topic 7: Tasks for aligning AI and Psychology [WK]</h2>

<p>선정 이유: 최근 연구 동향을 살펴보기 위해 선정하였다. <br /></p>

<p>내용 요약: AI 연구에서 human-planning을 살펴보기 위해 사용되는 task는 chess 또는 바둑 등 어려운 task를 사용하였다. 반면, 심리학 연구에서는 이에 비해 쉬운 task를 사용하였다. 따라서, AI 연구자와 심리학 연구자의 융합연구가 이루지기 힘들게 만들었으며 이에 관해 저자들은 intermediate level task를 사용하자는 의견을 제시하였다. 본 논문에서는 여태까지 사용되었던 task를 살펴보았으며 four-in-a-row라는 task를 제안했다  <br /></p>

<p>장단점: 현재까지 인지심리학에서 사용되었던 human-planning task를 잘 요약하였으며 새로운 아이디어를 제시함으로서 인공지능 연구와 심리학 연구의 융합연구가 더 원할하게 진행될 수 있도록 만들었다. <br /></p>

<p>의의: 새로운 아이디어를 제시함으로서 인공지능 연구와 심리학 연구의 융합연구가 더 원할하게 진행될 수 있도록 만들었다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>van Opheusden, B., &amp; Ma, W. J. (2019). Tasks for aligning human and machine planning. Current Opinion in Behavioral Sciences, 29, 127-133
</code></pre></div></div>


</div>

<div class="pagination">
  
    <a href="/blog/2020-08-03/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2020-07-13/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
