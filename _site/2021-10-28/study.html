<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Oct 28th Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Oct 28th Journal Club" />
<meta name="author" content="Jae Eun Park (dawn2089@snu.ac.kr)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: Human-level bond, Woebot, Conversational Agent, Self-Talk, Implicit Commonsense Knowledge for Response Generation Presenters: YK (Yoon Kyung Lee), SB (Seoyeon Bae) Topic 1: Human-level bond, Woebot, Conversational Agent [YK] 선정 이유 우봇을 만든 회사에서 새로 선보인 페이퍼. 우봇을 실제로 사용해본 사람들의 평가 뿐만 아니라 우울과 불안을 경감하는 효과가 있었는지 궁금헸다. 내용 실제 본문은 3페이지 정도의 아주 간결한 페이퍼다. 기존의 대면 방식의 상담과 인터넷 기반 일방향 상담 위주로 우봇을 비교했다. 생각보다 선례가 많이 없어서 의외였다. “치료”의 영역에 들어올 수 있는 또는 그렇게 간주할 수 있는 상담 사례를 선정하는 것, 그 기준이 모호해서일 수 있다. 다 합쳐서 10개가 되지않는 다는 것이 우봇의 효과 검증에 대한 타당성을 논하기엔 아직 부족한 것 같다. 하지만 샘플이 3만명 이상이며 기존의 대면 상담에 비해 5주 이상 단축된 기간동안 간단한 감정 진단 및 대화를 함으로써써어느정도 우울과 불안 경감 효과를 보았다는 것이 인상적이다. 하지만 이도 이 연구팀에서 우봇에만 적용되는 작업 동맹 척도를 개발하여 측정한 결과만을 보고했기에 기존의 인재행동, 우울, 불안을 측정하는데 쓰인 검사에서도 그 효과가 지속적으로 나타날지 궁금하다. 장단점 예전에 우봇을 썼을때보다 자연어이해 성능이 더 높아진 것 같다. 논문에 나온 샘플 그램은 체리피킹한 것일 수도 있겠지만, 간단한 대화도 가능하며 중간 중간 적절한 버튼을 써서 대화가 쑥쑥 진행될 수 있도록 기획을 한 것 같다. 완전 룰기반으로 기획되었던 초창기 모델에 비교하면 현재는 많이 발전한 하이브리드형 (룰 + 학습) 기획인 것 같다. 비고 최근 국내에도 디지털 의료 학회가 출범했다. 심리 상담형 챗봇에 대한 이해를 높이고 활용 가치가 높게 만들 수 있도록 이런 연구가 더 많아졌으면 좋겠다. 참고 문헌 Darcy, A., Daniels, J., Salinger, D., Wicks, P., &amp; Robinson, A. (2021). Evidence of human-level bonds established with a digital conversational agent: Cross-sectional, retrospective observational study. JMIR Formative Research, 5(5), e27868. Topic 2: Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation [SB] 선정 이유 챗봇 및 자연어를 사용하는 인공지능의 현존하는 가장 큰 단점 중 하나인, 맥락에 어긋나는 대화, 모순적인 대화를 해결하는 방안에 대해 관심이 있어 본 논문을 선정하게 되었다. 내용 요약 사람 간의 대화에서 기본 지식(혹은 상식)을 적용하는 방식에서 착안하여, 본 연구진들은 기존의 대화 히스토리를 통해 이와 관련 있는 지식을 생성해내고, 대화 맥락 및 생성한 지식과 연관이 있는 반응도 함께 생성해내는 self-talk 모델(TBS-RG)을 고안해냈다. 대화 히스토리와 기본 지식을 연결하는 방식은 hard-matching과 soft-matching 두가지로 나누었으며, 지식 표상 방식 또한 Q&amp;A 방식을 새로이 도입하였다. 대화 히스토리와 지식, 반응을 구분하기 위해서는 &lt;\implicit&gt;이라는 상징자와 prompt 두 가지 방식을 차용하였다. 모델 성능 평가 결과, TBS-RG 모델이 전통적인 RG 모델에 비해 생성 지식의 질적 측면, 지식과 출력 반응 간의 연관성, 출력 반응의 질적 측면에서 모두 우월한 것으로 밝혀졌다. 장단점 장점: Self-talk 모델의 성능을 파악하기 위해 다차원적으로 평과 결과를 비교했다. 서로 다른 모델 간의 평가, 모델 내 변인들 간의 평가, 사람의 평가와 자동 평가 프로그램 간의 비교 등 다각도로 모델의 성능을 비교하고 평가하여 우수성을 검증하였다. 의의 대화 히스토리에서 반응을 바로 이끌어내는 기존의 모델과 달리, 본 연구진들은 주어진 대화를 통해 직접 상식과, 상식에 기반한 response를 모두 만들어내는 self-talk 모델을 고안했다는 점에서 매우 큰 의의가 있다. 이는 현재 계속 문제시되고 있는 맥락을 벗어난, 혹은 맥락과 전혀 상관 없는 AI의 반응 출력을 추후 해결할 수 있을 것으로 예상된다. 참고 문헌 Zhou, P., Gopalakrishnan, K., Hedayatnia, B., Kim, S., Pujara, J., Ren, X., Liu, Y., &amp; Hakkani-Tur, D. (2021). Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation. arXiv preprint arXiv:2110.08501. https://arxiv.org/abs/2110.08501" />
<meta property="og:description" content="Themes: Human-level bond, Woebot, Conversational Agent, Self-Talk, Implicit Commonsense Knowledge for Response Generation Presenters: YK (Yoon Kyung Lee), SB (Seoyeon Bae) Topic 1: Human-level bond, Woebot, Conversational Agent [YK] 선정 이유 우봇을 만든 회사에서 새로 선보인 페이퍼. 우봇을 실제로 사용해본 사람들의 평가 뿐만 아니라 우울과 불안을 경감하는 효과가 있었는지 궁금헸다. 내용 실제 본문은 3페이지 정도의 아주 간결한 페이퍼다. 기존의 대면 방식의 상담과 인터넷 기반 일방향 상담 위주로 우봇을 비교했다. 생각보다 선례가 많이 없어서 의외였다. “치료”의 영역에 들어올 수 있는 또는 그렇게 간주할 수 있는 상담 사례를 선정하는 것, 그 기준이 모호해서일 수 있다. 다 합쳐서 10개가 되지않는 다는 것이 우봇의 효과 검증에 대한 타당성을 논하기엔 아직 부족한 것 같다. 하지만 샘플이 3만명 이상이며 기존의 대면 상담에 비해 5주 이상 단축된 기간동안 간단한 감정 진단 및 대화를 함으로써써어느정도 우울과 불안 경감 효과를 보았다는 것이 인상적이다. 하지만 이도 이 연구팀에서 우봇에만 적용되는 작업 동맹 척도를 개발하여 측정한 결과만을 보고했기에 기존의 인재행동, 우울, 불안을 측정하는데 쓰인 검사에서도 그 효과가 지속적으로 나타날지 궁금하다. 장단점 예전에 우봇을 썼을때보다 자연어이해 성능이 더 높아진 것 같다. 논문에 나온 샘플 그램은 체리피킹한 것일 수도 있겠지만, 간단한 대화도 가능하며 중간 중간 적절한 버튼을 써서 대화가 쑥쑥 진행될 수 있도록 기획을 한 것 같다. 완전 룰기반으로 기획되었던 초창기 모델에 비교하면 현재는 많이 발전한 하이브리드형 (룰 + 학습) 기획인 것 같다. 비고 최근 국내에도 디지털 의료 학회가 출범했다. 심리 상담형 챗봇에 대한 이해를 높이고 활용 가치가 높게 만들 수 있도록 이런 연구가 더 많아졌으면 좋겠다. 참고 문헌 Darcy, A., Daniels, J., Salinger, D., Wicks, P., &amp; Robinson, A. (2021). Evidence of human-level bonds established with a digital conversational agent: Cross-sectional, retrospective observational study. JMIR Formative Research, 5(5), e27868. Topic 2: Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation [SB] 선정 이유 챗봇 및 자연어를 사용하는 인공지능의 현존하는 가장 큰 단점 중 하나인, 맥락에 어긋나는 대화, 모순적인 대화를 해결하는 방안에 대해 관심이 있어 본 논문을 선정하게 되었다. 내용 요약 사람 간의 대화에서 기본 지식(혹은 상식)을 적용하는 방식에서 착안하여, 본 연구진들은 기존의 대화 히스토리를 통해 이와 관련 있는 지식을 생성해내고, 대화 맥락 및 생성한 지식과 연관이 있는 반응도 함께 생성해내는 self-talk 모델(TBS-RG)을 고안해냈다. 대화 히스토리와 기본 지식을 연결하는 방식은 hard-matching과 soft-matching 두가지로 나누었으며, 지식 표상 방식 또한 Q&amp;A 방식을 새로이 도입하였다. 대화 히스토리와 지식, 반응을 구분하기 위해서는 &lt;\implicit&gt;이라는 상징자와 prompt 두 가지 방식을 차용하였다. 모델 성능 평가 결과, TBS-RG 모델이 전통적인 RG 모델에 비해 생성 지식의 질적 측면, 지식과 출력 반응 간의 연관성, 출력 반응의 질적 측면에서 모두 우월한 것으로 밝혀졌다. 장단점 장점: Self-talk 모델의 성능을 파악하기 위해 다차원적으로 평과 결과를 비교했다. 서로 다른 모델 간의 평가, 모델 내 변인들 간의 평가, 사람의 평가와 자동 평가 프로그램 간의 비교 등 다각도로 모델의 성능을 비교하고 평가하여 우수성을 검증하였다. 의의 대화 히스토리에서 반응을 바로 이끌어내는 기존의 모델과 달리, 본 연구진들은 주어진 대화를 통해 직접 상식과, 상식에 기반한 response를 모두 만들어내는 self-talk 모델을 고안했다는 점에서 매우 큰 의의가 있다. 이는 현재 계속 문제시되고 있는 맥락을 벗어난, 혹은 맥락과 전혀 상관 없는 AI의 반응 출력을 추후 해결할 수 있을 것으로 예상된다. 참고 문헌 Zhou, P., Gopalakrishnan, K., Hedayatnia, B., Kim, S., Pujara, J., Ren, X., Liu, Y., &amp; Hakkani-Tur, D. (2021). Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation. arXiv preprint arXiv:2110.08501. https://arxiv.org/abs/2110.08501" />
<link rel="canonical" href="http://localhost:4000/blog/2021-10-28/study" />
<meta property="og:url" content="http://localhost:4000/blog/2021-10-28/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-10-28T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Oct 28th Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jae Eun Park (dawn2089@snu.ac.kr)"},"dateModified":"2021-10-28T00:00:00+09:00","datePublished":"2021-10-28T00:00:00+09:00","description":"Themes: Human-level bond, Woebot, Conversational Agent, Self-Talk, Implicit Commonsense Knowledge for Response Generation Presenters: YK (Yoon Kyung Lee), SB (Seoyeon Bae) Topic 1: Human-level bond, Woebot, Conversational Agent [YK] 선정 이유 우봇을 만든 회사에서 새로 선보인 페이퍼. 우봇을 실제로 사용해본 사람들의 평가 뿐만 아니라 우울과 불안을 경감하는 효과가 있었는지 궁금헸다. 내용 실제 본문은 3페이지 정도의 아주 간결한 페이퍼다. 기존의 대면 방식의 상담과 인터넷 기반 일방향 상담 위주로 우봇을 비교했다. 생각보다 선례가 많이 없어서 의외였다. “치료”의 영역에 들어올 수 있는 또는 그렇게 간주할 수 있는 상담 사례를 선정하는 것, 그 기준이 모호해서일 수 있다. 다 합쳐서 10개가 되지않는 다는 것이 우봇의 효과 검증에 대한 타당성을 논하기엔 아직 부족한 것 같다. 하지만 샘플이 3만명 이상이며 기존의 대면 상담에 비해 5주 이상 단축된 기간동안 간단한 감정 진단 및 대화를 함으로써써어느정도 우울과 불안 경감 효과를 보았다는 것이 인상적이다. 하지만 이도 이 연구팀에서 우봇에만 적용되는 작업 동맹 척도를 개발하여 측정한 결과만을 보고했기에 기존의 인재행동, 우울, 불안을 측정하는데 쓰인 검사에서도 그 효과가 지속적으로 나타날지 궁금하다. 장단점 예전에 우봇을 썼을때보다 자연어이해 성능이 더 높아진 것 같다. 논문에 나온 샘플 그램은 체리피킹한 것일 수도 있겠지만, 간단한 대화도 가능하며 중간 중간 적절한 버튼을 써서 대화가 쑥쑥 진행될 수 있도록 기획을 한 것 같다. 완전 룰기반으로 기획되었던 초창기 모델에 비교하면 현재는 많이 발전한 하이브리드형 (룰 + 학습) 기획인 것 같다. 비고 최근 국내에도 디지털 의료 학회가 출범했다. 심리 상담형 챗봇에 대한 이해를 높이고 활용 가치가 높게 만들 수 있도록 이런 연구가 더 많아졌으면 좋겠다. 참고 문헌 Darcy, A., Daniels, J., Salinger, D., Wicks, P., &amp; Robinson, A. (2021). Evidence of human-level bonds established with a digital conversational agent: Cross-sectional, retrospective observational study. JMIR Formative Research, 5(5), e27868. Topic 2: Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation [SB] 선정 이유 챗봇 및 자연어를 사용하는 인공지능의 현존하는 가장 큰 단점 중 하나인, 맥락에 어긋나는 대화, 모순적인 대화를 해결하는 방안에 대해 관심이 있어 본 논문을 선정하게 되었다. 내용 요약 사람 간의 대화에서 기본 지식(혹은 상식)을 적용하는 방식에서 착안하여, 본 연구진들은 기존의 대화 히스토리를 통해 이와 관련 있는 지식을 생성해내고, 대화 맥락 및 생성한 지식과 연관이 있는 반응도 함께 생성해내는 self-talk 모델(TBS-RG)을 고안해냈다. 대화 히스토리와 기본 지식을 연결하는 방식은 hard-matching과 soft-matching 두가지로 나누었으며, 지식 표상 방식 또한 Q&amp;A 방식을 새로이 도입하였다. 대화 히스토리와 지식, 반응을 구분하기 위해서는 &lt;\\implicit&gt;이라는 상징자와 prompt 두 가지 방식을 차용하였다. 모델 성능 평가 결과, TBS-RG 모델이 전통적인 RG 모델에 비해 생성 지식의 질적 측면, 지식과 출력 반응 간의 연관성, 출력 반응의 질적 측면에서 모두 우월한 것으로 밝혀졌다. 장단점 장점: Self-talk 모델의 성능을 파악하기 위해 다차원적으로 평과 결과를 비교했다. 서로 다른 모델 간의 평가, 모델 내 변인들 간의 평가, 사람의 평가와 자동 평가 프로그램 간의 비교 등 다각도로 모델의 성능을 비교하고 평가하여 우수성을 검증하였다. 의의 대화 히스토리에서 반응을 바로 이끌어내는 기존의 모델과 달리, 본 연구진들은 주어진 대화를 통해 직접 상식과, 상식에 기반한 response를 모두 만들어내는 self-talk 모델을 고안했다는 점에서 매우 큰 의의가 있다. 이는 현재 계속 문제시되고 있는 맥락을 벗어난, 혹은 맥락과 전혀 상관 없는 AI의 반응 출력을 추후 해결할 수 있을 것으로 예상된다. 참고 문헌 Zhou, P., Gopalakrishnan, K., Hedayatnia, B., Kim, S., Pujara, J., Ren, X., Liu, Y., &amp; Hakkani-Tur, D. (2021). Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation. arXiv preprint arXiv:2110.08501. https://arxiv.org/abs/2110.08501","headline":"Oct 28th Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2021-10-28/study"},"url":"http://localhost:4000/blog/2021-10-28/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Jae Eun Park (dawn2089@snu.ac.kr)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2021-10-28 00:00:00 +0900">October 28, 2021</time>
    
  </div>

  <h1 class="post-title">Oct 28th Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: Human-level bond, Woebot, Conversational Agent, Self-Talk, Implicit Commonsense Knowledge for Response Generation 
</code></pre></div></div>

<p>Presenters: YK (Yoon Kyung Lee), SB (Seoyeon Bae)  <br /></p>

<hr />

<h1 id="topic-1-human-level-bond-woebot-conversational-agent-yk">Topic 1: Human-level bond, Woebot, Conversational Agent [YK]</h1>

<h3 id="선정-이유"><strong>선정 이유</strong></h3>

<p>우봇을 만든 회사에서 새로 선보인 페이퍼.
우봇을 실제로 사용해본 사람들의 평가 뿐만 아니라 우울과 불안을 경감하는 효과가 있었는지 궁금헸다.</p>

<h3 id="내용"><strong>내용</strong></h3>
<p>실제 본문은 3페이지 정도의 아주 간결한 페이퍼다. 기존의 대면 방식의 상담과 인터넷 기반 일방향 상담 위주로 우봇을 비교했다. 생각보다 선례가 많이 없어서 의외였다.
“치료”의 영역에 들어올 수 있는 또는 그렇게 간주할 수 있는 상담 사례를 선정하는 것, 그 기준이 모호해서일 수 있다.
다 합쳐서 10개가 되지않는 다는 것이 우봇의 효과 검증에 대한 타당성을 논하기엔 아직 부족한 것 같다.
하지만 샘플이 3만명 이상이며 기존의 대면 상담에 비해 5주 이상 단축된 기간동안 간단한 감정 진단 및 대화를 함으로써써어느정도 
우울과 불안 경감 효과를 보았다는 것이 인상적이다. 하지만 이도 이 연구팀에서 우봇에만 적용되는 작업 동맹 척도를 개발하여
측정한 결과만을 보고했기에 기존의 인재행동, 우울, 불안을 측정하는데 쓰인 검사에서도 그 효과가 지속적으로 나타날지 궁금하다.</p>

<h3 id="장단점"><strong>장단점</strong></h3>

<p>예전에 우봇을 썼을때보다 자연어이해 성능이 더 높아진 것 같다. 논문에 나온 샘플 그램은 체리피킹한 것일 수도 있겠지만, 
간단한 대화도 가능하며 중간 중간 적절한 버튼을 써서 대화가 쑥쑥 진행될 수 있도록 기획을 한 것 같다. 완전 룰기반으로 기획되었던 초창기 모델에 비교하면
현재는 많이 발전한 하이브리드형 (룰 + 학습) 기획인 것 같다.</p>

<h3 id="비고"><strong>비고</strong></h3>
<p>최근 국내에도 디지털 의료 학회가 출범했다. 심리 상담형 챗봇에 대한 이해를 높이고 활용 가치가 높게 만들 수 있도록 이런 연구가 더 많아졌으면 좋겠다.</p>

<h3 id="참고-문헌"><strong>참고 문헌</strong></h3>

<ul>
  <li>Darcy, A., Daniels, J., Salinger, D., Wicks, P., &amp; Robinson, A. (2021). Evidence of human-level bonds established with a digital conversational agent: Cross-sectional, retrospective observational study. JMIR Formative Research, 5(5), e27868.</li>
</ul>

<h1 id="topic-2-think-before-you-speak-using-self-talk-to-generate-implicit-commonsense-knowledge-for-response-generation-sb">Topic 2: Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation [SB]</h1>

<h3 id="선정-이유-1"><strong>선정 이유</strong></h3>

<p>챗봇 및 자연어를 사용하는 인공지능의 현존하는 가장 큰 단점 중 하나인, 맥락에 어긋나는 대화, 모순적인 대화를 해결하는 방안에 대해 관심이 있어 본 논문을 선정하게 되었다.</p>

<h3 id="내용-요약"><strong>내용 요약</strong></h3>

<p>사람 간의 대화에서 기본 지식(혹은 상식)을 적용하는 방식에서 착안하여, 본 연구진들은 기존의 대화 히스토리를 통해 이와 관련 있는 지식을 생성해내고, 대화 맥락 및 생성한 지식과 연관이 있는 반응도 함께 생성해내는  self-talk 모델(TBS-RG)을 고안해냈다. 대화 히스토리와 기본 지식을 연결하는 방식은 hard-matching과 soft-matching 두가지로 나누었으며, 지식 표상 방식 또한 Q&amp;A 방식을 새로이 도입하였다. 대화 히스토리와 지식, 반응을 구분하기 위해서는 <implicit>&lt;\implicit&gt;이라는 상징자와 prompt 두 가지 방식을 차용하였다. 모델 성능 평가 결과, TBS-RG 모델이 전통적인 RG 모델에 비해 생성 지식의 질적 측면, 지식과 출력 반응 간의 연관성, 출력 반응의 질적 측면에서 모두 우월한 것으로 밝혀졌다.</implicit></p>

<h3 id="장단점-1"><strong>장단점</strong></h3>

<p>장점: Self-talk 모델의 성능을 파악하기 위해 다차원적으로 평과 결과를 비교했다. 서로 다른 모델 간의 평가, 모델 내 변인들 간의 평가, 사람의 평가와 자동 평가 프로그램 간의 비교 등 다각도로 모델의 성능을 비교하고 평가하여 우수성을 검증하였다.</p>

<h3 id="의의"><strong>의의</strong></h3>

<p>대화 히스토리에서 반응을 바로 이끌어내는 기존의 모델과 달리, 본 연구진들은 주어진 대화를 통해 직접 상식과, 상식에 기반한 response를 모두 만들어내는 self-talk 모델을 고안했다는 점에서 매우 큰 의의가 있다. 이는 현재 계속 문제시되고 있는 맥락을 벗어난, 혹은 맥락과 전혀 상관 없는 AI의 반응 출력을 추후 해결할 수 있을 것으로 예상된다.</p>

<h3 id="참고-문헌-1"><strong>참고 문헌</strong></h3>

<ul>
  <li>Zhou, P., Gopalakrishnan, K., Hedayatnia, B., Kim, S., Pujara, J., Ren, X., Liu, Y., &amp; Hakkani-Tur, D. (2021). Think Before You Speak: Using Self-talk to Generate Implicit Commonsense Knowledge for Response Generation. arXiv preprint arXiv:2110.08501. https://arxiv.org/abs/2110.08501</li>
</ul>


</div>

<div class="pagination">
  
    <a href="/blog/2021-11-04/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2021-10-21/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
