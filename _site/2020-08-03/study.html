<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Aug 3rd Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Aug 3rd Journal Club" />
<meta name="author" content="Yoon Kyung Lee (yoonlee78@snu.ac.kr)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: Narrative Flow, NLP, GPT, Backpropagation, Cognitive Bots, Mental Simulation, Decision Making, Compliance in Robot Behavior" />
<meta property="og:description" content="Themes: Narrative Flow, NLP, GPT, Backpropagation, Cognitive Bots, Mental Simulation, Decision Making, Compliance in Robot Behavior" />
<link rel="canonical" href="http://localhost:4000/blog/2020-08-03/study" />
<meta property="og:url" content="http://localhost:4000/blog/2020-08-03/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-03T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Aug 3rd Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Yoon Kyung Lee (yoonlee78@snu.ac.kr)"},"dateModified":"2020-08-03T00:00:00+09:00","datePublished":"2020-08-03T00:00:00+09:00","description":"Themes: Narrative Flow, NLP, GPT, Backpropagation, Cognitive Bots, Mental Simulation, Decision Making, Compliance in Robot Behavior","headline":"Aug 3rd Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2020-08-03/study"},"url":"http://localhost:4000/blog/2020-08-03/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Yoon Kyung Lee (yoonlee78@snu.ac.kr)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-08-03 00:00:00 +0900">August 03, 2020</time>
    
  </div>

  <h1 class="post-title">Aug 3rd Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: Narrative Flow, NLP, GPT, Backpropagation, Cognitive Bots, Mental Simulation, Decision Making, Compliance in Robot Behavior
</code></pre></div></div>

<p>Presenters: YK (Yoon Kyung Lee), YW (Yoonwon Jung), JE (Jaeun Park), IJ (Inju Lee), HY (Hoyoung Maeng), WK (Whani Kim), SC (Soomin Cho) <br /></p>

<hr />

<h2 id="topic-1-narrative-flow--human-memory-inspired-deep-learninig-yk">Topic 1: Narrative Flow &amp; Human Memory-Inspired Deep Learninig [YK]</h2>

<p>선정 이유: 사람의 기억의 종류와(episodic, semantic memory)의 그 메커니즘에서 착안한 사고의 흐름 과정을 살펴봄. 비슷한 종류의 데이터를 다룰때 참고할 수 있는 평가 방법으로 적당한지도 살펴보고자 함</p>

<p>내용 요약: 본 연구에서는 자연어처리 분석법을 통해 사람의 사고의 흐름이 어떻게 텍스트를 통해 나타나는지 살펴보았다. 연구팀에서는 Hippocorpus라는 이름의 코퍼스를 공개했다. 코퍼스에는 약 5,387명의 참여자가 평균 17문장으로 구성된 7000개의 스토리를 작성했다. 스토리는 3가지 분류로 나뉘었는데, 1) 실제 경험한 일, 2) 상상한 일, 3) 몇달 뒤에 다시 회상해서 기록한 글이었다. 스토리안에 담긴 단어 형태가 의미 기억을 표상하는지 사건 기억을 표상하는지 비교했다. 회상한 스토리와 상상한 스토리의 Flow가 어떻게 변하는지를 negative log likelihood (NLL)를 계산해서 비교했다. 그 결과, 상상한 스토리의 경우 좀 더 commonsense에 가깝게 더 일반적인 내용을 주로 많이 작성했고, 더 감정적이었으며, relis events (사실적 사건)에 대한 묘사가 더 많았다. 회상한 스토리는 작성자 자신에게 더 집중된 표현 (self-focused, “I”)이 많이 보였고 autobiographical한 내용이 주로 많이 나타난 것을 볼 수 있었다. 또한, 회상을 덜 할 수록 더 logical하게 hierarchical하게 이야기가 전개되는 걸 발견했다.</p>

<p>장단점: 기억의 종류에 따라 텍스트 안에 담긴 사고의 흐름이 어떻게 변하는지를 나타내고자 했다. 데이터가 Microsoft에 공개되어있고 자세한 설계 인터페이스와 Instruction이 담겨있다.상상한 스토리와 회상한 스토리가 어떻게 다르게 펼쳐졌는지 내용 자체의 전개의 차이에는 덜 집중되어있다. 성격 등의 개인차를 보는 척도를 사용하긴 했으나 이러한 개인차가 실제 상상력 또는 스토리 제작 능력에 어떤 영향을 주었고, 이런 영향이 연구 결과에 미쳤을 (또는 미치지 않은) 영향에 대한 설명이 부재해서 아쉽다. 또한 회상 능력에 따라 서술된 내용의 퀄리티가 달라질수도 있는데, 이에 대한 고려가 있었는지 궁금하다. 실제 생긴 사건에 대해 묘사할때는 그 당시 겪은 감정에 대해 주의를 덜 주는 것인지, 아니면 스토리를 상상하면서 쓰는 것 자체가 좀 더 감정적인 표현을 쓰게 하는지 궁금하다. 예를 들어서 트라우마틱한 사건에 대해 회상할때는 좀 더 감정적인 표현을 쓸텐데, 논의에 이에 대한 언급이 없어서 아쉽다.</p>

<p>의의: 실제 사건 발생 시점이 기억으로 전환되는 시점에서 narrative하게 묘사하는 시점까지의 시간 간격이 길수록 스토리가 더 일반적이고, 선형적으로 flow하고, 요점이 산만하다는 점을 계산적으로 풀어냈다. Flow의 과정과 다음에 올 컴포넌트에 대한 예측을 위해 고려한 두 모형 (Bag-like, Chain-like)은 신선한 개념이었다.</p>

<p>GPT에 기학습된 지식 (English fiction)이 선형성을 강하게 지니기 때문에 상상한 스토리가 이에 더 가까운 패턴을 보임을 구현했다</p>

<p>참고문헌
<a href="http://aka.ms/hippocorpus">Dataset</a>
Sap, M., Choi, Y., Smith, N. A., &amp; Pennebaker, J. (2020, July). Recollection versus Imagination: Exploring Human Memory and Cognition via Neural Language Models. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (pp. 1970-1978).</p>

<h2 id="topic-2--neural-networks-backpropagation-jp">Topic 2:  Neural Networks, Backpropagation [JP]</h2>

<p>선정 이유: backpropagation 이해와 neural network 공부</p>

<p>내용 요약: Computation Graph(계산 그래프)를 통해 backpropagation(역전파)을 효율적으로 적용할 수 있다. Computation graph는 계산과정을 node와 edge를 사용해 표현하며 이를 통해 상위 레이어에서 계산된 derivative를 하위레이어에서 쉽게 재사용할 수 있다. <br />
Neural network 실행에 도움이 되는 여러 방법이 존재한다. Regularization(정규화)는 손실 함수에 추가적인 항을 더함으로써 모델의 overfitting(과적합화)를 피하기 위한 방편이다. Vectorization(벡터화)는 루프를 사용하는 대신 벡터와 행렬을 통해 계산함으로써 계산 속도를 높이는 방법이다. 또한 neural network에서 활성화함수로 sigmoid 함수가 아닌 다른 함수를 사용함으로써 계산의 효율을 높일 수 있다. 사용할 수 있는 활성화함수로 tanh, hard tanh, ReLU, Leaky ReLU, Parametric ReLU 등이 있으며 현재 ReLU가 가장 많이 쓰인다. 또, 파라미터를 적절히 초기화(parameter initialization)하고, optimizer를 사용하며, 적절한 learning rate 선택 후 시간이 지남에 따라 learning rate를 줄여나가는 방법으로 neural network의 성능을 높일 수 있다.</p>

<p>의의: Neural network의 실질적인 적용을 위한 실용적인 팁을 더 배울 수 있었음</p>

<p>참고문헌: Backpropagation and Computation Graphs. (Manning, Stanford CS224N); Derivatives, Backpropagation, and Vectorization (course material)</p>

<h2 id="topic-3--cognitive-bots-social-intelligence-yw">Topic 3:  Cognitive bots, Social intelligence [YW]</h2>

<p>선정 이유: 사회인지에 대해 관심을 가지고 있었고, 사회적인 인공지능의 구현에도 관심이 있어 선정하게 되었다.</p>

<p>내용 요약: 사회신경과학과 인공지능 연구 분야에서는 사회적 지능을 연구하기 위한 핵심 프레임워크로 멀티 에이전트 강화학습 MARL(multi-agent reinforcement learning)을 활용하고 있다. 이 모델은 상황에 따라 모델을 재사용할 수 있다는 장점이 있으나 학습의 복잡성이 에이전트의 수(N)만큼 기하급수적으로 늘어나는 계산상(computational)의 어려움(dimensionality problem)이 존재한다. 또한 인간이 학습의 복잡성을 줄이고 학습 결과를 새로운 맥락에 유동적으로 적용하기 위해 추론 편향(inductive bias)을 보임이 밝혀지면서 이를 구현하기 위한 추가적인 모델들이 도입되고 있다. 한편, 최근 공학에서는 전통적인 MARL의 parameterizing과 복잡한 policy들을 학습시킬 수 있는 유동적인 방법으로서의 인공 신경망에 관심을 가지기 시작했다. Hernadez-Leal 연구팀은 다른 에이전트의 존재를 모델링하기 위한 접근법으로 정교화 위계(hierarchy of sophistication)를 제안하였다. 정교화 위계에 따르면, 타 에이전트의 존재를 무시하는 낮은 위계의 접근부터 타 에이전트의 행동 혹은 전략뿐만 아니라 타 에이전트가 스스로를 어떻게 모델링하는지까지 고려하는 높은 위계의 접근까지 다양한 위계의 알고리즘을 구축할 수 있다. MARL에 딥러닝을 적용하는 맥락에서 소개된 두 개의 최근 모델로는 Learning with Opponent-Learning Awareness(LOLA)와 Theory of Mind neural network(ToMnet)이 있다. 마지막으로, 사회신경과학에서는 인간이 어떻게 발달 과정에서 자연적으로 타인의 목표, 의도, 욕구, 신념 등을 고려하여 의사결정을 내릴 수 있는지를 마음이론(Theory of Mind)의 관점에서 연구해왔다. 뇌영상연구에 따르면 우측 측두 두정 접합(rTPJ)과 내측전전두피질(mPFC)이 불공정에 대해 혐오를 느끼거나 공정함에 대한 개념을 생각할 때, 타인의 신념을 추론할 때와 같은 같은 사회적 과제를 수행할 때에 공통적으로 많이 보고되는 부위이다. 이는 사회인지에 특화된 인간 뇌 영역 존재의 가능성을 시사한다. 사회 지능에 대한 연구를 진행해온 사회신경과학이 전통적으로 집중해 온 토픽들은 멀티 에이전트 인공지능 연구의 주류와 거리가 있었지만, 최근 이와 같은 멀티 에이전트 게임에 대한 연구들이 두 영역 간에 다리를 놓고 있다.</p>

<p>장단점: 인간의 사회인지에 대해 진행된 연구와 사회적 인공지능의 구현을 위해 진행된 연구를 함께 리뷰하고, 그것들의 강점과 한계를 분석함과 더불어 두 접근 간의 유사성 또한 분석하여 향후 연구에 대한 제언을 하였다.</p>

<p>의의: 최근 이루어지고 있는 심리학, 뇌과학, 그리고 인공지능 연구의 융합은 앞서 소개한 연구들처럼 사회적 지능에 대한 고전적인 질문들을 다학제적으로 해결할 수 있는 실마리를 제공한다.</p>

<p>참고문헌: McDonald, K. R., &amp; Pearson, J. M. (2019). Cognitive bots and algorithmic humans: toward a shared understanding of social intelligence. Current Opinion in Behavioral Sciences, 29, 55-62.</p>

<h2 id="topic-4--mental-simulation-deep-reinforcement-learning-ij">Topic 4:  Mental Simulation, Deep Reinforcement Learning [IJ]</h2>

<p>선정 이유: 강화학습을 통해 인공지능에게 mental simulation을 모델링하고 구현하는 과정이 궁금하여 읽어보았다.</p>

<p>내용 요약: mental simulation은 무엇이 발생할 지, 무엇이 가능할 지 상상할 수 있도록 mental model을 구성하는 능력이다. 일종의 알고리즘 모음인 model-based methods를 통해 인공지능이 mental simulation을 하도록 할 수 있다. 대부분의 model-based deep reinforcement learning(MBDRL)의 핵심은 partially-observable Markov decision process(POMDP)이며, POWDP을 통해 다양한 mental simulation을 프레이밍(framing)할 수 있다. 관련 딥러닝 학습 모델은 transition과 recognition function에 초점을 맞추고 있으며, 이와 관련된 학습모델은 4가지가 존재한다: (1) state-transition models, (2) observation-transition models, (3) prior-constrained latent state-transition models, (4) data-constrained state-transition models. 또한 학습한 모델을 통한 prediction을 기반으로 action을 하게 되는 과정에서 planning method를 사용하며, 이 방법은 크게 (1) background planning과 (2) decision-time planning 2가지가 있다. MBDRL은 사람의 mental simulation과 많은 공통점을 공유하고 있기 때문에, mental imagery, learning by thinking, the control of mental simulation에 대한 다양한 인지 모델 개발의 시작점이 될 수 있다. 그러나 인공지능이 강화학습을 통해 사람의 mental simulation의 다양한 측면(e.g., general, flexible, exploratory)을 구현할 수 있기 위해선 아직 많은 연구가 필요하다.</p>

<p>의의: Deep reinforcement learning을 이용하여 인공지능에게 mental simulation을 구현할 수 있는 방법, 앞으로의 전망, 발전시켜나가야 하는 방향에 대하여 체계적으로 리뷰해놓았다.</p>

<p>참고문헌: Hamrick, J. B. (2019). Analogues of mental simulation and imagination in deep learning. Current Opinion in Behavioral Sciences, 29, 8-16.</p>

<h2 id="topic-5-decision-time-in-the-background-theta--swr-sequences-hy">Topic 5: Decision time, In the background, Theta &amp; SWR Sequences [HY]</h2>

<p>선정이유: 인공지능은 인간의 뇌를 모티브하여 만들었는데, 이때, 인간의 뇌가 어떻게 예측하는지에 대한 원리를 이해해보고 싶었음.</p>

<p>내용요약</p>

<ul>
  <li>
    <p>목표 : 모델 기반 계획 프로세스와 spatial navigation 상황에서 설치류(쥐) 및 인간의 뇌의 미래 목표 상태 표현을 검토
위 상황에서 의사결정시, 해마에서 내부적으로 생성된 두 종류의 시퀀스인 “세타”와 “SWR 시퀀스”가 있으며,
이 두 가지 계획 모드가 뉴런 구현에 어떻게 참여하여, 적응형 인지 및 행동을 위한 유연한 모델 기반 시스템을 지원하는 지 논의.</p>
  </li>
  <li>
    <p>의사결정(at decision time): 목표 지향적 선택과 순차적 메모리 인코딩을 지원하는 것. ‘세타’는 해마 세타 리듬의 특정 단계에 고정되어 있다는 사실을 가리킨다
세타 시퀀스는 메모리 인코딩 메커니즘으로 해석되어 왔으나, 향후 위치를 위해 코드화할 때 단기 시퀀스 예측 또는 예측 코딩도 가능하며 현재를 지속적으로 추정(예: 자체 국지화)하고 미래를 예측하는 모델 기반 메커니즘의 발현이며(예: 목표 위치의 경로)
이 두 연산은 각 세타 사이클의 개별적인 부분에서 발생할 수 있다.</p>
  </li>
  <li>
    <p>배경지식(in the background) : 행동 정책을 배우고 내부 모델을 최적화하기 위한 것이다.</p>
  </li>
  <li>
    <p>SWR(sharp wave ripples): 뇌의 오프라인 상태에서 소모적 행동 및 비 REM 수면과 관련된 매우 빠른 신경 모집단 패턴, 일반적으로 국부적이지 않고 동물의 현재 위치와 구별되는 궤적 또는 사건을 인코딩한다(단, 수면 중과 깨어 있는 상태의 통계는 다르다)
해마는 신피질에 있는 기억을 통합하기 위해 오프라인 기간과 수면 중에 최신 기억(에피소드)을 저장하고 재생한다
SWR 시퀀스는 동물이 깨어 있는 상태지만 항로에 직접 관여하지 않을 때 발생한다. (세타 시퀀스랑 차이점)</p>
  </li>
</ul>

<p>장단점</p>

<ul>
  <li>장점 : 설치류(쥐)를 통해 뇌가 활성화된 부분을 이해하고, 비슷한 상황에서 인간의 뇌에 대해 분석했던 측면이 이해를 도왔다</li>
  <li>단점 ; 궁극적으로 뇌의 어느부분이 작동하는지에 대해 이해는 할 수 있었으나, 어느상황에서 발생하는지 이해가 어려웠다
설치류 경우 미로에서 발생하는 선택문제 라는 상황을 제시하였으나, 인간의 경우 구체적인 상황이나 예시가 없었다.</li>
</ul>

<p>의의</p>
<ul>
  <li>설치류(쥐)들이 의사결정을 할때, 해마에서 일어나는 과정을 연구하는 문헌들을 종합적으로 검토하였으며, 향후, 엔토르하피질, 복측 선조체, 전두엽 피질 등과 같은 뇌 영역들을 연구할때 참고하고 동시에 비교해볼만한 리뷰라고 생각한다.</li>
</ul>

<p>참고문헌</p>
<ul>
  <li>Pezzulo, G., Donnarumma, F., Maisto, D., &amp; Stoianov, I. (2019). Planning at decision time and in the background during spatial navigation. Current Opinion in Behavioral Sciences, 29, 69–76.</li>
</ul>

<h2 id="topic-6-hrirobot-behavior-compliance-wk">Topic 6: HRI,Robot Behavior, Compliance [WK]</h2>

<p>선정이유</p>

<ul>
  <li>HRI에 최신 연구동향을 살펴보기 위해 선정함</li>
</ul>

<p>내용요약</p>

<ul>
  <li>연구자들은 로봇의 존재와 로봇의 행동 스타일이 task compliance에 어떤 영향을 주는 지 살펴보고자 했다. 60명의 연구참여자는 3가지 task를 해야했으며 instruction을 Pepper에게서 받았다. Pepper는 neutral, friendly, authoritarian 컨디션으로 나누어졌다. Neutral 컨디션에서는 눈 색깔이 하얀색이였으며, 아무런 제스쳐를 하지 않았고 낮고 느린 목소리와 형식적인 말투를 가졌다. Friendly 컨디션은 노란색 눈, 제스쳐를 자주 취했으며 높고 빠른 목소리와 비형식적인 말투를 가졌다. Authoritarian 컨디션은 빨간 눈, 제스쳐를 취하며 “medium-high” tone과 빠른 목소리와 형식적인 말투를 가졌다. 결과에 의하면 사람들은 friendly와 authoritarian한 로봇들에 비해 neutral한 행동을 취한 로봇에게 덜 순종하였다.</li>
</ul>

<p>장단점</p>

<ul>
  <li>장점 : 눈 색깔, 말투, 목소리, 제스쳐 등 많은 특징을 조작하여 컨디션을 확실하게 구분하였다.</li>
  <li>단점 : 많은 특징을 조작함으로써 각 특징이 결과에 어떤 영향을 줬는지 구별할 수 없으며 로봇 행동 조작에 대한 이유와 이에 대한 선행연구와 결과가 단순하며 결과에 대한 논의와 해석이 짧아서 아쉬운 점이 많이 남았다.</li>
</ul>

<p>의의</p>

<ul>
  <li>로봇의 행동들은 사람들의 compliance에 영향을 줄 수 있음으로 로봇 디자인에 도움될 수 있다.</li>
</ul>

<p>참고문헌
Maggi, G., Dell’Aquila, E., Cucciniello, I., &amp; Rossi, S. (2020). Cheating with a Socially Assistive Robot? A Matter of Personality. In Companion of the 2020 ACM/IEEE International Conce on Human-Robot Interaction. (pp. 352-354)</p>



</div>

<div class="pagination">
  
    <a href="/blog/2020-08-10/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2020-07-20/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
