<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Apr 29th Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Apr 29th Journal Club" />
<meta name="author" content="Jae Eun Park (dawn2089@snu.ac.kr)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: Sympathy and Empathy in a Chatbot, Empathy: A Review of the Concept, HRI, Trust Violation, and Repair Presenters: YJ (Yoonwon Jeong), IL (Inju Lee), HM (Hoyoung Maeng) Topic 1: Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot [YJ] 선정 이유 공감하는 챗봇이 인간-AI 상호작용에 있어 가지는 효과에 대한 실험 연구를 읽어보고자 하여 선정하였다. 내용 요약 사람들은 다른 사람과 상호작용을 할 때 정서적인 지지를 기반으로 한 의사소통을 선호하지만, 인공지능 에이전트와의 상호작용에 있어서도 같은 것을 원하는지는 명확히 밝혀지지 않았으며, 특히 그러한 경향성의 기반이 되는 심리학적 과정이 어떤 것인지에 대한 탐구는 상대적으로 부족하다. 본 연구에서는 헬스케어 관련 정보와 개인적 문제에 대한 상담을 제공하는 챗봇을 사용하여 CASA와 Uncanny Valley of Mind(UVM)라는 두 개의 이론적 관점 중 어느 것이 인간-챗봇 상호작용에서 감정적 지지 방법으로서의 인지적 공감(cognitive empathy), 정서적 공감(affective empathy), 그리고 동정심(sympathy) 표현의 역할을 설명할지 알아보고자 하였다. Study1에서는 챗봇과 인간의 대화 내용을 텍스트화한 시나리오를 보여준 후 참여자의 인식을 평가하였고, Study2에서는 참여자가 챗봇과 직접 대화한 경험을 토대로 척도에 응답하였다. 실험 결과, 참여자들은 동정심과 정서적 공감은 통제 조건보다 더 지지적이라고 평가하였고, 로봇의 감정적 능력 혹은 지능에 대한 참여자들의 믿음이 챗봇의 동정과 공감에 대한 반응을 조절하였다. 로봇이 감정을 가질 수 있다고 믿는 사람들은 정서적 공감을 표출하는 챗봇에 대해 더 이상함(uncanny)을 느껴 UVM모델에 부합하였으나, 동정심과 정서적 공감을 보이는 로봇에 대한 긍정적인 지각 및 평가는 로봇의 능력을 믿지 않는 사람들에게서만 나타나, CASA패러다임에 더 부합하였다. 또한 study1에서는 챗봇의 감정 인식에 대한 지각과 챗봇의 감정 이해가 3개의 공감 감정 표현 실험 조건과 이상함의 관계를 매개하였으나, study2에서는 챗봇의 슬픔에 대한 지각이 그 관계를 매개하는 것으로 나타났다. 본 논문에서는 두 study에서 modality차이가 인간-AI상호작용 상황에서 챗봇의 사회감정적 측면과 인지적 능력 중 무엇이 더 현저하게(salient)보이는지의 차이를 가져왔기 때문일 수 있다고 설명하였다. 장단점 perceived sadness, perceived recognition, perceived understanding을 mediator variable로 사용하여 분석했는데, 그것이 각각 무엇을 정확히 측정하였고 왜 mediating variable로 선정하였는지에 대한 설명이 부족한 점이 아쉽다. Study1과 2의 결과가 일관적이지 않은 점이 한계점으로 보이고, 그로 인해 인지적 공감, 정서적 공감, 동정심 3가지를 구분하여 연구에 사용하였으나 study2에서 그 세 개를 합쳐서 empathic expression이라는 새로운 구성개념을 만들어 결과를 낸 점이 서론에서 언급한 연구의 본래 목적과 잘 맞지 않게 되어 아쉽다. 의의 로봇 대화 디자인할 시 AI가 공감을 표현하는 가장 좋은 방법을 실용적으로 제시하였다는 함의가 있다. 참고 문헌 Liu, B., &amp; Sundar, S. S. (2018). Should machines express sympathy and empathy? Experiments with a health advice chatbot. Cyberpsychology, Behavior, and Social Networking, 21(10), 625-636. Topic 2: Empathy: A Review of the Concept [IL] 선정 이유 “공감”이 무엇인지 정리하고 싶어 읽어보았다. 내용 요약 본 논문은 공감을 개념화한 다양한 연구들을 리뷰하여, 8가지 속성에 대하여 공감을 체계적으로 분석하였고, 이를 바탕으로 공감을 총체적으로 개념화하였다. Distinguishing Empathy From Other Concepts Sympathy: 공감은 관찰자가 대상과 동일한 감정을 느끼는 상태인 반면, sympathy는 관찰자가 대상에 대하여 감정을 느끼는 상태이다(대상과 동일한 감정을 느끼는 것이 아니다). Compassion &amp; Tenderness: compassion은 타인의 고통을 보았을 때 타인을 도와주고 싶은 마음이 드는 상태를 의미하며, tenderness는 약한 타인을 따뜻하게 대해주고 싶은 상태를 의미한다. 둘 다 타인의 역경에 대한 관찰자의 감정과 관련된 것으로 sympathy에 더 가까운 개념이다. Cognitive or Affective? 공감의 인지적 요소와 정서적 요소는 별개의 개념이지만 서로 상호작용한다. 공감에 있어 반드시 정서적 요소가 필요한지, 아니면 인지적인 공감 자체만으로도 공감으로 볼 수 있을지에 관해 논쟁이 있다. 널리 받아들여지고 있는 견해에 따라 공감에 있어 정서적 요소를 배제시킬 수는 없을 것이다. 인지적 공감과 perspective-taking을 같은 개념으로 볼 수 있을지에 관한 논쟁도 존재한다. Congruent or Incongruent? 공감에 있어 관찰자와 공감의 대상이 느끼는 감정이 반드시 동일해야 하는지에 관한 논쟁이 있다. 이는 타인의 생각과 감정을 정확하게 추론하는 능력인 공감적 정확성(empathic accuracy)과 관련된다. 관찰자가 대상과 “완전히” 동일한 감정을 느끼는 것은 매우 어렵고, 실제로 사람들은 공감적 정확성과 관계 없이 그들이 느끼는 공감적 경험에 기반하여 행동한다. Subject to Other Stimuli? 공감의 대상과 그 대상의 감정적인 정보가 실제적으로 존재하지 않아도 사람들은 perspective-taking, 상상, 자신의 기억 및 경험 등을 바탕으로 충분히 공감할 수 있다. 공감은 다양한 감정에 의해 유발되며, 개인들의 공감 능력은 공감을 해야하는 감정이 무엇인지에 따라 달라질 수 있다. Self/Other Distinction or Merging? 관찰자가 자신이 느끼는 감정이 외부의 자극으로부터 발생했다는 것을 지각하는 것은 공감과 emotional contagion을 구분하는 기준이 된다. Trait or State Influences? 공감은 trait의 속성을 가지지만, 관찰자와 대상과의 유사성, 대상을 얼마나 가치있게 생각하는지, 관찰자의 기분 등과 같은 상황적 요소(state)에도 영향을 받는다. Has a Behavioural Outcome? 단일 개념으로서의 공감은 공감으로부터 유발되는 행동과는 분리된 별개의 개념으로 본다. 공감이 행동의 동기가 될 수 있지만 공감이 행동적 요소를 포함하고 있다고 보기는 어렵다. Automatic or Controlled? 공감은 자동적으로 유발될 수도 있고 관찰자의 인지적 노력에 의해서 조절되어질 수도 있다. 의의 공감에 대한 정의를 총체적으로 정리하였기 때문에 공감의 개념과 속성을 정리하는 데에 도움이 될 수 있는 논문이다. 참고 문헌 Cuff, B. M., Brown, S. J., Taylor, L., &amp; Howat, D. J. (2016). Empathy: A review of the concept. Emotion review, 8(2), 144-153. Topic 3: HRI, Trust Violation and Repair [HM] 선정 이유 인공지능 에이전트와 인간의 상호작용에서 신뢰를 판단하는 척도와 영향을 확인하기 위해서. 내용 요약 본 연구는 인간과 로봇의 상호작용 상황에서 신뢰가 깨지고, 복귀되는 방법에 대하여 각각 2가지 방법을 적용하여 실험이 진행되었다. 신뢰가 깨지는 상황 : Competence trust violation vs Integrity-based trust violation 이때 competence는 고의가 아닌 실수로 신뢰가 깨지는 상황을 말하며, 화자의 능력부족 혹은 스킬 부족과 같은 상황을 나타낸다. 반면 integrity는 화자의 고의로 인하여 신뢰가 깨지는 상황이다. 신뢰를 회복하는 방법 : apology vs denial 앞선 신뢰가 깨진 상황에서, 자신의 잘못을 인정하고 바로 사과를 하는 apology와 자신의 잘못을 부정하고 부인하는 denial 방법이 각각 적용되었다 실험 참가자들은 나오(Nao)라는 인공지능 로봇과 real time으로 태블릿에서 우주선으로 소행성을 파괴하는 게임을 하였다. 이때 로봇은 실험 참여자들에게 상대방의 우주선을 고정시키지 않겠다는 약속을 하였다. 그러나 실제로는 그 약속을 지키지 않았고 이 과정에서 trust violation이 발생하였다. 이후 다음과 같은 4가지 형식의 대화를 통해 로봇은 인간에게 신뢰를 회복하기 위해 노력하였다. 이후 실험 참가자들에게 로봇에 대한 신뢰도를 측정하여 본 연구가 진행되었다. 결과적으로 competence-apology 방법이 가장 높은 신뢰도를 나타내었으며, 향후 인간 로봇 상호작용 실험 디자인에서 본 연구와 같이 신뢰라는 개념에 대해 고려해야함을 시사하였다. 장단점 실제 인간과 인간 상호작용에서 발생하는 신뢰 깨짐과 회복 경우의 수를 분석하여, 인간과 로봇이 상호작용하는 상황에 적용하여 실험을 진행한 점이 흥미로웠다. 또한 real time으로 신뢰도를 측정하고 분석한 측면이 실험의 신뢰도를 높혔다고 생각된다. 반면, 실제 참가자들의 인터뷰 내용이 나와있지 않은 측면은 아쉬움으로 남는다. 참고 문헌 Sebo, S. S., Krishnamurthi, P., &amp; Scassellati, B. (2019). “I Don’t Believe You”: Investigating the Effects of Robot Trust Violation and Repair. In 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), 57-65" />
<meta property="og:description" content="Themes: Sympathy and Empathy in a Chatbot, Empathy: A Review of the Concept, HRI, Trust Violation, and Repair Presenters: YJ (Yoonwon Jeong), IL (Inju Lee), HM (Hoyoung Maeng) Topic 1: Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot [YJ] 선정 이유 공감하는 챗봇이 인간-AI 상호작용에 있어 가지는 효과에 대한 실험 연구를 읽어보고자 하여 선정하였다. 내용 요약 사람들은 다른 사람과 상호작용을 할 때 정서적인 지지를 기반으로 한 의사소통을 선호하지만, 인공지능 에이전트와의 상호작용에 있어서도 같은 것을 원하는지는 명확히 밝혀지지 않았으며, 특히 그러한 경향성의 기반이 되는 심리학적 과정이 어떤 것인지에 대한 탐구는 상대적으로 부족하다. 본 연구에서는 헬스케어 관련 정보와 개인적 문제에 대한 상담을 제공하는 챗봇을 사용하여 CASA와 Uncanny Valley of Mind(UVM)라는 두 개의 이론적 관점 중 어느 것이 인간-챗봇 상호작용에서 감정적 지지 방법으로서의 인지적 공감(cognitive empathy), 정서적 공감(affective empathy), 그리고 동정심(sympathy) 표현의 역할을 설명할지 알아보고자 하였다. Study1에서는 챗봇과 인간의 대화 내용을 텍스트화한 시나리오를 보여준 후 참여자의 인식을 평가하였고, Study2에서는 참여자가 챗봇과 직접 대화한 경험을 토대로 척도에 응답하였다. 실험 결과, 참여자들은 동정심과 정서적 공감은 통제 조건보다 더 지지적이라고 평가하였고, 로봇의 감정적 능력 혹은 지능에 대한 참여자들의 믿음이 챗봇의 동정과 공감에 대한 반응을 조절하였다. 로봇이 감정을 가질 수 있다고 믿는 사람들은 정서적 공감을 표출하는 챗봇에 대해 더 이상함(uncanny)을 느껴 UVM모델에 부합하였으나, 동정심과 정서적 공감을 보이는 로봇에 대한 긍정적인 지각 및 평가는 로봇의 능력을 믿지 않는 사람들에게서만 나타나, CASA패러다임에 더 부합하였다. 또한 study1에서는 챗봇의 감정 인식에 대한 지각과 챗봇의 감정 이해가 3개의 공감 감정 표현 실험 조건과 이상함의 관계를 매개하였으나, study2에서는 챗봇의 슬픔에 대한 지각이 그 관계를 매개하는 것으로 나타났다. 본 논문에서는 두 study에서 modality차이가 인간-AI상호작용 상황에서 챗봇의 사회감정적 측면과 인지적 능력 중 무엇이 더 현저하게(salient)보이는지의 차이를 가져왔기 때문일 수 있다고 설명하였다. 장단점 perceived sadness, perceived recognition, perceived understanding을 mediator variable로 사용하여 분석했는데, 그것이 각각 무엇을 정확히 측정하였고 왜 mediating variable로 선정하였는지에 대한 설명이 부족한 점이 아쉽다. Study1과 2의 결과가 일관적이지 않은 점이 한계점으로 보이고, 그로 인해 인지적 공감, 정서적 공감, 동정심 3가지를 구분하여 연구에 사용하였으나 study2에서 그 세 개를 합쳐서 empathic expression이라는 새로운 구성개념을 만들어 결과를 낸 점이 서론에서 언급한 연구의 본래 목적과 잘 맞지 않게 되어 아쉽다. 의의 로봇 대화 디자인할 시 AI가 공감을 표현하는 가장 좋은 방법을 실용적으로 제시하였다는 함의가 있다. 참고 문헌 Liu, B., &amp; Sundar, S. S. (2018). Should machines express sympathy and empathy? Experiments with a health advice chatbot. Cyberpsychology, Behavior, and Social Networking, 21(10), 625-636. Topic 2: Empathy: A Review of the Concept [IL] 선정 이유 “공감”이 무엇인지 정리하고 싶어 읽어보았다. 내용 요약 본 논문은 공감을 개념화한 다양한 연구들을 리뷰하여, 8가지 속성에 대하여 공감을 체계적으로 분석하였고, 이를 바탕으로 공감을 총체적으로 개념화하였다. Distinguishing Empathy From Other Concepts Sympathy: 공감은 관찰자가 대상과 동일한 감정을 느끼는 상태인 반면, sympathy는 관찰자가 대상에 대하여 감정을 느끼는 상태이다(대상과 동일한 감정을 느끼는 것이 아니다). Compassion &amp; Tenderness: compassion은 타인의 고통을 보았을 때 타인을 도와주고 싶은 마음이 드는 상태를 의미하며, tenderness는 약한 타인을 따뜻하게 대해주고 싶은 상태를 의미한다. 둘 다 타인의 역경에 대한 관찰자의 감정과 관련된 것으로 sympathy에 더 가까운 개념이다. Cognitive or Affective? 공감의 인지적 요소와 정서적 요소는 별개의 개념이지만 서로 상호작용한다. 공감에 있어 반드시 정서적 요소가 필요한지, 아니면 인지적인 공감 자체만으로도 공감으로 볼 수 있을지에 관해 논쟁이 있다. 널리 받아들여지고 있는 견해에 따라 공감에 있어 정서적 요소를 배제시킬 수는 없을 것이다. 인지적 공감과 perspective-taking을 같은 개념으로 볼 수 있을지에 관한 논쟁도 존재한다. Congruent or Incongruent? 공감에 있어 관찰자와 공감의 대상이 느끼는 감정이 반드시 동일해야 하는지에 관한 논쟁이 있다. 이는 타인의 생각과 감정을 정확하게 추론하는 능력인 공감적 정확성(empathic accuracy)과 관련된다. 관찰자가 대상과 “완전히” 동일한 감정을 느끼는 것은 매우 어렵고, 실제로 사람들은 공감적 정확성과 관계 없이 그들이 느끼는 공감적 경험에 기반하여 행동한다. Subject to Other Stimuli? 공감의 대상과 그 대상의 감정적인 정보가 실제적으로 존재하지 않아도 사람들은 perspective-taking, 상상, 자신의 기억 및 경험 등을 바탕으로 충분히 공감할 수 있다. 공감은 다양한 감정에 의해 유발되며, 개인들의 공감 능력은 공감을 해야하는 감정이 무엇인지에 따라 달라질 수 있다. Self/Other Distinction or Merging? 관찰자가 자신이 느끼는 감정이 외부의 자극으로부터 발생했다는 것을 지각하는 것은 공감과 emotional contagion을 구분하는 기준이 된다. Trait or State Influences? 공감은 trait의 속성을 가지지만, 관찰자와 대상과의 유사성, 대상을 얼마나 가치있게 생각하는지, 관찰자의 기분 등과 같은 상황적 요소(state)에도 영향을 받는다. Has a Behavioural Outcome? 단일 개념으로서의 공감은 공감으로부터 유발되는 행동과는 분리된 별개의 개념으로 본다. 공감이 행동의 동기가 될 수 있지만 공감이 행동적 요소를 포함하고 있다고 보기는 어렵다. Automatic or Controlled? 공감은 자동적으로 유발될 수도 있고 관찰자의 인지적 노력에 의해서 조절되어질 수도 있다. 의의 공감에 대한 정의를 총체적으로 정리하였기 때문에 공감의 개념과 속성을 정리하는 데에 도움이 될 수 있는 논문이다. 참고 문헌 Cuff, B. M., Brown, S. J., Taylor, L., &amp; Howat, D. J. (2016). Empathy: A review of the concept. Emotion review, 8(2), 144-153. Topic 3: HRI, Trust Violation and Repair [HM] 선정 이유 인공지능 에이전트와 인간의 상호작용에서 신뢰를 판단하는 척도와 영향을 확인하기 위해서. 내용 요약 본 연구는 인간과 로봇의 상호작용 상황에서 신뢰가 깨지고, 복귀되는 방법에 대하여 각각 2가지 방법을 적용하여 실험이 진행되었다. 신뢰가 깨지는 상황 : Competence trust violation vs Integrity-based trust violation 이때 competence는 고의가 아닌 실수로 신뢰가 깨지는 상황을 말하며, 화자의 능력부족 혹은 스킬 부족과 같은 상황을 나타낸다. 반면 integrity는 화자의 고의로 인하여 신뢰가 깨지는 상황이다. 신뢰를 회복하는 방법 : apology vs denial 앞선 신뢰가 깨진 상황에서, 자신의 잘못을 인정하고 바로 사과를 하는 apology와 자신의 잘못을 부정하고 부인하는 denial 방법이 각각 적용되었다 실험 참가자들은 나오(Nao)라는 인공지능 로봇과 real time으로 태블릿에서 우주선으로 소행성을 파괴하는 게임을 하였다. 이때 로봇은 실험 참여자들에게 상대방의 우주선을 고정시키지 않겠다는 약속을 하였다. 그러나 실제로는 그 약속을 지키지 않았고 이 과정에서 trust violation이 발생하였다. 이후 다음과 같은 4가지 형식의 대화를 통해 로봇은 인간에게 신뢰를 회복하기 위해 노력하였다. 이후 실험 참가자들에게 로봇에 대한 신뢰도를 측정하여 본 연구가 진행되었다. 결과적으로 competence-apology 방법이 가장 높은 신뢰도를 나타내었으며, 향후 인간 로봇 상호작용 실험 디자인에서 본 연구와 같이 신뢰라는 개념에 대해 고려해야함을 시사하였다. 장단점 실제 인간과 인간 상호작용에서 발생하는 신뢰 깨짐과 회복 경우의 수를 분석하여, 인간과 로봇이 상호작용하는 상황에 적용하여 실험을 진행한 점이 흥미로웠다. 또한 real time으로 신뢰도를 측정하고 분석한 측면이 실험의 신뢰도를 높혔다고 생각된다. 반면, 실제 참가자들의 인터뷰 내용이 나와있지 않은 측면은 아쉬움으로 남는다. 참고 문헌 Sebo, S. S., Krishnamurthi, P., &amp; Scassellati, B. (2019). “I Don’t Believe You”: Investigating the Effects of Robot Trust Violation and Repair. In 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), 57-65" />
<link rel="canonical" href="http://localhost:4000/blog/2021-04-29/study" />
<meta property="og:url" content="http://localhost:4000/blog/2021-04-29/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-04-29T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Apr 29th Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jae Eun Park (dawn2089@snu.ac.kr)"},"dateModified":"2021-04-29T00:00:00+09:00","datePublished":"2021-04-29T00:00:00+09:00","description":"Themes: Sympathy and Empathy in a Chatbot, Empathy: A Review of the Concept, HRI, Trust Violation, and Repair Presenters: YJ (Yoonwon Jeong), IL (Inju Lee), HM (Hoyoung Maeng) Topic 1: Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot [YJ] 선정 이유 공감하는 챗봇이 인간-AI 상호작용에 있어 가지는 효과에 대한 실험 연구를 읽어보고자 하여 선정하였다. 내용 요약 사람들은 다른 사람과 상호작용을 할 때 정서적인 지지를 기반으로 한 의사소통을 선호하지만, 인공지능 에이전트와의 상호작용에 있어서도 같은 것을 원하는지는 명확히 밝혀지지 않았으며, 특히 그러한 경향성의 기반이 되는 심리학적 과정이 어떤 것인지에 대한 탐구는 상대적으로 부족하다. 본 연구에서는 헬스케어 관련 정보와 개인적 문제에 대한 상담을 제공하는 챗봇을 사용하여 CASA와 Uncanny Valley of Mind(UVM)라는 두 개의 이론적 관점 중 어느 것이 인간-챗봇 상호작용에서 감정적 지지 방법으로서의 인지적 공감(cognitive empathy), 정서적 공감(affective empathy), 그리고 동정심(sympathy) 표현의 역할을 설명할지 알아보고자 하였다. Study1에서는 챗봇과 인간의 대화 내용을 텍스트화한 시나리오를 보여준 후 참여자의 인식을 평가하였고, Study2에서는 참여자가 챗봇과 직접 대화한 경험을 토대로 척도에 응답하였다. 실험 결과, 참여자들은 동정심과 정서적 공감은 통제 조건보다 더 지지적이라고 평가하였고, 로봇의 감정적 능력 혹은 지능에 대한 참여자들의 믿음이 챗봇의 동정과 공감에 대한 반응을 조절하였다. 로봇이 감정을 가질 수 있다고 믿는 사람들은 정서적 공감을 표출하는 챗봇에 대해 더 이상함(uncanny)을 느껴 UVM모델에 부합하였으나, 동정심과 정서적 공감을 보이는 로봇에 대한 긍정적인 지각 및 평가는 로봇의 능력을 믿지 않는 사람들에게서만 나타나, CASA패러다임에 더 부합하였다. 또한 study1에서는 챗봇의 감정 인식에 대한 지각과 챗봇의 감정 이해가 3개의 공감 감정 표현 실험 조건과 이상함의 관계를 매개하였으나, study2에서는 챗봇의 슬픔에 대한 지각이 그 관계를 매개하는 것으로 나타났다. 본 논문에서는 두 study에서 modality차이가 인간-AI상호작용 상황에서 챗봇의 사회감정적 측면과 인지적 능력 중 무엇이 더 현저하게(salient)보이는지의 차이를 가져왔기 때문일 수 있다고 설명하였다. 장단점 perceived sadness, perceived recognition, perceived understanding을 mediator variable로 사용하여 분석했는데, 그것이 각각 무엇을 정확히 측정하였고 왜 mediating variable로 선정하였는지에 대한 설명이 부족한 점이 아쉽다. Study1과 2의 결과가 일관적이지 않은 점이 한계점으로 보이고, 그로 인해 인지적 공감, 정서적 공감, 동정심 3가지를 구분하여 연구에 사용하였으나 study2에서 그 세 개를 합쳐서 empathic expression이라는 새로운 구성개념을 만들어 결과를 낸 점이 서론에서 언급한 연구의 본래 목적과 잘 맞지 않게 되어 아쉽다. 의의 로봇 대화 디자인할 시 AI가 공감을 표현하는 가장 좋은 방법을 실용적으로 제시하였다는 함의가 있다. 참고 문헌 Liu, B., &amp; Sundar, S. S. (2018). Should machines express sympathy and empathy? Experiments with a health advice chatbot. Cyberpsychology, Behavior, and Social Networking, 21(10), 625-636. Topic 2: Empathy: A Review of the Concept [IL] 선정 이유 “공감”이 무엇인지 정리하고 싶어 읽어보았다. 내용 요약 본 논문은 공감을 개념화한 다양한 연구들을 리뷰하여, 8가지 속성에 대하여 공감을 체계적으로 분석하였고, 이를 바탕으로 공감을 총체적으로 개념화하였다. Distinguishing Empathy From Other Concepts Sympathy: 공감은 관찰자가 대상과 동일한 감정을 느끼는 상태인 반면, sympathy는 관찰자가 대상에 대하여 감정을 느끼는 상태이다(대상과 동일한 감정을 느끼는 것이 아니다). Compassion &amp; Tenderness: compassion은 타인의 고통을 보았을 때 타인을 도와주고 싶은 마음이 드는 상태를 의미하며, tenderness는 약한 타인을 따뜻하게 대해주고 싶은 상태를 의미한다. 둘 다 타인의 역경에 대한 관찰자의 감정과 관련된 것으로 sympathy에 더 가까운 개념이다. Cognitive or Affective? 공감의 인지적 요소와 정서적 요소는 별개의 개념이지만 서로 상호작용한다. 공감에 있어 반드시 정서적 요소가 필요한지, 아니면 인지적인 공감 자체만으로도 공감으로 볼 수 있을지에 관해 논쟁이 있다. 널리 받아들여지고 있는 견해에 따라 공감에 있어 정서적 요소를 배제시킬 수는 없을 것이다. 인지적 공감과 perspective-taking을 같은 개념으로 볼 수 있을지에 관한 논쟁도 존재한다. Congruent or Incongruent? 공감에 있어 관찰자와 공감의 대상이 느끼는 감정이 반드시 동일해야 하는지에 관한 논쟁이 있다. 이는 타인의 생각과 감정을 정확하게 추론하는 능력인 공감적 정확성(empathic accuracy)과 관련된다. 관찰자가 대상과 “완전히” 동일한 감정을 느끼는 것은 매우 어렵고, 실제로 사람들은 공감적 정확성과 관계 없이 그들이 느끼는 공감적 경험에 기반하여 행동한다. Subject to Other Stimuli? 공감의 대상과 그 대상의 감정적인 정보가 실제적으로 존재하지 않아도 사람들은 perspective-taking, 상상, 자신의 기억 및 경험 등을 바탕으로 충분히 공감할 수 있다. 공감은 다양한 감정에 의해 유발되며, 개인들의 공감 능력은 공감을 해야하는 감정이 무엇인지에 따라 달라질 수 있다. Self/Other Distinction or Merging? 관찰자가 자신이 느끼는 감정이 외부의 자극으로부터 발생했다는 것을 지각하는 것은 공감과 emotional contagion을 구분하는 기준이 된다. Trait or State Influences? 공감은 trait의 속성을 가지지만, 관찰자와 대상과의 유사성, 대상을 얼마나 가치있게 생각하는지, 관찰자의 기분 등과 같은 상황적 요소(state)에도 영향을 받는다. Has a Behavioural Outcome? 단일 개념으로서의 공감은 공감으로부터 유발되는 행동과는 분리된 별개의 개념으로 본다. 공감이 행동의 동기가 될 수 있지만 공감이 행동적 요소를 포함하고 있다고 보기는 어렵다. Automatic or Controlled? 공감은 자동적으로 유발될 수도 있고 관찰자의 인지적 노력에 의해서 조절되어질 수도 있다. 의의 공감에 대한 정의를 총체적으로 정리하였기 때문에 공감의 개념과 속성을 정리하는 데에 도움이 될 수 있는 논문이다. 참고 문헌 Cuff, B. M., Brown, S. J., Taylor, L., &amp; Howat, D. J. (2016). Empathy: A review of the concept. Emotion review, 8(2), 144-153. Topic 3: HRI, Trust Violation and Repair [HM] 선정 이유 인공지능 에이전트와 인간의 상호작용에서 신뢰를 판단하는 척도와 영향을 확인하기 위해서. 내용 요약 본 연구는 인간과 로봇의 상호작용 상황에서 신뢰가 깨지고, 복귀되는 방법에 대하여 각각 2가지 방법을 적용하여 실험이 진행되었다. 신뢰가 깨지는 상황 : Competence trust violation vs Integrity-based trust violation 이때 competence는 고의가 아닌 실수로 신뢰가 깨지는 상황을 말하며, 화자의 능력부족 혹은 스킬 부족과 같은 상황을 나타낸다. 반면 integrity는 화자의 고의로 인하여 신뢰가 깨지는 상황이다. 신뢰를 회복하는 방법 : apology vs denial 앞선 신뢰가 깨진 상황에서, 자신의 잘못을 인정하고 바로 사과를 하는 apology와 자신의 잘못을 부정하고 부인하는 denial 방법이 각각 적용되었다 실험 참가자들은 나오(Nao)라는 인공지능 로봇과 real time으로 태블릿에서 우주선으로 소행성을 파괴하는 게임을 하였다. 이때 로봇은 실험 참여자들에게 상대방의 우주선을 고정시키지 않겠다는 약속을 하였다. 그러나 실제로는 그 약속을 지키지 않았고 이 과정에서 trust violation이 발생하였다. 이후 다음과 같은 4가지 형식의 대화를 통해 로봇은 인간에게 신뢰를 회복하기 위해 노력하였다. 이후 실험 참가자들에게 로봇에 대한 신뢰도를 측정하여 본 연구가 진행되었다. 결과적으로 competence-apology 방법이 가장 높은 신뢰도를 나타내었으며, 향후 인간 로봇 상호작용 실험 디자인에서 본 연구와 같이 신뢰라는 개념에 대해 고려해야함을 시사하였다. 장단점 실제 인간과 인간 상호작용에서 발생하는 신뢰 깨짐과 회복 경우의 수를 분석하여, 인간과 로봇이 상호작용하는 상황에 적용하여 실험을 진행한 점이 흥미로웠다. 또한 real time으로 신뢰도를 측정하고 분석한 측면이 실험의 신뢰도를 높혔다고 생각된다. 반면, 실제 참가자들의 인터뷰 내용이 나와있지 않은 측면은 아쉬움으로 남는다. 참고 문헌 Sebo, S. S., Krishnamurthi, P., &amp; Scassellati, B. (2019). “I Don’t Believe You”: Investigating the Effects of Robot Trust Violation and Repair. In 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), 57-65","headline":"Apr 29th Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2021-04-29/study"},"url":"http://localhost:4000/blog/2021-04-29/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Jae Eun Park (dawn2089@snu.ac.kr)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2021-04-29 00:00:00 +0900">April 29, 2021</time>
    
  </div>

  <h1 class="post-title">Apr 29th Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: Sympathy and Empathy in a Chatbot, Empathy: A Review of the Concept, HRI, Trust Violation, and Repair
</code></pre></div></div>

<p>Presenters: YJ (Yoonwon Jeong), IL (Inju Lee), HM (Hoyoung Maeng) <br /></p>

<hr />

<h1 id="topic-1-should-machines-express-sympathy-and-empathy-experiments-with-a-health-advice-chatbot-yj">Topic 1: Should Machines Express Sympathy and Empathy? Experiments with a Health Advice Chatbot [YJ]</h1>

<h3 id="선정-이유"><strong>선정 이유</strong></h3>
<p>공감하는 챗봇이 인간-AI 상호작용에 있어 가지는 효과에 대한 실험 연구를 읽어보고자 하여 선정하였다.<br /></p>

<h3 id="내용-요약"><strong>내용 요약</strong></h3>
<p>사람들은 다른 사람과 상호작용을 할 때 정서적인 지지를 기반으로 한 의사소통을 선호하지만, 인공지능 에이전트와의 상호작용에 있어서도 같은 것을 원하는지는 명확히 밝혀지지 않았으며, 특히 그러한 경향성의 기반이 되는 심리학적 과정이 어떤 것인지에 대한 탐구는 상대적으로 부족하다. 본 연구에서는 헬스케어 관련 정보와 개인적 문제에 대한 상담을 제공하는 챗봇을 사용하여 CASA와 Uncanny Valley of Mind(UVM)라는 두 개의 이론적 관점 중 어느 것이 인간-챗봇 상호작용에서 감정적 지지 방법으로서의 인지적 공감(cognitive empathy), 정서적 공감(affective empathy), 그리고 동정심(sympathy) 표현의 역할을 설명할지 알아보고자 하였다. <br />
Study1에서는 챗봇과 인간의 대화 내용을 텍스트화한 시나리오를 보여준 후 참여자의 인식을 평가하였고, Study2에서는 참여자가 챗봇과 직접 대화한 경험을 토대로 척도에 응답하였다. 실험 결과, 참여자들은 동정심과 정서적 공감은 통제 조건보다 더 지지적이라고 평가하였고, 로봇의 감정적 능력 혹은 지능에 대한 참여자들의 믿음이 챗봇의 동정과 공감에 대한 반응을 조절하였다. 로봇이 감정을 가질 수 있다고 믿는 사람들은 정서적 공감을 표출하는 챗봇에 대해 더 이상함(uncanny)을 느껴 UVM모델에 부합하였으나, 동정심과 정서적 공감을 보이는 로봇에 대한 긍정적인 지각 및 평가는 로봇의 능력을 믿지 않는 사람들에게서만 나타나, CASA패러다임에 더 부합하였다. 또한 study1에서는 챗봇의 감정 인식에 대한 지각과 챗봇의 감정 이해가 3개의 공감 감정 표현 실험 조건과 이상함의 관계를 매개하였으나, study2에서는 챗봇의 슬픔에 대한 지각이 그 관계를 매개하는 것으로 나타났다. 본 논문에서는 두 study에서 modality차이가 인간-AI상호작용 상황에서 챗봇의 사회감정적 측면과 인지적 능력 중 무엇이 더 현저하게(salient)보이는지의 차이를 가져왔기 때문일 수 있다고 설명하였다.  <br /></p>

<h3 id="장단점"><strong>장단점</strong></h3>
<p>perceived sadness, perceived recognition, perceived understanding을 mediator variable로 사용하여 분석했는데, 그것이 각각 무엇을 정확히 측정하였고 왜 mediating variable로 선정하였는지에 대한 설명이 부족한 점이 아쉽다.<br />
Study1과 2의 결과가 일관적이지 않은 점이 한계점으로 보이고, 그로 인해 인지적 공감, 정서적 공감, 동정심 3가지를 구분하여 연구에 사용하였으나 study2에서 그 세 개를 합쳐서 empathic expression이라는 새로운 구성개념을 만들어 결과를 낸 점이 서론에서 언급한 연구의 본래 목적과 잘 맞지 않게 되어 아쉽다. <br /></p>

<h3 id="의의"><strong>의의</strong></h3>
<p>로봇 대화 디자인할 시 AI가 공감을 표현하는 가장 좋은 방법을 실용적으로 제시하였다는 함의가 있다. <br /></p>

<h3 id="참고-문헌"><strong>참고 문헌</strong></h3>
<p>Liu, B., &amp; Sundar, S. S. (2018). Should machines express sympathy and empathy? Experiments with a health advice chatbot. Cyberpsychology, Behavior, and Social Networking, 21(10), 625-636.<br /></p>

<h1 id="topic-2-empathy-a-review-of-the-concept-il">Topic 2: Empathy: A Review of the Concept [IL]</h1>

<h3 id="선정-이유-1"><strong>선정 이유</strong></h3>

<p>“공감”이 무엇인지 정리하고 싶어 읽어보았다. <br /></p>

<h3 id="내용-요약-1"><strong>내용 요약</strong></h3>

<p>본 논문은 공감을 개념화한 다양한 연구들을 리뷰하여, 8가지 속성에 대하여 공감을 체계적으로 분석하였고, 이를 바탕으로 공감을 총체적으로 개념화하였다. <br /></p>

<ol>
  <li>Distinguishing Empathy From Other Concepts <br />
    <ul>
      <li>Sympathy: 공감은 관찰자가 대상과 동일한 감정을 느끼는 상태인 반면, sympathy는 관찰자가 대상에 대하여 감정을 느끼는 상태이다(대상과 동일한 감정을 느끼는 것이 아니다).<br /></li>
      <li>Compassion &amp; Tenderness: compassion은 타인의 고통을 보았을 때 타인을 도와주고 싶은 마음이 드는 상태를 의미하며, tenderness는 약한 타인을 따뜻하게 대해주고 싶은 상태를 의미한다. 둘 다 타인의 역경에 대한 관찰자의 감정과 관련된 것으로 sympathy에 더 가까운 개념이다.<br /></li>
    </ul>
  </li>
  <li>Cognitive or Affective?<br />
    <ul>
      <li>공감의 인지적 요소와 정서적 요소는 별개의 개념이지만 서로 상호작용한다.<br /></li>
      <li>공감에 있어 반드시 정서적 요소가 필요한지, 아니면 인지적인 공감 자체만으로도 공감으로 볼 수 있을지에 관해 논쟁이 있다. 널리 받아들여지고 있는 견해에 따라 공감에 있어 정서적 요소를 배제시킬 수는 없을 것이다.<br /></li>
      <li>인지적 공감과 perspective-taking을 같은 개념으로 볼 수 있을지에 관한 논쟁도 존재한다.<br /></li>
    </ul>
  </li>
  <li>Congruent or Incongruent? <br />
    <ul>
      <li>공감에 있어 관찰자와 공감의 대상이 느끼는 감정이 반드시 동일해야 하는지에 관한 논쟁이 있다. 이는 타인의 생각과 감정을 정확하게 추론하는 능력인 공감적 정확성(empathic accuracy)과 관련된다. 관찰자가 대상과 “완전히” 동일한 감정을 느끼는 것은 매우 어렵고, 실제로 사람들은 공감적 정확성과 관계 없이 그들이 느끼는 공감적 경험에 기반하여 행동한다. <br /></li>
    </ul>
  </li>
  <li>Subject to Other Stimuli? <br />
    <ul>
      <li>공감의 대상과 그 대상의 감정적인 정보가 실제적으로 존재하지 않아도 사람들은 perspective-taking, 상상, 자신의 기억 및 경험 등을 바탕으로 충분히 공감할 수 있다.<br /></li>
      <li>공감은 다양한 감정에 의해 유발되며, 개인들의 공감 능력은 공감을 해야하는 감정이 무엇인지에 따라 달라질 수 있다.<br /></li>
    </ul>
  </li>
  <li>Self/Other Distinction or Merging? <br />
    <ul>
      <li>관찰자가 자신이 느끼는 감정이 외부의 자극으로부터 발생했다는 것을 지각하는 것은 공감과 emotional contagion을 구분하는 기준이 된다.<br /></li>
    </ul>
  </li>
  <li>Trait or State Influences?<br />
    <ul>
      <li>공감은 trait의 속성을 가지지만, 관찰자와 대상과의 유사성, 대상을 얼마나 가치있게 생각하는지, 관찰자의 기분 등과 같은 상황적 요소(state)에도 영향을 받는다.<br /></li>
    </ul>
  </li>
  <li>Has a Behavioural Outcome? <br />
    <ul>
      <li>단일 개념으로서의 공감은 공감으로부터 유발되는 행동과는 분리된 별개의 개념으로 본다. 공감이 행동의 동기가 될 수 있지만 공감이 행동적 요소를 포함하고 있다고 보기는 어렵다.<br /></li>
    </ul>
  </li>
  <li>Automatic or Controlled?<br />
    <ul>
      <li>공감은 자동적으로 유발될 수도 있고 관찰자의 인지적 노력에 의해서 조절되어질 수도 있다.<br /></li>
    </ul>
  </li>
</ol>

<h3 id="의의-1"><strong>의의</strong></h3>

<p>공감에 대한 정의를 총체적으로 정리하였기 때문에 공감의 개념과 속성을 정리하는 데에 도움이 될 수 있는 논문이다. <br /></p>

<h3 id="참고-문헌-1"><strong>참고 문헌</strong></h3>

<p>Cuff, B. M., Brown, S. J., Taylor, L., &amp; Howat, D. J. (2016). Empathy: A review of the concept. Emotion review, 8(2), 144-153. <br /></p>

<h1 id="topic-3-hri-trust-violation-and-repair-hm">Topic 3: HRI, Trust Violation and Repair [HM]</h1>

<h3 id="선정-이유-2"><strong>선정 이유</strong></h3>

<p>인공지능 에이전트와 인간의 상호작용에서 신뢰를 판단하는 척도와 영향을 확인하기 위해서.<br /></p>

<h3 id="내용-요약-2"><strong>내용 요약</strong></h3>

<p>본 연구는 인간과 로봇의 상호작용 상황에서 신뢰가 깨지고, 복귀되는 방법에 대하여 각각 2가지 방법을 적용하여 실험이 진행되었다.<br /></p>

<ul>
  <li>신뢰가 깨지는 상황 : Competence trust violation vs Integrity-based trust violation <br /></li>
</ul>

<p>이때 competence는 고의가 아닌 실수로 신뢰가 깨지는 상황을 말하며, 화자의 능력부족 혹은 스킬 부족과 같은 상황을 나타낸다. 반면 integrity는 화자의 고의로 인하여 신뢰가 깨지는 상황이다.<br /></p>

<ul>
  <li>신뢰를 회복하는 방법 : apology vs denial <br /></li>
</ul>

<p>앞선 신뢰가 깨진 상황에서, 자신의 잘못을 인정하고 바로 사과를 하는 apology와 자신의 잘못을 부정하고 부인하는 denial 방법이 각각 적용되었다 <br /></p>

<p>실험 참가자들은 나오(Nao)라는 인공지능 로봇과 real time으로 태블릿에서 우주선으로 소행성을 파괴하는 게임을 하였다. 이때 로봇은 실험 참여자들에게 상대방의 우주선을 고정시키지 않겠다는 약속을 하였다. 그러나 실제로는 그 약속을 지키지 않았고 이 과정에서 trust violation이 발생하였다. 이후 다음과 같은 4가지 형식의 대화를 통해 로봇은 인간에게 신뢰를 회복하기 위해 노력하였다. 이후 실험 참가자들에게 로봇에 대한 신뢰도를 측정하여 본 연구가 진행되었다. <br /></p>

<p>결과적으로 competence-apology 방법이 가장 높은 신뢰도를 나타내었으며, 향후 인간 로봇 상호작용 실험 디자인에서 본 연구와 같이 신뢰라는 개념에 대해 고려해야함을 시사하였다.<br /></p>

<h3 id="장단점-1"><strong>장단점</strong></h3>

<p>실제 인간과 인간 상호작용에서 발생하는 신뢰 깨짐과 회복 경우의 수를 분석하여, 인간과 로봇이 상호작용하는 상황에 적용하여 실험을 진행한 점이 흥미로웠다. <br /></p>

<p>또한 real time으로 신뢰도를 측정하고 분석한 측면이 실험의 신뢰도를 높혔다고 생각된다.<br /></p>

<p>반면, 실제 참가자들의 인터뷰 내용이 나와있지 않은 측면은 아쉬움으로 남는다.<br /></p>

<h3 id="참고-문헌-2"><strong>참고 문헌</strong></h3>

<p>Sebo, S. S., Krishnamurthi, P., &amp; Scassellati, B. (2019). “I Don’t Believe You”: Investigating the Effects of Robot Trust Violation and Repair. In 2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI), 57-65 <br /></p>


</div>

<div class="pagination">
  
    <a href="/blog/2021-05-20/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2021-04-15/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
