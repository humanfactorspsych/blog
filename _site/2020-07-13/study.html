<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>July 13th Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="July 13th Journal Club" />
<meta name="author" content="Soomin Cho (soominc3@illinois.edu)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: Predictive Modelling, Theory of Mind(ToM), Word2Vec, Artificial General Intelligence(AGI), Reinforcement Learning, Mood Contagion" />
<meta property="og:description" content="Themes: Predictive Modelling, Theory of Mind(ToM), Word2Vec, Artificial General Intelligence(AGI), Reinforcement Learning, Mood Contagion" />
<link rel="canonical" href="http://localhost:4000/blog/2020-07-13/study" />
<meta property="og:url" content="http://localhost:4000/blog/2020-07-13/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-13T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="July 13th Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Soomin Cho (soominc3@illinois.edu)"},"dateModified":"2020-07-13T00:00:00+09:00","datePublished":"2020-07-13T00:00:00+09:00","description":"Themes: Predictive Modelling, Theory of Mind(ToM), Word2Vec, Artificial General Intelligence(AGI), Reinforcement Learning, Mood Contagion","headline":"July 13th Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2020-07-13/study"},"url":"http://localhost:4000/blog/2020-07-13/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Soomin Cho (soominc3@illinois.edu)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-07-13 00:00:00 +0900">July 13, 2020</time>
    
  </div>

  <h1 class="post-title">July 13th Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: Predictive Modelling, Theory of Mind(ToM), Word2Vec, Artificial General Intelligence(AGI), Reinforcement Learning, Mood Contagion 
</code></pre></div></div>

<p>Presenters: YK (Yoon Kyung Lee), YW (Yoonwon Jung), JE (Jaeun Park), IJ (Inju Lee), HY (Hoyoung Maeng), WK (Whani Kim), SC (Soomin Cho) <br />
Guest : HeeYoung Park (Psychometrics Lab)</p>

<hr />

<h2 id="topic-1-predictive-modeling-in-agents-and-question-answering-yk">Topic 1: Predictive Modeling in Agents and Question Answering [YK]</h2>

<p>선정 이유: 에이젼트 학습에 언어를 어떻게 조합했는지 궁금했다. 또한, 에이젼트가 대상에 대한 ‘의미’를 어떻게 표상하고 학습했는지를 알아볼 방법이 궁금했다. <br /></p>

<p>내용 요약: 가상 환경 방안에서 여러 개의 다른 속성 (색깔, 모양, 각도) 을 가진 사물을 하나씩 다 탐색해보게 했다. 그런 다음, 이 사물에 대해 에이젼트가 탐색을 했고 대상의 속성 정보를 제대로 습득했는지를 알아보고자 질의응답 패러다임을 도입했다. 사람이 절차적 지식과 명제적 지식을 따로 구분해서 배우는 것처럼 에이젼트에게도 이러한 지식을 구분하여 학습하도록 했다. 딥마인드의 이전 연구에서 선보였던 SimCore모형과 다른 모형들을 비교했을 때, SimCore 모형으로 학습한 에이젼트가 더 잘 탐색하고 대상의 속성들을 잘 이해했다는 걸 알 수 있었다. Continual Learning이란, 사람이 새로운 환경에 적응하는 동안은 새로운 학습이 이루어지지 않고, 기존에 쌓여두었던 지식과 경험을 활용하는 것에서 착안한 학습 방식이다. Continual learning을 하는 에이젼트는 학습 결과에 대해 알 수 없는 상태에서 계속 (예측)과제를 시행한다. 본 연구에서는 backpropagation을 사용하지 않았는데, 이런 것도 이 이유에서였다(feedback이 없으면 학습도 이루어지지 않는다는 점). <br /></p>

<p>의의: 가상 환경 내에서 에이젼트가 스스로 환경에 대한 명제적 지식 (사물의 색깔, 크기, 각도 등)을 배우도록 했으며 이를 확인하는 방법으로 QA를 사용하였다. 에이젼트 학습은 predictive loss function을 사용하였다 (action-conditional CPC 그리고 SimCore). 질문을 compositional하게 제공함으로써 (color vs shape) 에이젼트가 대상에 대한 지식 또한 compositional하게 처리하는지를 확인할 수 있었다. <br /></p>

<p>장단점</p>
<ol>
  <li>사람이 실제로 명제적, 절차적 지식을 쌓는 과정에 대한 설명이 부족하다. 본 논문의 앞부분은 이러한 지식을 구분해서 학습을 어떻게 했는지를 QA를 통해 더 깊이 알 수 있다는 뉘앙스를 풍겼지만, 결국 환경에 대한 인식(지각) 결과만 있었다. 그림과 요약에 보여주는 예시 질문 (shape, color) 또한 지각 수준에서의 학습에 대한 질문뿐, 실제 추론과 예측이 어떻게 이루어졌는지는 알 수 없다.<br /></li>
  <li>무엇보다도, 사람이 실제 적응하는 과정에서 (zero-shot)학습이 incremental 하게 이루어지는지 아닌지에 대한 전제가 ‘학습이 이루어지지 않는다’인데, 이는 다소 비약적인 것 같다. 새로운 환경에 적응하는 과정에서 사람은 스스로 피드백을 주기도 한다. 예를 들어 어려운 과목의 시험을 치르는 과정에서 그 시험 문제에 대한 정답을 알지 못하더라도 시험이 얼마나 어려운지, 자신이 얼마나 준비가 되었는지, 시험을 치르는 자신의 상태가 어떤지 등 많은 내외부적 환경을 학습한다 (짧은 찰나의 순간이라도). 이렇게 찰나의 순간이라도 학습한 지식은 다음 단계에서 택할 전략 또는 행동 (시험을 두 번째 본다던가, 시험을 포기한다던가 등)에 영향을 준다. Agent가 적응하는 과정에서도 incremental하게 learning이 일어나는지 아닌지에 대한 논의가 더 있었으면 하는 아쉬움이 있고, 이에 대한 다른 분야의 관점도 궁금하다.</li>
</ol>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Das, A., Carnevale, F., Merzic, H., Rimell, L., Schneider, R., Abramson, J., ... &amp; Hill, F. (2020). Probing Emergent Semantics in Predictive Agents via Question Answering. arXiv preprint arXiv:2006.01016.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-2-empathy-compassion-theory-of-mindtom-ij">Topic 2: Empathy, compassion, Theory of Mind(ToM) [IJ]</h2>

<p>선정이유: empathy, compassion, Theory of Mind 간의 관계에 대해 정리해보고 싶어서 선정하였다.
<br /></p>

<p>내용요약 : empathy는 타인의 감정 상태를 공유하는 것을 의미하고, compassion은 타인에 대한 관심 및 따뜻함의 감정과 타인을 도와주고자 하는 동기와 관련되며, ToM은 타인의 mental state에 대한 인지적인 추론을 의미한다. empathy, compassion, ToM은 각자 서로 다른 뇌 영역과 관련된다. 타인과 상호작용하며, 특히 타인의 고통에 마주하게 되었을 때, 사람들은 empathy와 ToM을 통해 사회적인 행동을 한다. 그러나 empathy는 empathic distress라는 본인 스스로의 고통과 asocial behavior를 유발하기도 한다. empathic distress는 compassion으로 바뀔 수 있다. compassion은 타인의 고통에 공감함으로써 유발되는 부정적인 감정을 긍정적인 감정을 만들어내어 상쇄시키는 것으로, 긍정적인 감정의 상향 조절(up-regulation)을 통해 감정을 조절하는 전략이다. empathy와 ToM에 있어 self-other distinction은 중요한 요소이다. empathy와 ToM이 기능할 때 활성화되는 뇌의 영역과 self-other distinction에 있어 중요한 뇌의 영역이 일치한다는 점을 통해 이를 확인할 수 있다. 
<br /></p>

<p>단점: sympathy와 compassion을 같은 개념으로 봐도 되는지 등의 설명이 없어서 아쉽다. 기존 심리학에서 사용해오던 관련 개념 간의 연관성에 대해 짚어주었다면, 관련 개념들을 좀 더 명확하게 정리할 수 있었을 것이다.
<br /></p>

<p>의의: empathy, compassion, Theory of Mind 각각의 개념과 개념 간의 관계를 개념적인 측면과 뇌과학적 측면에서 설명해 놓은 리뷰 논문이다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Preckel, K., Kanske, P., &amp; Singer, T. (2018). On the interaction of social affect and cognition: empathy, compassion and theory of mind. Current Opinion in Behavioral Sciences, 19, 1-6.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-3-nlp-word-vectors-word2vec-glove-je">Topic 3: NLP, word vectors, word2vec, GloVe [JE]</h2>

<p>선정 이유: count-based method와 prediction-based method를 통합하여 워드 벡터를 만드는 방식과 워드 벡터를 평가하는 방식에 관해 공부하기 위해 선정하였다. <br /></p>

<p>내용 요약 <br />
1) word2vec <br />
word2vec에서 corpus의 모든 단어에 대한 probability를 계산하는 대신, computation 비용을 절감하기 위해 stochastic gradient descent (SGD)와 negative sampling을 사용한다. Stochastic gradient descent는 gradient descent 시행 시 sample window를 추출해 gradient를 추정, parameter를 업데이트하는 방식이다. negative sampling이란 center word에 대해 sample window와 random words (negative sample)을 추출, binary logistic regression을 시행해 probability를 계산하는 방식이다. <br />
2) GloVe <br />
word vector를 만드는 방법론은 크게 count-based method와 prediction-based method로 나뉜다. GloVe vector는 단어들의 co-occurrence probability의 비율로 linear meaning component를 나타냄으로써 이 두 가지 방법을 통합하고자 한다. 이러한 방식으로 GloVe vector에서는 단어 간 의미의 차이를 선형 공간 내에서 나타낼 수 있다. <br />
3) Word vector evaluation <br />
word vector evaluation에는 intrinsic과 extrinsic 두 가지 종류가 있다. Intrinsic evaluation이란 워드 벡터가 할 수 있다고 얘기되는 구체적인 subtask를 잘하는지를 평가하는 것이고, extrinsic evaluation은 워드 벡터가 실제로 (로봇, 어플리케이션 등) task에 활용되었을 때의 성능을 평가하는 것을 말한다. intrinsic evaluation 방법에는 analogy evaluation과 correlation evaluation이 있다. <br />
4) 기타 <br />
그 외에도 word vector를 만들 때 ‘the’와 같이 빈번히 출현하는 불용어와 다의어의 경우 어떤 방법으로 접근할지에 대해 다루며, 성능 향상을 위해 hyperparameter를 어떻게 설정해야 하는지에 대해 다룬다.</p>

<p><br />
장점: 좋은 워드 벡터를 만들기 위해 어떠한 방법을 택해야 할지 자세히 설명하였다.
<br /></p>

<p>의의: 다양한 워드 임베딩 방법론과 성능 향상을 위한 방법을 다루었다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Schnabel, Labutov, Mimno, &amp; Joachims (2015). Evaluation methods for unsupervised word embeddings. arXiv preprint.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-4-agiartificial-general-intelligence-hy">Topic 4: AGI(artificial general intelligence) [HY]</h2>

<p>선정 이유: 강한 인공지능에 대한 향후 시각에 대한 일반적인 시선과는 다른 진화론적 방향성을 보여주는 측면에서 흥미로웠다.
<br /></p>

<p>내용 요약 <br />
보통 일반적으로 AI라는 단어를 많이 사용하지만, artificial general intelligence (AGI)는 인간이 할 수 있는 어떠한 지적인 업무도 기계 스스로 성공적으로 해낼 수 있는 기계의 지능을 말한다. 인공지능의 주요 목표이며 강한 인공지능이라고도 불린다. <br />
일반적인 AI: 현재 AI에 대한 일반적인 접근 방식은 인간 개발자가 해결해야 할 문제를 정의하고 관련 데이터를 수집하여, 신경망 아키텍처나 확률론적 그래픽 모델을 설계한 뒤 솔루션을 위한 학습 알고리즘을 적용한다. <br />
AGI 접근법: 에이전트가 처음 직면하는 것을 포함하여 많은 작업에서 우수한 성능을 발휘하는 AI 에이전트를 설계하는 것이다. 즉, 인공지능 스스로 알아서 업무를 수행해낼 수 있도록 설계하는 것을 목표로 한다. <br />
그러나 주의할 점은, 그러한 설계가 이미 주어진 도메인의 집합체일 뿐일 수 있으며, 성취된 결과에만 집중한다는 것이다.
<br />
따라서, EDI(evolutionary and developmental intelligence) 라는 새로운 접근법을 제시한다.
환경에서 능동적인 상호작용을 통해 지능을 획득하는 프로세스에 초점을 맞추는 대안적 접근방식. 환경과 상호작용하는 방식이며, 인간이 지능을 인식하는 프로세스에 집중하는 것, 진화를 통한 지능 획득 과정에 더 주목한다. <br />
1) 신경과학 2) 머신러닝 3) 로봇틱스 3가지 측면에서 분석.
<br /></p>

<p>장점: 현재까지 AI가 발전해왔던 과거를 개괄하고, 이후 앞으로 발전 방향성에 대해 논의하는 측면이 구조적으로 이해하는 데 도움이 되었다.
<br /></p>

<p>단점 : 대략적인 방향성은 설정하였지만, 구체적인 방법 자체를 보여주거나 궁극적인 해결책을 제시하지 않은 측면이 아쉬움으로 남는다.</p>

<p><br /></p>

<p>의의: 인공지능에 대한 지금까지와는 다른 접근방식으로, 향후 강한 인공지능 시대가 올 때를 대비하여 충분히 시도할 수 있는 접근 방식을 제시하였다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Doya, K., &amp; Taniguchi, T. (2019). Toward evolutionary and developmental intelligence. Current Opinion in Behavioral Sciences, 29, 91–96.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-5-meta-reasoning-meta-learning-yw">Topic 5: Meta-reasoning, Meta-learning [YW]</h2>

<p>선정 이유: 머신 러닝에 사용되는 기본 개념을 인간의 인지적 특징과 연관 지어 공부해보고 싶어서 선정하였다. 
<br /></p>

<p>내용 요약:  AI가 매우 구체적인 문제해결을 위해 점점 더 많은 계산과 데이터를 사용하는 반면, 인간은 광범위한 문제해결을 위해 고정된 양의 계산과 제한된 경험을 활용한다. 인간 지능의 이러한 특성들로부터 도출되는 general intelligence의 핵심 능력으로는 메타 추론(meta-reasoning)과 메타 학습(meta-learning)이 있고, 최근 AI 연구들은 이 두 능력을 인공지능 시스템에서 구현하기 위해 노력해왔다. <br /></p>
<ol>
  <li>메타 추론은 계산에 필요한 리소스를 어떻게 할당할지를 결정하는 것으로, “어떻게 생각할지” 혹은 “어떻게 의사결정을 내릴지”에 대한 사고를 통해 인지적 결정을 내리는 것을 의미한다. 메타 추론에 기초한 합리성의 개념은 metalevel rationality 를 거쳐 bounded optimality로 발전했고, 그것을 AI에 구현하기 위한 해법으로 각 계산에 대한 VOC를 효율적으로 근사 시켜 최적의 결정을 찾는 방식이 연구되고 있다. 또한, 메타 추론을 사용한 의사결정의 문제는 sequential decision problem으로 축소 정의하여 MDP(강화학습 문제들을 공식화하는 데에 사용되는 스탠더드)로 표현될 수 있고, Mouselab task를 이용하여 이미 연구된 휴리스틱뿐만 아니라 새로운 상황에서 사람들이 그러한 휴리스틱들을 조합하거나 발전 시켜 새로 만들어내어 사용하는 새로운 전략도 발견할 수 있다. 메타 추론 개념은 AI 관련 연구에서 성능에 제한이 있는 하드웨어를 기반으로 자신을 둘러싼 환경과 실시간으로 상호작용할 수 있는 합리적인 에이전트를 정의하고 디자인하는 데에 중심적 역할을 하고 있다. <br /></li>
  <li>메타 학습은 제한된 데이터만으로도 개념을 학습하거나 유사한 과제들을 해결할 수 있도록 제한된 데이터를 활용하여 학습 환경을 모델링한다. “few-shot” 혹은 “one-shot” 학습을 할 수 있는 인간과 달리, 대량의 데이터를 바탕으로 구체적인 과제만 수행할 수 있는 인공지능의 문제를 해결하고자 연구되고 있다. 메타 학습에서 학습자는 한 개의 구체적인 과제 대신 비슷한 특성을 가진 여러 과제를 학습하게 되고, 그들의 공통점을 찾음으로써 미래의 과제들까지 더 빠르고 효율적으로 해결하는 것을 목표로 한다. 메타 학습은 딥러닝의 기반이 되는 gradient-based learning의 최근 접근법을 사용하고, 이는 task-general component를 파라미터화하는 hyperparameter을 추정하여 학습자의 파라미터를 찾는 방식이다. 이를 통해 주어진 “old task”로부터 향후 추론의 편향(inductive bias) 도출하여 미래 과제 수행 시에 그러한 bias를 가지고 데이터를 효율적으로 사용하여 학습할 수 있도록 한다. Gradient-based 메타 학습은 위계적 베이지안 추론과 밀접한 관련이 있는데, 인지과학의 기존 연구들이 위계적 베이지안 모델을 많이 활용하였음을 고려한다면 이러한 유사성은 인간 학습을 모델링한 인사이트를 현대 머신러닝 시스템으로 전환해 적용하는 데에 중요한 역할을 할 수 있을 것이다.
<br /></li>
</ol>

<p>의의: 인간 지능에 대한 연구를 바탕으로 인공지능의 향후 방향에 대해 고찰하였고, 그 과정에서 인지과학적 연구 결과와 인공지능 구축에 사용되는 구체적인 개념을 연결하여 설명하였다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Griffiths, T. L., Callaway, F., Chang, M. B., Grant, E., Krueger, P. M., &amp; Lieder, F. (2019). Doing more with less: meta-reasoning and meta-learning in humans and machines. Current Opinion in Behavioral Sciences, 29, 24-30.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-6-reinforcement-learning-sc">Topic 6: Reinforcement Learning [SC]</h2>

<p>선정 이유: 강화학습에 지금까지 접근해왔던 model-free approach와 model-based approach의 장단점을 분석하고, 한계점을 보완한 hindsight modelling 을 새롭게 제시했기 때문에 선정하였다.
<br /></p>

<p>내용 요약: x (observation) → Y (future observations) → Z (scalar return)이라는 기본 개념을 토대로 Model-free 접근법은 Y 없이 X와 Z의 직접적인 관계만을 고려하는 반면, Model-based 접근법은 X → Y, Y→ Z의 관계를 관찰한다. 하지만 model-based 모델은 Y 안에 불필요하게 많은 정보가 포함되어 있어서 Z를 예측하기에 약한 시그널을 보낸다. 그러므로 Y의 어떤 부분이 필요하고 필요하지 않은 정보인지 배워야 하고, 양 끝 단에 있는 두 모델 간의 균형을 맞출 수 있는 새로운 모델의 제시가 필요하다. 이때 제시되는 hindsight model은 Y를 additional input으로 해석하고 Y를 통해 X의 정확도를 향상함으로써 더욱더 효과적이고 빠른 강화 학습을 가능하게 한다.
<br /></p>

<p>의의: 기존 모델들을 분석하고 향후 방향만 제시한 것이 아니라 한계점들을 보완한 새로운 모델을 직접 제안했다는 점에서 의의가 있다. 또한 이 모델을 다른 두 연구에 직접 사용함으로써 미래에 더 보완되어야 할 점까지 언급하였다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Guez, A., Viola, F., Weber, T., Buesin, L., Kapturowski, S., Precup, D., ... &amp; Heess, N. (2020). Value-driven hindsight modelling. DeepMind
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-7-hri-mood-contagion-bodily-emotion-expression-wk">Topic 7: HRI, Mood contagion, Bodily emotion expression [WK]</h2>

<p>선정 이유: 학위 논문 관련 로봇의 신체적 감정 표현에 대해 더 알아보기 위해 선정하였다. <br />
<br />
내용 요약: 이 연구에서는 Imitation game을 통해 연구참여자가 로봇이 신체를 통해 표현하는 기분 (mood)을 잘 구별할 수 있는가 (Hypothesis 1), 로봇의 표현하는 mood가 연구참여자에게 transfer 되는가 (H2), 선행 연구 결과를 기반하여 부정적인 컨디션에서 task performance가 높아지는가를 살펴보았다 (H3). 연구참여자는 각 긍정적, 부정적인 제스쳐 (컨디션 별 8개, 총 16개)를 따라 해야 했으며 (within-subjects) 따라 하기 쉬운 컨디션과 따라 하기 힘든 컨디션으로 나누어졌다 (between-subjects). 연구참여자는 난이도와 상관없이 긍정적, 부정적 제스쳐를 잘 구별할 수 있었으며, 낮은 난이도에서 mood contagion effect를 볼 수 있었다. 반면, 어려운 난이도와 부정적인 제스쳐에서 taks performance가 높아진 것을 볼 수 있었다.  <br />
<br />
장단점: 본 연구에서 mood를 살펴본 이유는 emotion과 달리 오랜 시간 동안 유지되며 functional behavior (목적을 가진 행동, i.e. 사물을 옮기는 행동) 를 방해하지 않기 때문이다. 하지만 mood를 살펴보았지만 연구에서는 functional behavior가 없었기 때문에 mood라고 할 수 있는지 의문이다. 또한, imitation game을 통해 mood contagion을 보았기 때문에 일반적인 인간-로봇 상호작용에서도 이 결과가 적용되는지도 의문이다. 하지만 신체적 감정 표현과 이를 통해 mood contagion이 존재하는지를 본 자체가 장점이기도 하다.  <br />
<br />
의의: 사람들은 로봇의 신체적 언어표현을 잘 구별할 수 있으며 이 신체적 언어표현은 사람들의 감정에 영향을 줄 수 있다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Xu, J., Broekens, J., Hindriks, K., &amp; Neerincx, M. A. (2014). Robot mood is contagious: effects of robot body language in the imitation game. In Proceedings of the 2014 international conference on Autonomous agents and multi-agent systems, 973-980
</code></pre></div></div>


</div>

<div class="pagination">
  
    <a href="/blog/2020-07-20/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2020-07-06/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
