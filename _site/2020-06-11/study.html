<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>June 11th Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="June 11th Journal Club" />
<meta name="author" content="Yoon Kyung Lee (yoonlee78@snu.ac.kr)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: Emotion in Computer Vision, Emotion Network, Fairness, Social Robot, Executive Function" />
<meta property="og:description" content="Themes: Emotion in Computer Vision, Emotion Network, Fairness, Social Robot, Executive Function" />
<link rel="canonical" href="http://localhost:4000/blog/2020-06-11/study" />
<meta property="og:url" content="http://localhost:4000/blog/2020-06-11/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-06-11T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="June 11th Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Yoon Kyung Lee (yoonlee78@snu.ac.kr)"},"dateModified":"2020-06-11T00:00:00+09:00","datePublished":"2020-06-11T00:00:00+09:00","description":"Themes: Emotion in Computer Vision, Emotion Network, Fairness, Social Robot, Executive Function","headline":"June 11th Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2020-06-11/study"},"url":"http://localhost:4000/blog/2020-06-11/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Yoon Kyung Lee (yoonlee78@snu.ac.kr)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-06-11 00:00:00 +0900">June 11, 2020</time>
    
  </div>

  <h1 class="post-title">June 11th Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: Emotion in Computer Vision, Emotion Network, Fairness, Social Robot, Executive Function
</code></pre></div></div>

<p>Presenters: YK(Yoon Kyung), YW(Yoonwon), JE(Jaeun), IJ(Injoo), HY(Hoyoung), WK(Whani Kim)</p>

<hr />
<p><br /></p>

<h2 id="topic-1-affect-in-the-wild-yk-">Topic 1: Affect in the Wild [YK] <br /></h2>
<p>선정 이유: 정서가와 각성가에 대한 정보가 담겨있는 오픈 데이터셋인 Aff-Wild에 대해 알아보고자 했다. <br />
내용 요약: 이 페이퍼는 유투브에 존재하는 ‘반응’ 비디오들을 크롤링했다. 다른 사람이나 영화, 노래 등에 대해 오로지 반응하는 것만 담은 데이터셋이다. 반응은 기쁜 반응도 있고 슬픈 반응도 다양하게 있다. 총 298개의 비디오를 약 120만개의 프레임으로 나누어 일일이 감정가(valence)와 각성가(arousal)를 레이블링했다. 비디오 하나가 최대 15분일때, 비디오 하나당 약 4천개 프레임으로 나누어 레이블링한 셈이다. 어노테이터 툴은 이 팀에서 직접 개발했는데, 흔히 인지 심리 실험에서 쓰이는 간단한 (psychopy로 구현할 수 있는) 평정 과제라고 생각하면 된다. <br />
장단점: 영상에 담긴 사람들이 나이가 77세까지 다양했는데, 이 논문이 컴퓨터 시각 성능에 관련된 논문이다보니 사람들의 연령, 성별 등에 의한 감정가 또는 각성가 차이 등에 대해 다루지 않았던 것이 아쉽다. 또한, 여기서 사용하는 ‘in-the-wild’라는 표현이 다소 오해의 소지가 있는데, 실제 상황 또는 장소에서 촬영했다는 의미로 더 다가오는 것 같다. 또한, 유투브 데이터라 하더라도 실제 안에 들어있는 인물이 감정을 유도했거나 연출할 수 있어서 다소 편향이 존재할 수 있다. <br />
의의: 데이터가 (연구용으로) 공개되어있어 활용성이 높다 (실제로 CVPR에서 경진대회용으로도 활용된 바가 있다). 관련 링크는 아래 참고 자료에 포함되어있다. 또한, CNN-RNN모델을 써서 그 성능을 더 높였다. RNN을 쓴 이유는, 영상의 시퀀스 길이가 들쭉날쭉해서인 것이 크다 (실제 최소 1분보다 짧은 영상부터 최대 15분짜리까지 다양한 길이의 영상들이 있다). RNN은 시퀀스 데이터 크기가 달라도 유연하게 입력값으로 받아서 처리할 수 있다는 장점이 있다. <br /></p>

<p>참고 문헌<br /> 
<a href="https://ibug.doc.ic.ac.uk/resources/first-affect-wild-challenge/">Affect-in-the-wild Challenge 설명</a></p>

<p>Kollias, D., Tzirakis, P., Nicolaou, M. A., Papaioannou, A., Zhao, G., Schuller, B., … &amp; Zafeiriou, S. (2019). Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond. International Journal of Computer Vision, 127(6-7), 907-929.</p>

<h2 id="topic-2-emotion-network-model-ywj-">Topic 2: Emotion Network Model [YWJ] <br /></h2>
<p>선정 이유: 대화 데이터로부터 감정 정보를 분석하는 방법에 대해 공부하기 위해
내용 요약: 최근 심리학적 구성개념 및 과정의 요소들 간 복잡한 상호작용의 다이나믹을 분석 및 시각화의 대상으로 삼는 네트워크 분석이 떠오르고 있다. 이 논문에서는 VAR모델을 사용하여 시간에 걸친 감정의 변화와 신경성의 관계를 네트워크 모델로 분석하였다. 첫 번째로, 전체평균 네트워크에서는 긍정/부정에 속하는 감정끼리 같은 집단의 감정을 증가시키거나 다른 집단의 감정을 약화시키는 경향성이 나타났고, 스스로를 강화시키는 루프는 가장 강력한 강도를 보였다.<br />
두 번째로, 개인별 네트워크를 Dynamic interplay의 주요 특성을 알려줄 수 있는 특징들을 중심으로 분석하였다. 첫 번째로, 요소들이 강하게 연결된 정도를 나타내는 Density의 경우, 신경성 정도가 높은 집단이 낮은 집단보다 전체 감정과 부정 감정이 높았으나 긍정 감정의 경우 데이터셋마다 다르게 나타났다. 두 번째로, 전체 네트워크에서 특정 요소가 중요한 정도를 나타내는 Centrality는 strength, closeness, betweenness로 살펴보았다. In-strength 경향은 신경성이 높을수록 증가하였으나 out-strength 경향의 차이는 일관되지 않았다. 스트레스 감정을 제외하고는 신경성이 높은 집단이 closeness가 높았으나, Betweenness는 신경성과의 연관 경향성이 일관되지 않았다. 스스로를 강화시키는 루프의 경우 슬픔과 불안만이 신경성과 유의하게 관련이 있었다.
단점: 추출된 감정이 아닌, 0~100 스케일의 자기보고를 바탕으로 측정된 감정이 데이터로 활용되었다. 또한 각 요소들의 연결로 시각화된 데이터들은 다중회귀분석의 회귀계수처럼 다른 요소들의 효과를 통제했을 때의 효과이기 때문에, 요소들 간의 공유된 효과(shared effect)가 반영되지 않았다.<br />
의의: 네트워크 접근을 경험적 데이터에 적용하여 분석함으로써 심리적 현상의 시간에 따른 다이나믹을 연구하는 새로운 틀의 가능성을 제시하였다. <br />
비고: 자기보고가 아닌 대화 데이터와 같은 텍스트에서 감정 정보를 추출하는 방법에 대해 공부하기 위해서는 다른 논문을 읽어봐야 할 것 같다.<br /></p>

<p>참고 문헌 <br />
Bringmann, L. F., Pe, M. L., Vissers, N., Ceulemans, E., Borsboom, D., Vanpaemel, W., … &amp; Kuppens, P. (2016). Assessing temporal emotion dynamics using networks. Assessment, 23(4), 425-435.</p>

<h2 id="topic-3-big-data-software-engineering-hy-">Topic 3: Big data software engineering [HY] <br /></h2>

<p>선정 이유 :<br />
LDA 및 Topic-modeling에 관련된 논문을 읽고 싶었음. 1학기 동안 많은 프로그램 다뤄왔는데, 관련하여 정리를 한번 하고 싶었음</p>

<p>내용 요약 :
<br />
목표 : 빅데이터 소프트웨어 엔지니어링에 필요한 지식 영역과 기술 집합을 공개하고 이러한 역량을 매핑하여 분류법을 개발하는 것을 목적으로 한다.
방법론 : Big data software engineering(BDSE)기반한 직업 구인 광고의 의미분석이다. 즉 직업 광고에 나타나는 말뭉치에 대해 LDA topic modeling을 사용하여 잠재 의미 패턴을 추출한다.
Indeed.com API를 사용하여 2,638 개의 온라인 데이터 셋을 확보했다(기간 2018.05~2018.07 3개월) 전처리 작업을 통해 13877개의 워드 space를 10432로 줄였다
각각 토픽의 확률 분포는 Bayesian estimation 을 통해 계산되었고, LDA 토픽 모델링에는 MALLET tool이 사용 되었다.
<br />
결론 : Key world indexing technique를 통해 4가지로 프로그래밍이 분류됨. 1) programming languages 2) programming tools 3)database technologies 4)big data tools. 빅데이터 소프트웨어 엔지니어링을 위한 필수 지식 영역, 기술 및 도구로 구성된 체계적인 역량 맵이 필요하다.
<br />
장점 : 빅데이터에서 최근 주로 사용되는 소프트웨어에 대한 정리가 되어있다. 기본적인 research methodology 대해 overview 할 수 있다. 도표 하나하나에 대해 상세한 설명이 있다 <br />
단점 : 확률 분포에 대한 결과값이 없어서 아쉽다. <br /></p>

<p>의의:소프트웨어 엔지니어는 단순히 프로그램을 잘하는 사람이 아니라, data scientists가 되어야 한다.
비고:전문적인 소프트웨어 엔지니어가 될 수는 없더라도, 향후 data를 분석하고 유의미를 찾는 과정을 통해 진정한 scientists로서 발전해 나가야 할 필요성을 느꼈다.</p>

<p>참고 문헌 <br />
Gurcan, F., &amp; Cagiltay, N. E. (2019). Big Data Software Engineering: Analysis of Knowledge Domains and Skill Sets Using LDA-Based Topic Modeling. IEEE Access, 7, 82541 - 82552</p>

<h2 id="topic-4-social-chatbot-ij-">Topic 4: Social Chatbot [IJ] <br /></h2>

<p>선정 이유: 소셜챗봇에 대한 전반적인 지식을 정리하고 싶어서 읽어보았다.
내용 요약: 소셜챗봇은 user들의 여러 request를 수행할 뿐만 아니라, 대화를 통해 user들과 emotional connection을 한다는 점에서 task-completion system, intelligent personal assistant 등 다른 communication system과 구분된다. 소셜챗봇이 지녀야 하는 핵심적인 기능은 4가지로 정리할 수 있다: (1) empathy (2) social skills (3) personality (4) integration of EQ and IQ. 또한 소셜챗봇 설계의 측면에선 3가지 핵심 구성요소가 존재한다: (1) core-chat (2) visual awareness (3) skills. 현재 상용화되고 있는 소셜챗봇 중 하나가 Xiaolce이며, 이 챗봇은 앞서 소개한 소셜챗봇의 핵심 기능과 설계 구성요소를 통해 user들과 emotional connection을 형성할 수 있는 것으로 보인다. 앞으로 계속해서 사람 간의 상호작용 속에서의 fundamental mechanism of human level intelligence에 대한 연구가 지속적으로 진행되어야 하며, 또한 소셜챗봇 상용화를 위한 윤리적 가이드라인도 마련해야할 것이다.
단점: 좀 더 다양한 소셜챗봇의 사례가 소개되었으면 좋았을 것 같다.
의의: 다양한 communication system 간의 차이와 소셜챗봇의 기능 및 설계 구성요소의 핵심적인 내용들을 잘 정리해 놓은 리뷰논문이다.</p>

<p>참고문헌 <br />
Shum, H. Y., He, X. D., &amp; Li, D. (2018). From Eliza to XiaoIce: challenges and opportunities with social chatbots. Frontiers of Information Technology &amp; Electronic Engineering, 19(1), 10-26.</p>

<h2 id="topic-5-fairness-in-image-tagging-je-">Topic 5: Fairness in Image Tagging [JE] <br /></h2>

<p>선정 이유: 크라우드소싱을 통한 이미지 annotation에 있어 생길 수 있는 편향을 알아보기 위함</p>

<p>요약 <br /></p>
<ul>
  <li>무표정을 한 여러 인종과 성별의 얼굴 이미지를 보여주고 참여자들로 하여금 10개의 tag를 달도록 함.</li>
  <li>사용된 tag는 Demographic (Gender, Age, Race), Concrete (Shape 등), Abstract (Judgment, Traits, Emotion) 등의 토픽으로 분류되었음. 이 중 Asian의 경우 다른 그룹과 비교해서 race나 ethnicity tag를 사용하는 경우가 더 많았으며, Asian women의 경우 외모 특정 부위를 설명하는 shape tag의 비율이 다른 그룹보다 높았음. Black individual도 race-related tag가 많이 나옴.</li>
  <li>Abstract tag의 비율은 높지 않았으나, White women group이 가장 abstract tag가 많이 쓰임.</li>
</ul>

<p>장단점 <br />
장점: 보통 크라우드소싱 작업자들이 이미지를 annotation하는 방식과 비슷하게 tagging을 진행하고, tag가 달린 순서도 고려해서 bias가 있는지 살펴보는 등 연구 방법이 흥미로움. <br />
단점: worker group이 India와 US 두 그룹이 있는데 두 그룹의 차이는 많이 분석되지 않아 아쉬움. 맥락 없는 얼굴 이미지 태깅이어서 abstract tag가 많이 쓰이지 않았는데 이 부분에서의 bias가 어떻게 나타나는지 더 볼 수 있었으면 좋았을 것 같음.</p>

<p>의의: image annotation 상황에서의 bias가 잘 드러남.</p>

<p>참고문헌 <br />
Otterbacher, J., Barlas, P., Kleanthous, S., &amp; Kyriakou, K. (2019, October). How Do We Talk about Other People? Group (Un) Fairness in Natural Language Image Descriptions. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing (Vol. 7, No. 1, pp. 106-114).</p>

<h2 id="topic-6-perception-and-acceptance-of-social-robot-in-children-wk-">Topic 6: Perception and Acceptance of Social robot in Children [WK] <br /></h2>

<p>선정 이유: 학위 논문 관련 지속 리뷰 
요약: 많은 선행 연구들은 one-time interaction을 통해 결과를 얻는다. 하지만, 소셜 로봇이 사람들의 일상에 증가하고 있으며 over time relationship이 어떡해 발달되는지 또한, 로봇에 대한 지각이 어떡해 바뀌는지  보아야된다. 이를 보기 위해 아이들을 대상으로 8주 동안 로봇과 상호작용하는 실험을 하였다. 더불어, 아이들을 대상으로 실험을 하기 때문에 아이들을 위한 Picture Sorting Task 와 Social Acceptance Questionnaire를 개발하였다. 아이들은 로봇 Tega에 대한 지각이 실험기간 동안 통계적으로 유의미하지 않게 바뀌지 않았으며 Acceptance 또한 통계적으로 유의미하게 변화가 있지않았다. 하지만 trending한 결과를 얻었으며 연구자들은 이 결과의 이유를 설명하였다.</p>

<p>장점: 아이들을 위한 Task를 개발하였다. 
단점: 결과가 통계적으로 유의미하지 않았다.</p>

<p>의의: 향후 아이들 대상으로 실험을 진행할 시 연구자들이 개발한 task를 사용할 수 있을 것 같다.</p>

<p>참고문헌<br />
Kory-Westlund, J.M., &amp; Breazeal, C. (2019). Assessing Children’s Perception and Acceptance of a Social Robot. In Interaction Design and Children, 38-50.</p>

<h2 id="topic-7-short-term-music-training-enhances-verbal-intelligence-and-executive-function-wk-">Topic 7: Short-term Music training Enhances Verbal Intelligence and Executive Function. [WK] <br /></h2>

<p>요약: 아이들 대상으로 한달간 음악 훈련과 Visual art 훈련을 실시하였다. 결과는 20일의 훈련을 통해 verbal intelligence와 executive function이 향상된 것을 볼 수 있었다. 이 결과는 음악 훈련에서만 나타났으며 연구자들은 음악과 관련된 뇌 영역이 language와 관련된 뇌 영역과 겹쳐 이러한 결과가 나타났으며 추가로 음악 훈련은 주의력, 기억력과 통제력이 요구됨으로서 executive function이 향상되었을 것이라고 설명하였다. <br /></p>

<p>장점: 신문 연구와 비슷한 실험이 진행되었으며 비슷한 결과가 도출됨으로서 논문에 참고 가능할 것 같다. <br />
단점: 신문 연구와는 다른 “훈련”이 진행되었다. 따라서, 신문 연구와는 직접적이지 않아 신문 연구 결과를 설명할 수 있는지는 확실하지 않다. <br /></p>

<p>의의: 훈련을 통해 executive function을 향상시킬 수 있다는 근거를 수집함. <br /></p>

<p>참고문헌<br />
Moreno,  S., Bialystok,  E.,  Barac, R., Schellenberg, E.G., Cepeda, N.J.,  &amp; Chau, T. (2011). Short-Term Music Training Enhances Verbal Intelligence and Executive Function. Psychological Science, 22(11), 1425-1433.</p>


</div>

<div class="pagination">
  
    <a href="/blog/2020-07-06/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2020-06-04/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
