<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Nov 2nd Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Nov 2nd Journal Club" />
<meta name="author" content="Soomin Cho (soominc3@illinois.edu)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: Empathy in Virtual Agents and Robots, CNN, Text Classification" />
<meta property="og:description" content="Themes: Empathy in Virtual Agents and Robots, CNN, Text Classification" />
<link rel="canonical" href="http://localhost:4000/blog/2020-11-02/study" />
<meta property="og:url" content="http://localhost:4000/blog/2020-11-02/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-02T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Nov 2nd Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Soomin Cho (soominc3@illinois.edu)"},"dateModified":"2020-11-02T00:00:00+09:00","datePublished":"2020-11-02T00:00:00+09:00","description":"Themes: Empathy in Virtual Agents and Robots, CNN, Text Classification","headline":"Nov 2nd Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2020-11-02/study"},"url":"http://localhost:4000/blog/2020-11-02/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Soomin Cho (soominc3@illinois.edu)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-11-02 00:00:00 +0900">November 02, 2020</time>
    
  </div>

  <h1 class="post-title">Nov 2nd Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: Empathy in Virtual Agents and Robots, CNN, Text Classification  
</code></pre></div></div>

<p>Presenters: JP (Jaeun Park), YWJ (Yoonwon Jung) <br /></p>

<hr />

<h2 id="topic-1-empathy-in-virtual-agents-and-robots-ywj">Topic 1: Empathy in Virtual Agents and Robots [YWJ]</h2>

<p>선정 이유: “공감하는 AI”와 관련된 연구들이 어느 정도까지 진행되었고 어떤 방법론을 사용했는지 전체적으로 공부해보기 위해 선정하였다.<br /></p>

<p>내용 요약<br />
‘공감(Empathy)’에 대해 보편적으로 합의된 정의는 아직 존재하지 않으나, 크게 인지적 공감, 정서적 공감, 그리고 인지적 공감과 정서적 공감의 합이라는 세 가지 카테고리가 존재한다. 이러한 관점들을 모두 포괄할 수 있는 통합적 접근 중 하나인 De Waal(2002)의 공감에 대한 정의에 의하면, 공감은 (1)the capacity to be affected by and share the emotional state of another, (2)assess the reasons for the others state, 그리고 (3)identify with the other, adopting his or her perspective이다. 이러한 접근 방식의 필요성과 타당성에 대한 이견이 존재하지만, 이러한 정의는 특히 인간-기계 상호 작용(Human-Machine Interaction)의 맥락에서 기계(Machine)가 거치는 고수준과 저수준의 과정을 모두 고려할 수 있는 포괄적이고 상세한 관점을 제공한다는 점에서 적절하다. <br />
그동안 진행되어 온 연구 결과에 따르면 공감 감정이 발생할 때에 거치는 가장 중요한 세 단계가 있다. 첫 번째 단계는 공감이 감정으로서 발생하고 경험되는 공감 기제(empathy mechanism)로, 무의식적이고 자동적으로 일어나는 감정적 과정과 의식적이고 보다 복잡한 과정을 거치는 인지적 조망수용(cognitive perspective-taking) 과정이 있다. 두 번째 단계는 공감 감정이 조정되어 경험되는 공감의 정도가 결정되는 공감 조정(empathy modulation)으로, 관찰된 감정의 특징(features of observed emotion), 관찰자와 공감 타깃의 사회적 관계(social relationships between observer and target), 상황과 맥락(situation and context), 그리고 관찰자의 특징 (features of the observer)이라는 크게 네 가지 카테고리에 속하는 변인들이 공감의 강도에 영향을 미친다. 마지막 세 번째 단계는 공감 감정이 표현되고 타인에게 전달되는 공감 반응(empathic responses)의 과정으로, 생리적 반응이나 얼굴 표정 등으로 표현될 수 있으며 행동 경향성(action tendency)는 사회적 행동으로까지 이어질 수 있다.<br />
인간-기계 상호작용의 맥락에서 저자들은 공감 에이전트(empathic agent)를 크게 (1)공감의 타깃으로서의 에이전트와 (2) 공감의 주체로서의 에이전트 두 가지로 정의하였다. 이러한 정의를 바탕으로 이 논문에서는 각 종류의 에이전트의 공감에 대한 계산 모델(computational model)을 세우기 위해서 어떤 요소들이 고려되어야 하는지 제시하고, 그러한 프레임워크에 맞추어 기존 연구들을 분석하였다. 분석 결과는 비고에 테이블로 정리하여 첨부하였다. (1)유형의 공감 에이전트보다 (2)유형의 공감 에이전트에 대한 연구는 비교적 덜 진행되었고, 비교적 명확한 한계점이 존재한다. 첫 번째로, 많은 연구들이 공감 기제(empathy mechanism)와 공감 반응(empathic responses)에 대해 탐구한 반면 공감 조정(empathy modulation)에 대해 다루지 않았다. 두 번째로, 공감 반응(empathic responses)의 정의와 측정이 주로 감정적 표현에 집중되었는데, 이는 사회적 행동과 더 밀접하게 연결된 행동 경향성(action tendency)을 통해 표현되는 공감을 포함하지 못하는 한정적인 정의라는 점에서 한계가 있다. 마지막으로, 로봇과 상호작용하는 인간 참여자의 감정적 상태를 측정하는 데에 사용된 방법들의 신뢰성이 떨어지는 경우도 존재하는데, 어떠한 도구를 쓰는지에 따라 에이전트의 공감적 행동의 적절성 평가 결과가 영향을 받을 수 있기 때문에 역시 주의를 요한다.</p>

<p>의의: 공감과 관련된 기존 심리학 연구들을 리뷰하고 이를 인간-기계 상호작용의 맥락에 적용하였다는 점에서 계산적 접근을 통해 구현하고자 하는 현상의 이론적 근거를 분명하게 확립하였다. 또한 논문을 마무리하며 공감 에이전트에 대한 연구들이 향후 해결해야 할 과제들과 그 과정에서 떠오를 수 있는 쟁점들을 제시하였는데, 이는 크게 (1) 공감이 발생하는 맥락에 대한 고려 (2) 이론과 그 이론을 바탕으로 만들어진 계산 모델 사이의 상호작용 (3) 무엇을 어떻게 측정하는지의 문제 (4) 공감 에이전트의 자율성 (5) 공감의 “authenticity)의 5가지이다. 이러한 작업을 통해 향후 공감 계산 모델링 연구들이 참고할 만한 로드맵을 제시한 것으로 보인다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Paiva, A., Leite, I., Boukricha, H., &amp; Wachsmuth, I. (2017). Empathy in virtual agents and robots: a survey. ACM Transactions on Interactive Intelligent Systems (TiiS), 7(3), 1-40.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-2-cnn-text-classification-jp">Topic 2: CNN, Text Classification [JP]</h2>

<p>선정이유: CNN을 통해 자연어처리를 하는 방법을 학습하고자 선정하였다. <br /></p>

<p>내용요약 <br /> 
RNN은 문장 전체 시퀀스만 represent할 수 있고 n-gram 등 문장의 일부는 represent하지 못하는 단점이 있는데, CNN을 사용하면 이를 해결할 수 있다. 주로 시각 분야에서 자주 사용되는 CNN은 시야의 어디든 비슷한 패턴이 나타나면 이를 찾을 수 있도록 하는 기능을 한다. 자연어처리에서도 비슷하나, 텍스트에서는 1차원의 convolution이 사용된다. 전체 시퀀스에 대해 특정 크기(e.g. 세 단어)의 kernel을 슬라이드하며 dot product를 한 후 계산하면 그 값이 그 특정 크기 구절의 representation이 된다. 이 때 input matrix의 크기와 convolution 적용 이후 output matrix의 크기가 달라지는 것을 막기 위해 zero padding을 사용한다. 또한, 더 좋은 representation을 위해 여러 개의 filter를 사용해서 여러 channel의 output이 나올 수 있도록 한다. 이 각각의 filter는 서로 다른 의미에 대해 specialize하며, output channel의 값이 이 각 의미를 summarize해주는 값이라 할 수 있다. output matrix를 여러 가지 방법으로 pooling할 수 있는데, max pooling over time을 사용하면 여러 개의 filter로 인해 나온 output인 각 channel 중 maximum value를 가져오게 된다. 이 때 이 maximum value는 그 filter가 대표하는 의미가 가장 잘 드러나는 marker 부분을 나타낸다. 이와 같이 CNN을 사용하면 여러 의미를 잘 나타내는 일부 시퀀스를 찾을 수 있어 text classification에 유리하다. <br /></p>

<p>장단점: CNN은 text classification에 유리하며 GPU에서 parallelize가 잘 되어 계산이 빠르다는 장점이 있다. RNN은 CNN보다 더 인지적/언어적 관점에서 그럴 듯하고, sequence tagging 등에 좋으나 CNN에 비해 느리고 attention 등의 방법을 사용하지 않으면 sentence representation을 잘 하지 못한다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Kim, Y. (2014). Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882.
</code></pre></div></div>



</div>

<div class="pagination">
  
    <a href="/blog/2020-11-16/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2020-10-19/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
