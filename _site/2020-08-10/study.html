<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Aug 10th Journal Club | Research Blog</title>
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="Aug 10th Journal Club" />
<meta name="author" content="Soomin Cho (soominc3@illinois.edu)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Themes: Commonsense Reasoning, Learning to learn, LDA, PersonaChat task, Dependency Parsing, Social sharing of emotions" />
<meta property="og:description" content="Themes: Commonsense Reasoning, Learning to learn, LDA, PersonaChat task, Dependency Parsing, Social sharing of emotions" />
<link rel="canonical" href="http://localhost:4000/blog/2020-08-10/study" />
<meta property="og:url" content="http://localhost:4000/blog/2020-08-10/study" />
<meta property="og:site_name" content="Research Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-10T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Aug 10th Journal Club" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Soomin Cho (soominc3@illinois.edu)"},"dateModified":"2020-08-10T00:00:00+09:00","datePublished":"2020-08-10T00:00:00+09:00","description":"Themes: Commonsense Reasoning, Learning to learn, LDA, PersonaChat task, Dependency Parsing, Social sharing of emotions","headline":"Aug 10th Journal Club","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2020-08-10/study"},"url":"http://localhost:4000/blog/2020-08-10/study"}</script>
<!-- End Jekyll SEO tag -->


  <!-- CSS -->
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/assets/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/assets/favicon-16x16.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/assets/apple-touch-icon.png">

  <!-- RSS -->
  <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/blog/feed.xml" title="Research Blog" />

  <!-- Google Analytics-->
  
</head>


  <body>

    <nav class="nav">
  <div class="nav-container">
    <a href="/blog/">
      <h2 class="nav-title">Research Blog</h2>
    </a>
    <ul>
      <li><a href="/blog/about">About</a></li>
      <li><a href="/blog/">Posts</a></li>
    </ul>
  </div>
</nav>


    <main>
      <div class="post">
  <div class="post-info">
    <span>Written by</span>
    
        Soomin Cho (soominc3@illinois.edu)
    

    
      <br>
      <span>on&nbsp;</span><time datetime="2020-08-10 00:00:00 +0900">August 10, 2020</time>
    
  </div>

  <h1 class="post-title">Aug 10th Journal Club</h1>
  <div class="post-line"></div>

  <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Themes: Commonsense Reasoning, Learning to learn, LDA, PersonaChat task, Dependency Parsing, Social sharing of emotions 
</code></pre></div></div>

<p>Presenters: YK (Yoon Kyung Lee), YW (Yoonwon Jung), JE (Jaeun Park), IJ (Inju Lee), HY (Hoyoung Maeng), WK (Whani Kim), SC (Soomin Cho) <br />
Guest : HeeYoung Park (Psychometrics Lab)</p>

<hr />

<h2 id="topic-1-commonsense-reasoning-yk">Topic 1: Commonsense Reasoning [YK]</h2>

<p>선정 이유: Self-supervised Learning 방법과 외부 지식을 학습 시키는 방법을 비교한 연구라 결과가 궁금해서 선정하였다. <br /></p>

<p>내용 요약: 언어 모델을 프리트레인함으로써 외부지식을 뉴럴넷에 학습시키는 방법이 증가했다. 이는 BERT, GPT-2, XLNET 등의 Transformer 를 통해 가능하다. 본 연구에서는 1) Self-Supervised Learning 방법과 뉴럴넷 언어 생성 모형을 사용해서 외부 지식을 학습한 방법을 비교했고, 2) 기존에 텍스트에 담긴 이야기나 지문에 담긴 요점, 사건의 원인과 결과, 질문의 대상이 되는 인물 등을 추론하는 6개의 과제에 실험했으며, 3) 정량적인 평가와 정성적인 평가 방법 둘 다 사용하여 각 모형에 대한 정확도, 사람이 느끼기에 유용한 정도와 문법적 오류를 평가했다. 과제는 COPA(Gordon et al., 2012),  CommonSenseQA (Talmor et al., 2019), MC-TACO( Zhou et al., 2019), Social IQa(Sap et al., 2019), PIQA (Bisk et al, 2020), 그리고 WinoGrande(Sakaguchi et al., 2020)였다. 연구에서 비교한 모형은 LM(Language Model)-only, Baseline Model with External Knowledge, Self-talk Model, 그리고 Human performance이다. 그 결과 WinoGrande 데이터셋 과제를 제외하고 zero-shot으로 평가했을 때, baseline model보다 모두 좋은 성능을 보였다. GPT2-XL이 2개의 과제를 제외하고 가장 높은 성능을 보였다. 외부 지식으로서 가장 높은 선호를 보인 데이터셋을 비교했을때, COPA, CSQA, Social IQa는 모두 COMET에 대한 선호를 보였으며 MC-TAO와 PIQA는 Google Ngram을, WinoGrande만 GPT에 대한 선호를 보였다. 문법적 타당도는 CommonSenseQA로 생성된 결과가 가장 높은 평가를 받았다. <br /></p>

<p>의의: 실제 Crowdsource worker를 대상으로 정성적 평가를 한 결과 20-40%의 결과만 ‘도움이 된다(helpful)’라고 평가를 받았다. 이에 대한 해석이 사람들이 별로 도움이 되지 않는다고 생각되는 표현들도 다 고려해서라고 나와있으나, 예시가 없어서 잘 와닿지 않는다. Not helpful 의 정의도 모호하게 느꼈다. <br /></p>

<p>장단점: Commonsence 생성 능력을 측정하기 위해 6개의 관련 과제를 풀게 하고 이에 대한 결과를 정량적 그리고 정성적으로 평가했다. GPT-2, XLNET 등 모형들의 성능을 랭킹을 매기는 방식으로 직접 비교하니 특정 과제에 대해 이 모형들이 얼마나 적합한지 그리고 얼마나 편향되어 있는지도 한눈에 볼 수 있다. 또한, 사람들이 실제 느끼는 바와 평가하는 걸 볼 수 있어서 과제 평가 방법과 분석을 좀 더 정교하게 할 수 있다면 의미 있는 심리학 연구로 발전시킬 수 있는 가능성도 확인했다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Shwartz, V., West, P., Bras, R. L., Bhagavatula, C., &amp; Choi, Y. (2020). Unsupervised Commonsense Question Answering with Self-Talk. arXiv preprint arXiv:2004.05483.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-2-learning-to-learn-sc">Topic 2: Learning to learn [SC]</h2>

<p>선정이유: 사람이 배우는 방식과 AI 에이전트들이 배우는 방식은 매우 다른데, 인간이 무의식적으로 처리하는 일련의 학습 과정들을 어떻게 기계에게 학습시킬 것인가를 발단으로 한 논문이다. 인간과 기계의 학습 방식 차이점을 좁히기 위해 사용된 Learning-to-learn method를 배우고 싶어서 선정하였다. <br /></p>

<p>내용요약 : 지금까지 AI 연구들에서는 일일히 수동 작업이 많이 이루어졌는데, 결론적으로 hand-coding 방식들은 복잡한 문제를 해결할 때 번거롭고 어렵다는 단점이 있다. AI 에이전트도 주어진 데이터로부터 직접 문제 해결 방식을 배울 수 있다고 밝혀지면서 인간은 문제 일반화로 쉽게 차용하지만 에이전트들에게는 까다로운 one shot, few shot learning 이 주목받았다. 더 효율적으로 문제 해결 방식을 배우기 위하여 learning-to-learn 이라는 컨셉이 나왔고, 이는 1) learning to optimize 와 2) structure learning 의 두 가지 방식으로 나뉜다. <br />
Learning to optimize 의 경우 좋은 솔루션에 빨리 도달하기 위해 효과적인 learning 방식을 배운다. 관련없는 task도 시도해볼 수 있다. 반면, Structure learning은 새로운 task를 빨리 배우기 위함으로, 각 과제들의 공통된 구조를 배움으로써 관련된 tasks에 일반화하는 것을 목적으로 한다. 예를 들어 Learning to optimize는 1991년 연구된 synaptic learning rules를 기반으로 Gradient Descent 라는 접근법이 있다. Structure Learning의 경우 비슷한 구조를 착취함으로써 새로운 과제에 빨리 적응하고 그것을 해결하기 위함이다. Few-shot learning 방식을 쓸 수 있다. 에이전트의 경우는 두 가지 시스템으로 구성되어 있고, 첫 번째는 주어진 과제를 시행하는 Learner이고 두 번째는 더 효율적인 learning 을 위해 learner을 튜닝하는 Meta-learner이다. <br />
Learning-to-learn 은 AI, cognitive science, neuroscience의 세 분야에서 대표적으로 다루고 있는데 각 분야들은 서로 상호작용을 주고받으며 관련 연구를 진행해나간다. <br /></p>

<p>장점: AI 분야만 분석한 것이 아니라 연관된 cognitive science, neuroscience의 접근 방식까지 다루었다는 점에서 전반적인 연구 동향을 반영한 논문이라고 느꼈다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Lansdell, B. J., &amp; Kording, K. P. (2019). Towards learning-to-learn. Current Opinion in Behavioral Sciences, 29, 45-50
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-3-lda-llda-labeled-lda-hy">Topic 3: LDA, LLDA (Labeled LDA) [HY]</h2>

<p>선정 이유: Topic Modelling 으로 많이 알려진 LDA의 개발 배경 및 발전 동향을 파악하고 싶어서 선정하였다. <br /></p>

<p>내용 요약: 기존 LDA(Latent Dirichlet Allocation)는 비지도 학습으로써 텍스트 기반의 문서 안에서 사용자가 알고자 하는 K개의 주제를 자동으로 선별하여, 어떤 주제들로 구성되어 있는지 자동으로 분석해주는 머신러닝 알고리즘이다. 즉, 사람이 라벨을 하나하나 지정해주지 않아도, 머신러닝이 스스로 유사한 것들끼리 모아서 주제를 붙인다. 반면, 비지도 학습이므로 머신러닝이 출력한 결과물이 사람이 이해하기 어려운 토픽일 수도 있다. LLDA(Labeled LDA)는 Ramage가 구성한 LDA의 지도학습 알고리즘이다이다. 이미 1차적으로 라벨링된 문서를 분석하여, 각 토픽별로 속해 있는 키워드 구성을 학습한다. 텍스트 자동분류, 키워드 추출, 자동 태킹, 주제 분류, 감정분석 등과 같은 알고리즘으로 활용된다. 학습이 잘 되면 학습된 데이터 문서 셋에 새로운 문서가 입력되었을 때, 그 문서 안에 어떤 주제가 있는지 자동으로 계산한다. <br /></p>

<p>장단점: LDA vs LLDA를 각각 예시를 visualization 하여 비교할 수 있도록 표현한 점은 LLD를 이해하는 데 큰 도움이 되었다. 다만 자연어처리에 대한 기본 배경지식이 없으면 이해하기 어려울 것 같다.<br /></p>

<p>의의: LLDA의 기본 원리 및 활용방안에 대하여 학습할 수 있었으며, 향후 데이터 분석시 충분히 활용할만한 가치가 있을 것이다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Daniel, R. et al.(2009), Labeled LDA: A supervised topic model for credit attribution in multi-labeled corpora, Proceedings of the 2009 conference on empirical methods in natural language processing, 248-256
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-4-chitchat-dialogue-conversation-quality-conditional-training-weighted-decoding-personachat-task-ij">Topic 4: Chitchat Dialogue, Conversation Quality, Conditional Training, Weighted Decoding, PersonaChat task [IJ]</h2>

<p>선정 이유: chitchat dialogue에서 ‘좋은’ 대화가 무엇이고 어떻게 대화의 질을 높일 수 있는지 궁금해서 선정하였다. <br /></p>

<p>내용 요약: ‘좋은’ 대화란 대화의 simplicity와 detail, 특정 주제에 대하여 이야기하는 것과 주제를 전환하는 것, 질문을 던지고 대답하는 것 사이에서 적절한 균형(balance)를 유지하는 대화이다. 본 연구는 대화의 질에 관여하는 요소에 있어 알고리즘적으로 통제가 가능한 4가지 low-level attributes(repetition, specificity, response-relatedness, question-asking)를 조절하고 각 요소가 대화의 질에 대한 사람의 판단에 미치는 영향을 살펴보았다. multi-turn interactive dialogue 상황에서의 자연어 생성과 이에 대한 사람의 평가를 다루고자 하였기 때문에 utterance 보다는 dialogue 수준에서 attributes를 조절하였으며, 2가지 알고리즘(conditional training, weighted decoding)을 함께 사용하였다. Automatic metrics를 통해 각 알고리즘의 유용성(effectiveness)을 평가하였고, 이를 기반으로 사람의 평가를 받아볼 총 28개의 유용성이 높은 control methods와 control settings을 선택하였다. 사람들은 PersonaChat task를 통해 챗봇과 대화를 나눈 후 해당 대화의 질에 대해 평가하였다. 그 결과, repetition, specificity, question-asking를 조작함으로써 engagingness를 향상시킬 수 있었고, 이는 전반적인 대화의 질을 향상시켰음을 나타낸다. 또한 전반적인 대화의 질을 측정하기 위해 흔히 humanness와 engagingness를 사용하지만 둘은 서로 다른 개념이기 때문에 dialogue agent를 평가하기 위해선 하나 이상의 quality metric을 이용해야 할 것으로 보인다. 앞으로 자동적으로 control setting을 최적화하고 더 human-like 챗봇을 설계할 수 있는 연구가 계속되어야 할 것이다. <br /></p>

<p>장점: 각 알고리즘을 이용하여 대화의 질에 영향을 주는 attributes를 조작한 방법을 체계적으로 설명해놓았다. <br /></p>

<p>의의: 그동안 전반적인 대화의 질에 대한 사람의 판단에 영향을 주는 요인에 대하여 제대로 다루어 오지 않았는데, 본 연구는 사람의 판단에 영향을 주는 fine-grained factor를 밝히고 이를 모델에 적용함으로써 state-of-the-art 성능을 이끌어냈다. 특히 더 적은 데이터를 통해 최근 NeurIPS ConvAI2 competition의 우승 모델과 비슷한 성능을 내보였다는 점에서 더욱 의미가 있다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> See, A., Roller, S., Kiela, D., &amp; Weston, J. (2019). What makes a good conversation? how controllable attributes affect human judgments. arXiv preprint arXiv:1902.08654.
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-5-dependency-parsing-transition-based-dependency-parsing-neural-network-jp">Topic 5: Dependency Parsing, Transition-Based Dependency Parsing, Neural Network [JP]</h2>

<p>선정 이유: 문장 구조 분석 방법 중 하나인 dependency parsing에 대해 공부하기 위해 선정하였다. <br /></p>

<p>내용 요약: 언어구조를 분석하는 방법에는 크게 phrase structure grammar와 dependency grammar 두 가지가 있다. phrase structure grammar에서는 단어가 구, 절, 문장 등 더 큰 통사단위를 형성하는 원리를 탐구하는 반면, dependency grammar에서는 문장 속 단어 간의 의존 관계(수식 관계 등)를 분석한다. 계산언어학에서는 주로 dependency grammar를 활용한다. 문장을 이해하는 데 있어 dependency grammar에서 얘기하는 것과 같은 의존 관계를 파악하는 일은 필수적이다. 머신러닝을 활용해 문장 구조 분석을 실시하기 위해 Universal Dependencies Treebanks와 같은 annotated data를 사용할 수 있다. 이러한 treebank는 사람이 직접 문장 속 단어들의 의존 관계를 태깅한 데이터셋이다. Dependency parsing 방법 중 greedy transition-based parsing은 문장 속 단어를 버퍼에서 stack로 하나씩 옮겨가며 각 상태에서 shift, left-arc, right-arc 등의 action 중 하나를 택해 파싱을 진행해나가는 방식이다. Nivre는 parsing 상태에서 다음에 어떤 action을 취해야 할지 예측하는 머신러닝 classifier를 만드는 방식의 MaltParser를 개발하였다. 이 classifier는 각 단어의 PoS와 특성 등등을 고려하는 indicator feature를 입력값으로 받았으나, 현재 자주 사용되는 neural dependency parser는 같은 아이디어를 바탕으로 하는 대신 단어 자체를 distributed representation의 형태로 직접 입력값으로 받는 방식을 취한다. <br /></p>

<p>장단점: 인공신경망을 사용한 dependency parsing은 기존의 MaltParser 등과 비교해서 여러 가지 장점이 있다. 기존 MaltParser는 indicator feature를 입력값으로 사용하였는데, 이러한 feature는 매우 sparse하다는 단점이 있었고, 모든 configuration에 맞출 수 없었기 때문에 완전하지 못했다. 또한 머신러닝 학습에 있어 대부분의 시간이 feature computation에 사용되는 등 계산 비용이 크다는 단점이 있었다. 인공신경망을 사용하면 정확도도 높으면서 빠른 속도로 학습이 가능하다. <br /></p>

<p>의의: 인공신경망으로 dependency parsing을 함으로써 단어 개별의 의미뿐 아니라 문장구조의 파악이 가능하다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Nivre, J. (2004). Incrementality in deterministic dependency parsing. In Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together (pp. 50-57).; Linguistic Structure: Dependency Parsing (Manning, Stanford CS224N)
</code></pre></div></div>

<p><br /></p>

<h2 id="topic-6-social-sharing-of-emotions-computer-mediated-communication-yw">Topic 6: Social sharing of emotions, computer-mediated communication [YW]</h2>

<p>선정 이유: 인간의 감정 표출과 감정 반응에 대한 연구를 소셜 미디어 기업에서는 어떻게 접근하는지 궁금해 선정하였다. <br /></p>

<p>내용 요약:  감정의 사회적 공유(Social sharing of emotions) 이론에 따르면, 인간은 사건에 대한 감정적 반응을 공유하고 타인으로부터 피드백을 얻고 싶어하는 근본적인 욕구가 있다. 감정의 사회적 공유에 대한 연구가 대면 상호작용(face-to-face communication)을 기초로 하여 진행되어 왔지만, 최근 트위터, 페이스북, 블로그 등의 컴퓨터 매개 상호작용(CMC)에서 나타나는 감정 표현에 대한 연구 또한 늘어나고 있다. 그 중 페이스북은 친구 집단을 대상으로 감정의 표출이 나타나기 때문에, 트위터나 블로그와 같이 불특정 다수의 사람들과 상호작용하는 공적 플랫폼과는 다른 양상의 상호작용이 나타날 수 있다. 또한 SNS에서는 문자 메시지와 같은 일대일 상호작용이 아닌 일대다 상호작용이 주로 일어나므로, 한 사용자의 상태 업데이트에 다른 한 명이 반응의 의무를 지는 형태가 아니다. 따라서 한 사용자의 감정 표출에 여러 명의 친구들이 어떻게 자유롭게 반응하는지 살펴볼 수 있고, 이는 결과적으로 페이스북이라는 SNS가 어떻게 사용되고 있는지에 대한 사회적 규범(social norm)의 정보를 제공해줄 것이다. <br />
포스팅을 한 사람이 직접 태깅한 페이스북 상태 업데이트에 담긴 감정 정보를 바탕으로 (1) 사람들이 어떤 상황에서 어느 정도로 감정을 표출하는지 (2) 감정 공유에 대한 반응의 특성이 어떠한지 살펴보았다. 그 결과, 사람들은 친구 네트워크가 작고 밀도가 높을수록 부정과 긍정 감정을 더 많이 공유하였다. 부정 감정의 경우에는 긍정 감정보다 친구 네트워크로부터 감정적이고 지지를 보내는 답변을 더 많이 유발하였고, 코멘트의 수와 길이도 더 많게 나타났다. 긍정 감정의 경우에는 부정 감정보다 좋아요를 더 많이 받았고, 댓글에서는 긍정적인 언어가 더 많이 쓰였다. 성취감이나 사랑받지 못한다는 감정 등 해당 글을 포스팅한 사람의 자기 가치감과 관련된 감정들은 이러한 효과를 증폭시키는 것으로 나타났다. <br /></p>

<p>장단점: 페이스북 포스팅에 나타난 감정가(valence)에 따라 반응 양상이 달라짐을 밝혀내었다. 추후에는 감정을 크게 긍정, 부정으로 나누는 것을 넘어, 그 안에서 더 세부적인 감정을 타겟팅하여 연구를 진행하는 것도 의의가 있을 것이다. <br /></p>

<p>의의: 사람들이 소셜 미디어에서 자신의 감정을 표출할 때는 어떤 맥락이 작용하며, 또 그러한 감정 표출의 결과로 어떠한 반응을 얻는지에 대해 실제 페이스북 이용자의 데이터를 활용하여 연구하였다.</p>

<p><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Burke, M., &amp; Develin, M. (2016, February). Once more with feeling: Supportive responses to social sharing on Facebook. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing (pp. 1462-1474)
</code></pre></div></div>



</div>

<div class="pagination">
  
    <a href="/blog/2020-08-24/study" class="left arrow">&#8592;</a>
  
  
    <a href="/blog/2020-08-03/study" class="right arrow">&#8594;</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
  <span>
    &copy; <time datetime="2022-12-20 15:33:14 +0900">2022</time> Yoon Kyung Lee. Made with Jekyll using the <a href="https://github.com/chesterhow/tale/">Tale</a> theme.
  </span>
</footer>

  </body>
</html>
